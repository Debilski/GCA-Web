abstracts = [{"correspondence": ["eero.simoncelli@nyu.edu, movshon@nyu.edu"], "figid": 1, "doi": "10.12751/nncn.bc2013.0257", "affiliations": [{"index": "1", "address": "HHMI and Center for Neural Science, New York University, New York, USA"}, {"index": "2", "address": " Center for Neural Science, New York University, New York, USA"}], "title": "A functional and perceptual signature of the second visual area in primates", "abstract": "The perception of complex visual patterns emerges from neuronal activity in a cascade of areas in the primate cerebral cortex. Neurons in the primary visual cortex (V1) represent information about local orientation and spatial scale, but the role of the second visual area (V2) is enigmatic. We made synthetic texture images that contain complex features found in naturally occurring visual images, and used them to stimulate macaque V1 and V2 neurons. Most V2 cells respond more vigorously to these stimuli than to matched control stimuli lacking complex naturalistic features, while V1 cells do not. fMRI measurements in humans reveal differences in V1 and V2 responses to the same textures that are consistent with neuronal measurements in macaque. Finally, the ability of human observers to detect naturalistic structure is well predicted by the strength of the neuronal and fMRI responses in V2 but not in V1. These results reveal a novel and particular role for V2 in the representation of naturally occurring structure in visual images, and suggest ways that it begins the transformation of information about elementary visual features into the specific signals about scenes and objects that are found in areas further downstream in the visual pathway. [Collaborative work with Jeremy Freeman, David Heeger, and Corey Ziemba].", "acknowledgements": "", "id": 1, "topic": "Opening lecture", "imagefile": "", "authors": [{"epithet": "1", "name": "Eero Simoncelli"}, {"epithet": "2", "name": "Tony Movshon"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["wmusrey@ucdavis.edu"], "figid": 2, "doi": "10.12751/nncn.bc2013.0258", "affiliations": [{"index": "1", "address": " Center for Neuroscience, University of California, Davis, USA"}], "title": "Organization and Dynamics of Neural Circuits for Vision", "abstract": "The response properties of neurons in the early visual system are governed by the anatomical organization of connections and the temporal patterns of impulse arrival. Recent advances in multielectrode recording technology have made it possible to study the role of both features in the same experiment. Results will be presented from experiments that examined the specificity of neuronal connections and the role of spike timing and behavioral modulation in the transmission of visual information. These results reveal a striking relationship between the biophysical properties that govern spike transfer and the encoding of visual information in neuronal spike trains.", "acknowledgements": "Supported by NIH grant EY013588 and NSF grant 1228535. ", "id": 2, "topic": "Physiology of Vision", "imagefile": "", "authors": [{"epithet": "1", "name": "W. Martin Usrey"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["p.roelfsema@nin.knaw.nl"], "figid": 3, "doi": "10.12751/nncn.bc2013.0259", "affiliations": [{"index": "1", "address": " Department of Vision & Cognition, Netherlands Institute for Neurosciences, Amsterdam, The Netherlands"}, {"index": "2", "address": " Department of Integrative Neurophysiology, Centre for Neurogenomics and Cognitive Research, VU University, Amsterdam, The Netherlands"}, {"index": "3", "address": " Psychiatry Department, Academic Medical Center, Amsterdam, The Netherlands"}], "title": "The neuronal mechanisms that are responsible for perceptual organization", "abstract": "A fundamental task of vision is to group the image elements that belong to one object and to segregate them from other objects and the background. I will discuss a conceptual framework that explains how perceptual grouping is implemented in the visual cortex. According to this framework, two mechanisms are responsible for perceptual grouping: base-grouping and incremental grouping. Base-groupings are coded by single neurons tuned to multiple features, like the combination of a color and an orientation. They are computed rapidly because they reflect the selectivity of feedforward connections that propagate information from lower to higher areas of the visual cortex. However, not all conceivable feature combinations are coded by dedicated neurons. Therefore, a second, flexible form of grouping is required that is called incremental grouping.\n\nIncremental grouping takes more time than base-grouping because it relies on horizontal connections between neurons in the same area and feedback connections that propagate information from higher to lower areas. These connections spread an enhanced response to all the neurons that code image elements that belong to the same perceptual object. This response enhancement acts as a label that tags those neurons that respond to image elements to be bound in perception. The enhancement of neuronal activity during incremental grouping has a correlate in psychology because attention is directed to precisely those features that are labeled by the enhanced neuronal response. I will show data indicating that feedforward and feedback processing rely on different receptors for glutamate and on processing in different cortical layers. ", "acknowledgements": "", "id": 3, "topic": "Physiology of Vision", "imagefile": "", "authors": [{"epithet": "1,2,3", "name": "Pieter R. Roelfsema"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["pasupat@uw.edu"], "figid": 4, "doi": "10.12751/nncn.bc2013.0260", "affiliations": [{"index": "1", "address": " University of Washington, Seattle, USA"}], "title": "Partial occlusions and primate V4 ", "abstract": "One current focus of research in my laboratory is to understand how partially occluded objects are processed in primate area V4, an intermediate stage in the visual shape processing pathway. I will describe results from two projects. First, I will talk about how shapes are encoded differently depending on whether they are the result of occlusion or not. We find that sharp convexities at the junction between occluding and occluded objects are suppressed, and this could mark the first step of image segmentation in the primate brain. Next, I will describe our recent efforts to understand how shape selective V4 neurons contribute to the discrimination of partially occluded objects. In addition to encoding shape information, we find that V4 responses reflect the animal's behavioral choice even before the emergence of similar signals in the inferotemporal and frontal cortices. Interestingly, V4 decision signals emerge more slowly for higher levels of occlusion and are matched to the time of peak shape selectivity, supporting the idea that V4 may be directly involved in the computation that underlies shape discrimination.", "acknowledgements": "", "id": 4, "topic": "Physiology of Vision", "imagefile": "", "authors": [{"epithet": "1", "name": "Anitha Pasupathy"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["rruth@mit.edu"], "figid": 5, "doi": "10.12751/nncn.bc2013.0261", "affiliations": [{"index": "1", "address": " MIT Department of Brain & Cognitive Sciences, CSAIL, Boston, USA"}], "title": "Rethinking the roles of selective attention and economical encoding in vision", "abstract": "Considerable research\u00a0points\u00a0to\u00a0a bottleneck in visual processing. \u00a0According to the traditional view, at any given moment selective attention allows only a small portion of the visual input to get through the bottleneck for further processing. \u00a0Some processing can occur \"preattentively\" and guide this selection. Much of the early research on visual search aimed at determining what processing could occur preattentively, and what required selective attention.\n\nWhile this view of visual processing has held sway for many years, it has also been problematic. \u00a0My lab proposes an alternative, in which the visual system's strategy for dealing with limited capacity focuses on compression of the visual input, rather than on selective attention. \u00a0I will demonstrate that this model can predict not only classic results in visual search, but also\u00a0phenomena that were problematic for the traditional selective attention story.", "acknowledgements": "", "id": 5, "topic": "Computational Vision", "imagefile": "", "authors": [{"epithet": "1", "name": "Ruth Rosenholtz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["torralba@csail.mit.edu"], "figid": 7, "doi": "10.12751/nncn.bc2013.0263", "affiliations": [{"index": "1", "address": " MIT Department of Brain & Cognitive Sciences, CSAIL, Boston, USA"}], "title": "Who is to blame in object detection failures?", "abstract": "In this talk I will discuss some of the reasons why current state of the art object detectors fail. Many times researchers are puzzled trying to understand why the car detector fires with high confidence on a patch of grass, or why some object views are never detected. In this talk I will discuss on the reasons behind those failures and on ways of understanding them. I will talk about the image features used by current state of the art detectors and also the most common image datasets used for training and evaluating current detection algorithms.\u00a0", "acknowledgements": "Work in Collaboration with C. Vondrick, A. Khosla, T. Malisiewicz, and A. Efros.", "id": 6, "topic": "Computational Vision", "imagefile": "", "authors": [{"epithet": "1", "name": "Antonio Torralba"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["perona@caltech.edu"], "figid": 8, "doi": "10.12751/nncn.bc2013.0264", "affiliations": [{"index": "1", "address": " Caltech, Pasadena, USA"}], "title": "Visual Search --\u00a0faster, better, spikier", "abstract": "What is the most information-efficient way to carry out visual search? What is the right trade-off between error rates and response times? What is the most economical implementation of such mechanisms? \u00a0I will present a Bayesian model of visual search that predicts both response time histograms and error rates of human subjects. The model has a very small number of free parameters representing the resolution of the visual system, the\u00a0signal to noise ratio of the stimuli and the response time vs error rate trade off. I will discuss a an\u00a0implementation of the model using a feed-forward network of spiking neurons. I will discuss trade-offs between optimality and design simplicity.", "acknowledgements": "Joint work with Bo Chen at Caltech.", "id": 7, "topic": "Computational Vision", "imagefile": "", "authors": [{"epithet": "1", "name": "Pietro Perona"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["david.fitzpatrick@mpfi.org"], "figid": 9, "doi": "10.12751/nncn.bc2013.0265", "affiliations": [{"index": "1", "address": " Max Planck Florida Institute for Neuroscience, Jupiter, Florida, USA"}], "title": "Rapid developmental changes in the patterns of population activity accompany the onset of visual experience in ferret visual cortex.", "abstract": "Early in postnatal development, at the time when experience begins to influence neural activity, visual cortex lacks the full complement of connections and the response selectivity that defines functional maturity. Studies in the ferret emphasize that visually-driven activity at this early stage is important for the construction of cortical circuits, especially those that represent stimulus motion. At the time of eye-opening, cortical neurons are weakly tuned to the direction of stimulus motion and they lack the columnar structure that characterizes the mature cortical representation.  Both response selectivity and columnar structure for motion direction emerge during the first week to 10 days after eye-opening, in a process that is dependent on visual experience.  The tuning of cortical responses for stimulus features is one measure of their functional maturity; But this measure does not assess the spatio-temporal dynamics of cortical activity that are supported by immature circuits and how these activity patterns change in response to visual experience.  In vivo imaging of calcium signals using genetically encoded calcium sensors reveals that the emergence of direction selectivity after eye opening is accompanied by dramatic changes in the dynamics of population response of layer 2/3 neurons.  Initially, visually driven responses are highly variable yet show strong correlations across the population, and frequently exhibit slow wave-like dynamics. Stimulus induced responses are orientation tuned, and they form well-defined patches which exhibit complex wave trajectories. Combined cell attached recordings and 2-photon imaging confirm that these early calcium signals are correlated with the spiking activity of layer 2/3 neurons.  With visual experience, responses become more reliable, less correlated, and the wave-like activity disappears. Several lines of evidence show that these changes in responsiveness are accompanied by significant changes in cortical inhibition. The density of parvalbumin immunoreactive GABAergic terminals in ferret visual cortex undergoes a striking increase in the first week after eye opening and there is an equally strong increase in the frequency of spontaneous inhibitory synaptic currents.  Taken together, these results suggest that the maturation of cortical direction selectivity may depend on changes in inhibitory circuits that shape the spatiotemporal structure of cortical responses. ", "acknowledgements": "", "id": 8, "topic": "Cortical Dynamics and Circuits", "imagefile": "", "authors": [{"epithet": "1", "name": "David Fitzpatrick"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["n.rochefort@ed.ac.uk"], "figid": 10, "doi": "10.12751/nncn.bc2013.0266", "affiliations": [{"index": "1", "address": " Centre for Integrative Physiology, University of Edinburgh, UK\u00a0"}], "title": "Visually-evoked calcium signalling in dendrites and spines of cortical neurons\u00a0in vivo", "abstract": "Dendritic spines arise as small protrusions from the dendritic shaft of various types of neurons and receive synaptic inputs. The individual functional properties and spatial arrangement of these synaptic inputs are critical for the processing of information by individual neurons. I am investigating the relationship between the inputs that individual neurons receive at the level of their dendrites and their specific output firing pattern.\n\nPrevious work has identified visually-evoked local dendritic calcium signals (,hot spots'; Jia, Rochefort et al., Nature, 2010) in the mouse visual cortex. However, visually-evoked signaling on the level of dendritic spines, corresponding to individual afferent excitatory synapses, remained unexplored.\n\nTo analyze spine signaling during spontaneous and visually-evoked activity in vivo, we performed two-photon imaging in combination with cell-attached recordings in layer 2/3 pyramidal neurons in the monocular region of the primary visual cortex in isoflurane-anesthetized mice. We used the LOw-power Temporal OverSampling (LOTOS) variant of two-photon microscopy that was recently shown to facilitate single spine imaging in vivo (Chen, Leichner et al., Nature, 2011). Layer 2/3 pyramidal neurons were first electroporated with a calcium dye and then targeted for cell-attached recordings. We recorded single spine calcium signals in parallel with the somatic spiking activity during spontaneous and drifting grating-evoked activity. Back-propagating spikes produced robust calcium transients throughout dendrites and spines. Importantly, we identified distinct single spine calcium signals in response to visual stimulation. Such active spines were widely distributed on basal and apical dendrites and drifting grating stimulation revealed both narrowly and widely tuned spines for the orientation and the direction of the gratings. These results provide strong support to the notion that the previously identified 'hot spots' represent single spine synaptic inputs.", "acknowledgements": "", "id": 9, "topic": "Cortical Dynamics and Circuits", "imagefile": "", "authors": [{"epithet": "1", "name": "Nathalie Rochefort"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["alfonso.renart@neuro.fchampalimaud.org"], "figid": 11, "doi": "10.12751/nncn.bc2013.0267", "affiliations": [{"index": "1", "address": " Centro Champalimaud, Lisbon, Portugal"}], "title": "Spontaneous Dynamics of Cortical Circuits during Activated States.", "abstract": "The possibility of recording the simultaneous activity of large populations of neurons within cortical circuits is opening the door to a systematic characterisation of their dynamical behaviour. I will describe our recent work quantifying the temporal structure of spontaneous population activity during states of cortical activation. The main feature of such states is the lack of slow, global activity fluctuations at the population level, which is equivalent to an almost negligible population-averaged correlation between pairs of neurons. Although such behaviour is typical or randomly connected networks in which excitation and inhibition are globally balanced, we find that the pattern of correlations in cortical circuits has a salient competitive structure, and that such structure is absent in randomly connected networks. Alternative models consistent with the data will be discussed.", "acknowledgements": "", "id": 10, "topic": "Cortical Dynamics and Circuits", "imagefile": "", "authors": [{"epithet": "1", "name": "Alfonso Renart"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["Karpovaa@janelia.hhmi.org"], "figid": 12, "doi": "10.12751/nncn.bc2013.0268", "affiliations": [{"index": "1", "address": " HHMI/Janelia Farm Research Campus, Ashburn, USA"}], "title": "Decision-making under uncertainty: Probing the neural basis of mental models", "abstract": "The overall interest of my lab is to understand how model-based inference is accomplished by neural circuits. Over the past few years we have focused on the role that the rodent medial prefrontal cortex (mPFC), an area homologous to primate anterior cingulate cortex (ACC), plays in encoding the internal representation of the rules of the environment. We have designed behavioral tasks in which these rules change suddenly or evolve in a very complex manner-in some cases eliciting abrupt changes in the workings of the internal model and in others leading to the abandonment of attempts at model construction. Recordings of the activity of neuronal ensembles in mPFC revealed that moments of abrupt change in behavioral strategy are associated with sudden transitions in the pattern of neural activity across the mPFC, one interpretation of which is that such changes signify a reset of prior expectations. In addition, inactivation of mPFC by local muscimol administration revealed that the influence of mPFC on behavior is suppressed when attempts to build an internal model are unsuccessful. In combination, our observations argue that mPFC represents an animal's beliefs about the environment's governing rules. ", "acknowledgements": "", "id": 11, "topic": "Decision Making", "imagefile": "", "authors": [{"epithet": "1", "name": "Alla Karpova"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["kepecs@cshl.edu"], "figid": 13, "doi": "10.12751/nncn.bc2013.0269", "affiliations": [{"index": "1", "address": " Cold Spring Harbor Laboratory, USA"}], "title": "Confidence: thinking about thinking or thinking about statistics and the brain", "abstract": "Decision confidence is a forecast about the correctness of one's decision. It is often regarded as a higher-order function of the brain requiring a capacity for metacognition that may be unique to humans. If confidence manifests itself to us as a feeling, how can then one identify it amongst the brain's electrical signals in an animal?\n\nWe tackle this issue by using mathematical models to gain traction on the problem of confidence, allowing us to identify neural correlates and mechanisms. I will present a normative statistical theory that enables us to establish that human self-reports of confidence are based on a computation of statistical confidence. Next, I will discuss computational algorithms that can be used to estimate confidence and decision tasks that we developed to behaviorally read out this estimate in humans and rats. Finally, I will discuss the neural basis of decision confidence and specifically the role of the orbitofrontal cortex.", "acknowledgements": "", "id": 12, "topic": "Decision Making", "imagefile": "", "authors": [{"epithet": "1", "name": "Adam Kepecs"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["brody@princeton.edu"], "figid": 14, "doi": "10.12751/nncn.bc2013.0270", "affiliations": [{"index": "1", "address": " Howard Hughes Medical Institute and Princeton Neuroscience Institute, Princeton University, USA"}], "title": "Neural substrates of decision-making", "abstract": "Gradual accumulation of evidence is thought to be a fundamental component of decision-making. Over the last 16 years, research in non-human primates has revealed neural correlates of evidence accumulation in parietal and frontal cortices, and other brain areas . However, the mechanisms underlying these neural correlates remain unknown. Reasoning that a rodent model of evidence accumulation would allow a greater number of experimental subjects, and therefore experiments, as well as facilitate the use of molecular tools, we developed a rat accumulation of evidence task, the \"Poisson Clicks\" task. In this task, sensory evidence is delivered in pulses whose precisely-controlled timing varies widely within and across trials. The resulting data are analyzed with models of evidence accumulation that use the richly detailed information of each trial's pulse timing to distinguish between different decision mechanisms. The method delivers great statistical power, allowing us to: (1) provide compelling evidence that rats are indeed capable of gradually accumulating evidence for decision-making; (2) accurately estimate multiple parameters of the decision-making process from behavioral data; and (3) measure, for the first time, the diffusion constant of the evidence accumulator, which we show to be optimal (i.e., equal to zero). In addition, the method provides a trial-by-trial, moment-by-moment estimate of the value of the accumulator, which can then be compared in awake behaving electrophysiology experiments to trial-by-trial, moment-by-moment neural firing rate measures. Based on such a comparison, we describe data and a novel analysis approach that reveals differences between parietal and frontal cortices in the neural encoding of accumulating evidence. Finally, using semi-automated training methods to produce tens of rats trained in the Poisson Clicks accumulation of evidence task, we have also used pharmacological inactivation to ask, for the first time, whether parietal and frontal cortices are required for accumulation of evidence, and we are using optogenetic methods to rapidly and transiently inactivate brain regions so as to establish precisely when, during each decision-making trial, it is that each brain region's activity is necessary for performance of the task.", "acknowledgements": "", "id": 13, "topic": "Decision Making", "imagefile": "", "authors": [{"epithet": "1", "name": "Carlos Brody"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["thomas.muench@cin.uni-tuebingen.de"], "abstract": "It is largely unknown how the ambient light level modulates the response properties of retinal ganglion cells to otherwise identical stimuli. We used multi-electrode arrays to record from ganglion cells of whole-mount mouse retinas. We characterized their responses to full-field steps of positive and negative contrast at light levels spanning scotopic, mesopic, and photopic regimes.\nThe polarity of each cell (ON, OFF) was determined by the polarity of its linear filter, obtained from responses to Gaussian white noise. Cells robustly increased spiking activity to steps of their preferred contrast (i.e. either light increments or decrements). Most ON cells were strongly suppressed by their anti-preferred stimulus, i.e. by light decrements. OFF cells had diverse responses to their anti-preferred stimulus, i.e. light increments, including short-latency suppression, short-latency responses and long-latency responses (peaking at ~170ms and ~680ms, respectively). The long-latency ON response could be preceded either by suppression or the short-latency ON response. For most OFF cells, their response pattern to light increments qualitatively depended on ambient luminance. Responses to natural movies could vary with luminance as well. Surprisingly, all OFF ganglion cells had excitatory ON responses at least at one light level. \nOur results suggest that all OFF cells receive ON input(s), which may be masked at some light levels and revealed at others. They therefore show highly varying response patterns at different light levels.\n", "topic": "Neural encoding and decoding", "id": 65537, "refs": "", "title": "Ambient luminance changes ganglion cell responses qualitatively", "imagefile": "", "affiliations": [{"index": "1", "address": "Center for Integrative Neurosciences, Bernstein Center, University T\u00fcbingen, Germany"}], "figid": 168, "altid": 196649, "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "authors": [{"epithet": "1", "name": "Alexandra Tikidji-Hamburyan"}, {"epithet": "1", "name": "Thomas A. M\u00fcnch"}], "acknowledgements": "", "doi": "10.12751/nncn.bc2013.0168", "caption": ""}, {"correspondence": ["jiankliu@gmail.com"], "abstract": "Retinal ganglion cells have to encode the visual world under different viewing conditions. When contrast changes, they show a fast dynamical change in sensitivity and temporal filtering characteristics. However, ganglion cells are often better described by multiple filter components in parallel. Here, we therefore ask whether these filter components adapt independently or whether the filters remain fixed, but their relative importance for the ganglion cell response changes. We thus study the temporal features represented in the ganglion cell responses by recording spikes from isolated axolotl retinas using a multielectrode array. We apply spike-triggered average (STA) and spike-triggered covariance (STC) analysis to determine the set of features represented by each ganglion cell under different contrast conditions. Following a switch from a low-contrast condition to one of high contrast, we found for OFF cells that the stimulus feature encoded by the STA under low contrast is preserved as the most significant feature detected by the STC analysis under high contrast. However, a second stimulus feature emerges as an additional filter component under high contrast. For ON-OFF cells with contributions from both ON and OFF pathways, on the other hand, this scheme does not hold. Rather, ON and OFF inputs are found to adapt independently. Further analysis of only those spikes that occurred in the OFF pathway recovered the observation made for pure OFF cells. A simple linear-nonlinear model with additional feedback can account for these filter changes during contrast adaptation. Together, these results suggest that contrast adaption occurs separately in ON and OFF pathways in the retina and can be described by changing the contributions from multiple parallel filtering processes.", "topic": "Neural encoding and decoding", "id": 65538, "refs": "", "title": "Spike-Triggered Analysis of Contrast Adaptation in the Retina", "imagefile": "", "affiliations": [{"index": "1", "address": "Department of Ophthalmology, University Medical Center Goettingen, 37073 Goettingen, Germany"}, {"index": "2", "address": "Bernstein Center for Computational Neuroscience Goettingen, 37073 Goettingen, Germany"}], "figid": 84, "altid": 131154, "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "authors": [{"epithet": "1,2", "name": "Jian Liu"}, {"epithet": "1,2", "name": "Tim Gollisch"}], "acknowledgements": "This work was supported by the German Initiative of Excellence, the International Human Frontier Science Program Organization, the German Ministry for Education, and the Deutsche Forschungsgemeinschaft (DFG) through the Collaborative Research Center 889.", "doi": "10.12751/nncn.bc2013.0084", "caption": ""}, {"correspondence": ["chepe@nld.ds.mpg.de"], "abstract": "Response characteristics of orientation-tuned neurons in the visual cortex appear to be similar in mammalian lineages widely separated in evolution. The spatial arrangement of preferences across the cortex, however, shows fundamental differences. While in primates and carnivores orientation preferences form orientation maps, in rodents they are spatially interspersed. The developmental processes and evolutionary origins of these two opposite layout-types remain enigmatic. Previous research in our group showed that columnar orientation maps realize a common design that naturally emerges by activity-dependent self-organization of large scale neuronal circuits when orientation selective long range interactions are present [1,2]. Here we show that cortical circuit self-organization can also explain the rodent layout type in a unified model. We demonstrate a direct transition from interspersed organization to quasi-periodic arrays of orientation columns. An interspersed organization is actively generated when local circuits are predominantly suppressive. Numerical simulations show that the final arrangement of orientations shows a weak negative correlation between nearest neighbours and that it suffers from a substantial dynamical lability of neuronal selectivities compared to columnar architectures. Interspersed layouts in general exhibit superior stimulus coverage but cause higher wiring costs to maintain a selective like-to-like connectivity. We examine models in which cortical organization is assumed to optimize a composite cost function that penalizes reductions in stimulus coverage and excessive wiring length depending on cortex size. We find a transition from interspersed layouts to columnar architecture above a critical area size. Our results suggest that neuronal circuit self-organization played a critical role in the evolution of cortical functional organization and that the invention of orientation columns was driven by the emergence of large brains.", "topic": "Neural encoding and decoding", "id": 65539, "refs": "[1] \u201cUniversality in the Evolution of Orientation Columns in the Visual Cortex\u201d, M. Kaschube et al., Science 330, 1113 (2010); 10.1126/science.1194869\n[2] Response to Comment on \u201cUniversality in the Evolution of Orientation Columns in the Visual Cortex\u201c, W. Keil et al., Science 336, 413 (2012); 10.1126/science.1206416\n", "title": "Understanding order and disorder in visual cortical circuits through self-organization", "imagefile": "", "affiliations": [{"index": "1", "address": "Max Planck Institute For Dynamics and Self-Organization, BCCN G\u00f6ttingen, Germany"}, {"index": "2", "address": "Goethe-Universit\u00e4t Frankfurt am Main, Germany"}, {"index": "3", "address": "Engineering Sciences and Applied Mathematics, Northwestern University, United States"}], "figid": 247, "altid": 196726, "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "authors": [{"epithet": "1", "name": "Juan Daniel Fl\u00f3rez Weidinger"}, {"epithet": "1", "name": "Wolfgang Keil"}, {"epithet": "2", "name": "Dmitry Tsigankov"}, {"epithet": "3", "name": "Michael Schnabel"}, {"epithet": "2", "name": "Matthias Kaschube"}, {"epithet": "1", "name": "Fred Wolf"}], "acknowledgements": "", "doi": "10.12751/nncn.bc2013.0247", "caption": ""}, {"correspondence": ["vmehrpour@dpz.eu"], "abstract": "Area MT of extrastriate visual cortex plays a prominent role in processing and perception of visual motion. The response of MT cells is enhanced by allocation of spatial attention to their receptive fields (RFs). Such modulation is typically assessed with a paradigm where the animal has to report a change in a moving visual stimulus and a comparison of the responses before the change in different attentional conditions. The present study instead focuses on MT responses around the transient change. \nNeural responses of MT neurons from two rhesus monkeys were recorded while they performed a direction change detection task: while the animal touched a lever and maintained its gaze on a central fixation point, a static random dot pattern (RDP) was shown either inside or outside the RF of the neuron, cueing the animal as to the target\u2019s location in the upcoming trial. Subsequently, two RDPs moving in one of 12 directions were simultaneously presented inside and outside the RF. After a random time the target or distracter direction changed by 25\u00b0 for 200ms. The animal indicated a target direction change by releasing the lever and had to ignore changes of the distracter. \nThe MT population response we recorded accurately represents the stimulus direction before the change, with a stronger response when the target is inside the RF. However, the population response profile indicates that the transient direction change in the RF is overestimated by about 8\u00b0 and 13\u00b0 for distracter and target stimuli, respectively. \nOur data demonstrate that the magnitude of abrupt changes in the direction of moving stimuli is exaggerated in MT and that this overestimation is almost twice as high for attended vs. unattended stimuli. Thus the saliency of such stimulus changes is enhanced in MT. This finding provides evidence that the role of attention is not only to increase the strength and accuracy of an attended stimulus\u2019 representation but also to strengthen the saliency of a change.", "topic": "Neural encoding and decoding", "id": 65540, "refs": "", "title": "Saliency enhancement by attention in area MT of the visual cortex of rhesus monkeys", "imagefile": "", "affiliations": [{"index": "1", "address": "Cognitive Neuroscience Laboratory, German Primate Center, Kellnerweg 4, 37077 G\u00f6ttingen, Germany"}, {"index": "2", "address": "Cognitive Neurophysiology Laboratory, Dept. of Physiology, McGill University, 3655 Prom Sir. W. Osler, Montreal QC H3G 1 Y6, Canada"}], "figid": 222, "altid": 196702, "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "authors": [{"epithet": "1", "name": "Vahid Mehrpour"}, {"epithet": "2", "name": "Julio C. Martinez-Trujillo"}, {"epithet": "1", "name": "Stefan Treue"}], "acknowledgements": "Supported by the Federal Ministry of Education and Research (BMBF) Germany under grant number 01GQ1005C.\n", "doi": "10.12751/nncn.bc2013.0222", "caption": ""}, {"correspondence": ["julie@ph.tum.de"], "figid": 224, "doi": "10.12751/nncn.bc2013.0224", "affiliations": [{"index": "1", "address": "Physik Department T35, TU M\u00fcnchen, Germany"}, {"index": "2", "address": "Dept. of Psychology, Hunter College, New York, United States"}], "title": "Multimodal integration allows the Mauthner cells to induce a fast escape", "abstract": "How to avoid a collision or, more usual in nature, an attack? And how to take the right decision to escape very fast? Multimodal integration of perceptive input is a key element of many behavioral decisions. For example, fish react with a fast (8-10 ms) directional escape response and, in doing so, need to detect the direction of an attack unambiguously. They manage this with high probability through a pair of brainstem neurons, the so-called Mauthner cells (M cells), which evolution has devised to induce the correct C-start. Extensive experimental research has shown that integration of acoustical-vestibular and lateral-line input is essential. Though the vestibular (saccule) input to both M cells is equal, because the pressure difference between both sides is not measurable, it is near the M-cell threshold. Conversely, the lateral-line input is relatively low but has different arrival times at the left and right M cell whereas left and right lateral-line inputs differ to a large extent. \n \nWe have developed a model of the two M cells (detailed compartmental modeling done with Neuron) with three synaptic-current inputs modeling the vestibular and the left and right lateral-line input from the posterior VIIIth nerve. Moreover, we have simulated PHP (passive hyperpolarizing potential) inhibitory interneurons, which ensure that only one M cell fires. This model shows that a fast and correct left-right discrimination is possible due to the multimodal integration performed by the M cells. We have studied the effects of changing duration and form of the inputs as well as the time difference between lateral-line input to the left and the right M cell and between the lateral-line and the vestibular input as well as changing duration and form of the inputs on directional discrimination. Furthermore, we have investigated the role of inhibition.\n", "acknowledgements": "", "id": 65541, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Julie Goulet"}, {"epithet": "1", "name": "Johanna Kipping"}, {"epithet": "2", "name": "Thomas Preuss"}, {"epithet": "1", "name": "J. Leo van Hemmen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["champvectoriel@hotmail.com"], "doi": "10.12751/nncn.bc2013.0011", "affiliations": [{"index": "1", "address": "University of Geneva, Switzerland"}, {"index": "2", "address": "University of Rochester, United States"}], "title": "Learning non-linear probabilistic computations in recurrent spiking networks", "abstract": "Cortical networks are known to perform canonical operations, like exponentiation, linear filtering, and normalization; key modular tasks combined by the sensory cortices to build accurate input representations [1].  According to the paradigm of probabilistic population codes(PPCs)[2], these form the basis of more complex probabilistic computations, like multisensory integration and marginalization[3], that operate on neural codes representing probability distributions. Previous work using PPCs has demonstrated how some of these computations can be implemented in biological neural networks, but only at the population scale. Moreover, the issue of learning has been largely ignored. To address these issues, we propose a computational framework designed to explore the ways in which fully recurrent spiking networks can learn to perform probabilistic computations. Specifically, we show that a variation of the STDP learning rule can be used to train a recurrent network to perform near-optimal probabilistic computations using spike response models [4].  The algorithm first generates population response patterns that correspond to a target posterior reflecting the operation of interest.  Along with input patterns of activity, this output pattern is used as a training signal to learn feedforward and recurrent weight matrices.  To test our method, we considered a simple task: cue combination, where the activity of two populations is summed probabilistically to preserve information [2].  Our simulations confirmed that the trained network can learn non trivial connectivity matrices to perform cue integration with near zero loss of information.", "acknowledgements": "", "id": 65542, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "J\u00e9r\u00e9mie Lefebvre"}, {"epithet": "1", "name": "Alexandre Pouget"}, {"epithet": "2", "name": "Jeff Beck"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Figure 1. a) Optimal connectivity matrices for the multisensory integration task. Given proper training, the network learns feedfoward (W, M) and recurrent (K) coupling weights in order to maximize information transmission about the stimulus between input and output layers. The arrow indicates information flow. For this example, the input layer consists of two populations of 20 LNP cells each responding to various angles with a maximal rate of 100Hz, and projecting to the output population, built of 100 cells that evolve according to a non-linear spike response model. Spike transmission between input and output layer is instantaneous, but recurrent connections display a delay of 10ms.  b) Spike count distribution of the output layer responding to the angle $\\theta=\\pi$. Shown is the training network (red line) response and the associated teaching signal (gray area) used for likelihood maximization. c) Information loss as a function of the redundancy index, defined as the ratio of cells present in the output population versus those contained in the input layer. ", "figpath": "011.png", "refs": "[1] M. Carandini & D.J. Heeger, Normalization as a canonical neural computation, Nature Reviews Neuroscience 13: 51-62, 2012\n[2] W.J. Ma et al. Bayesian inference with probabilistic population codes, Nature Neuroscience, 9: 1432-1438 , 2006\n[3] J.M. Beck et al. Marginalization in Neural Circuits with Divisive Normalization, The Journal of Neuroscience, 31(43): 15310-15319, 2011\n[4] W. Gerstner and W. M. Kistler, Spiking Neuron Models, Cambridge University Press, 2002"}, {"correspondence": ["moritz.deger@epfl.ch"], "abstract": "Local neuronal circuits in the neocortex consist of hundreds of neurons [1]. These neurons typically show refractoriness after emitting an action potential (spike), and accumulating refractory effects result in adaptation on multiple time scales [3]. Both finite network size and neuronal adaptation make it difficult to derive population dynamics using traditional, stochastic process approaches. Here we present a novel theory of the population activity of finite-sized, randomly connected networks of spiking neurons with adaptation, which is obtained by approximating neuronal spike emission by a quasi-renewal process [2]. Our theory describes the average firing rate and its spectral density in coupled networks, exemplified for the typical case of a network of excitatory and inhibitory neurons. Furthermore, we show how correlated noise influences the stationary population activity, and how it can contribute to synchronize or desynchronize neuronal circuits. ", "topic": "Neural encoding and decoding", "id": 65543, "refs": "[1] S. Lefort, C. Tomm, J.-C. F. Sarria, and C. C. H. Petersen. Neuron 61(2):301\u2013316, (2009).\n[2] R. Naud and W. Gerstner. PLoS Comput Biol, 8(10):e1002711, (2012).\n[3] C. A. Pozzorini, R. Naud, S. Mensi, and W. Gerstner. Nat Neurosci, (2013). in press.", "title": "Network dynamics of spiking neurons with adaptation", "imagefile": "", "affiliations": [{"index": "1", "address": "School of Life Sciences, Brain Mind Institute and School of Computer and Communication Sciences, Ecole polytechnique federale de Lausanne, Switzerland"}, {"index": "2", "address": "Department of Physics, University of Ottawa, Canada"}], "figid": 74, "altid": 131143, "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "authors": [{"epithet": "1", "name": "Moritz Deger"}, {"epithet": "1", "name": "Tilo Schwalger"}, {"epithet": "2", "name": "Richard Naud"}, {"epithet": "1", "name": "Wulfram Gerstner"}], "acknowledgements": "Research was supported by the European Research Council (no. 268 689; MultiRules: Synaptic multi-factor learning rules: from action potentials to behaviour) and by the European Community's Seventh Framework Program (grant agreement no. 269921, BrainScaleS).\n", "doi": "10.12751/nncn.bc2013.0074", "caption": ""}, {"correspondence": ["andrea.burgalossi@bccn-berlin.de"], "figid": 29, "doi": "10.12751/nncn.bc2013.0029", "affiliations": [{"index": "1", "address": "BCCN Berlin, Germany"}], "title": "Structural Determinants of Spatial Representations in Layer 2 of Medial Entorhinal Cortex", "abstract": "Medial Entorhinal Cortex (MEC) is a key structure contributing to spatial information processing. In superficial layers of MEC, extracellular recordings show spatial discharge patterns such as grid, head-direction and border cells, which may help generating a cognitive map of the environment. \nA subset of pyramidal principal neurons in L2 MEC with calbindin immunoreactivity (Cb+) is clustered in patches and is--as we recently observed--arranged in a hexagonal pattern. These pyramidal neurons receive selective cholinergic innervation and earlier work has shown that these pyramidal cells differ in intrinsic properties and projection patterns from L2 stellate cells. These findings made us wonder how the unique physiology and anatomy of calbindin positive pyramidal cells and stellate cells relate to the functional diversity in L2 MEC neurons.\nTo address this question, we optimized our juxtacellular recording technique in freely moving rats trained to explore open-field environments. This technique enables us to record and label multiple cells per animal, which were classified by Cb immunofluorescence. \nPreliminary results show that Cb- neurons comprise a functional heterogeneous population of border cells, band cells, head-direction cells and not spatially modulated cells. Because we did not obtain enough Cb+ cell recordings with sufficient spatial coverage, we cannot yet assess their spatial discharge patterns. Strikingly, while spike trains in only few (2 out of 13) of the Cb- neurons were theta modulated, most (3 out 4) Cb+ neurons were strongly theta modulated. This data was consistent with results obtained under urethane-anesthesia, where Cb+ cells were also more strongly entrained to theta rhythmicity. In summary, our preliminary results suggest that Cb+ neurons might represent a unique subpopulation of rhythmically discharging layer 2 neurons in vivo. We wonder if grid cells are recruited from this population, and we are currently testing this hypothesis.", "acknowledgements": "", "id": 65544, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Andrea Burgalossi"}, {"epithet": "1", "name": "Qiusong Tang"}, {"epithet": "1", "name": "Saikat Ray"}, {"epithet": "1", "name": "Robert Naumann"}, {"epithet": "1", "name": "Helene Schmidt"}, {"epithet": "1", "name": "Michael Brecht"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["wimmer.klaus@gmail.com"], "altid": 196677, "abstract": "Single neuron variability is correlated with variability in perceptual decisions [1]. This relationship can be quantified by choice probability (CP) and has commonly been interpreted as evidence for correlated noise in sensory circuits biasing decisions [2]. However, while choice probability is typically sustained throughout the trial, the impact of stimulus fluctuations on the decision decreases over time, questioning the causal role of fluctuations on the decision [3,4]. Here, we address this paradox while seeking a unified understanding of how stimulus, neuronal, and behavioral fluctuations give rise to correlations and CP in plausible cortical circuits. We developed a network model of a sensory (MT) and a decision circuit with attractor dynamics (LIP). If identical stimuli were used, the average correlation between neurons could be very small - despite substantial shared input - yielding chance-level CPs. Stimulus fluctuations gave rise to spurious correlations which caused significant CP early in the trial. Adding top-down connections between LIP and MT could parsimoniously reproduce the experimentally observed sustained time-course of CPs. The model makes several predictions which we confirmed in the data from a classical experiment [1,5]: (1) Stimulus fluctuations substantially increased the variability of MT neurons measured by the Fano factor. (2) Average CP exhibited a significant reduction in the early part for identical stimuli. (3) Choice-conditioned correlations for preferred choice trials decreased throughout the trial. (4) CP time courses of single neurons were heterogeneous and consistent with an underlying bottom-up and top-down component. Our findings suggest that correlations and CP in MT can partly be attributed to stimulus fluctuations and variability of top-down signals reflecting the upcoming decision. The model prompts for a revision of the potential sources of correlations in sensory circuits.", "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Klaus Wimmer"}, {"epithet": "1", "name": "Albert Compte"}, {"epithet": "2", "name": "Alex Roxin"}, {"epithet": "3", "name": "Alfonso Renart"}, {"epithet": "1", "name": "Jaime de la Rocha"}], "acknowledgements": "IRG, EU Marie Curie Action, PIRG07-GA-2010-268382\nMINECO Grant SAF2010-15730\nDFG Research Fellowship WI3767/1-1\nMINECO Grant BFU2009-09537\n", "id": 65545, "doi": "10.12751/nncn.bc2013.0197", "title": "Stimulus fluctuations together with top-down feedback can account for the dynamics of choice probabilities in MT", "affiliations": [{"index": "1", "address": "IDIBAPS, Spain"}, {"index": "2", "address": "CRM, Spain"}, {"index": "3", "address": "Champalimaud Neurosci Programme, Portugal"}], "caption": "Pair-wise correlations and Choice Probabilities in MT can partly be attributed to (1) stimulus fluctuations and (2) variability of top-down signals reflecting decision building. They do not seem to be due to shared inputs. Stimulus fluctuations and top-down signals impact the CP with different temporal profiles but on a common underlying timescale determined by the dynamics of the decision process. Thus, they can be combined to obtain sustained CP.", "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "figpath": "197.jpeg", "refs": "[1] Britten, K. H., Newsome, W. T., Shadlen, M. N., Celebrini, S. & Movshon, J. A., Vis Neurosci (1996).\n[2] Shadlen, M. N., Britten, K. H., Newsome, W. T. & Movshon, J. A., J Neurosci (1996).\n[3] Kiani, R., Hanks, T. D. & Shadlen, M. N., J Neurosci (2008). doi:10.1523/JNEUROSCI.4761-07.2008\n[4] Nienborg, H. & Cumming, B. G., Nature (2009). doi:10.1038/nature07821\n[5] Zohary, E., Shadlen, M. N. & Newsome, W. T., Nature (1994)."}, {"correspondence": ["kaikazuki@fukuoka-u.ac.jp"], "figid": 1, "doi": "10.12751/nncn.bc2013.0001", "affiliations": [{"index": "1", "address": "Department of Earth System Science, Fukuoka University, Japan"}, {"index": "2", "address": "School of Human Science and Environment, University of Hyogo, Japan"}, {"index": "3", "address": "RCAST, The University of Tokyo, Japan"}, {"index": "4", "address": "Department of Biology II, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Planegg-Martinsried, Germany"}], "title": "Response properties of auditory interneurons in the honeybee brain", "abstract": "Honeybees perform a symbolic waggle dance to inform their nest-mates of distance and direction of food source [1].  In the waggle run, the dancer swings its abdomen side-by-side and generates air-borne vibratory signal by wing-beats that consists of roughly 30 Hz pulses of 20 ms duration with carrier frequency of about 265 Hz. The followers (receivers of the waggle dance communication) detect these vibratory signals with Johnston\u2019s organ (JO) in the pedicel of antenna. The mechanical movements of the flagellum are transduced into spike activity of sensory neurons and the vibratory signals are transferred to the auditory center in the brain. However, the neural processing of these signals and how the properties of the vibration signals are encoded in the auditory system is largely unknown. We studied vibration sensitive interneurons in the auditory center of the honeybee brain (dorsal lobe) electrophysiologically by single cell recordings and staining. Neural activities were recorded in restrained honeybee and vibratory stimuli were delivered to flagellum with a piezoelectric  device within the range from 100 to 400Hz.\nAmong more than 40 types of vibration sensitive interneurons in the dorsal lobe, 2 interneurons, the so-called DL-Int-1 [2] and a newly identified interneuron, showed spike discharges corresponding to the temporal pattern of the vibration pulses which mimicked the waggle dance sound. These neurons showed on-phasic excitation to continuous vibration stimulus of 265 Hz. When depolarizing current was injected, these neurons showed inhibitory responses to continuous vibration stimuli.\nOur results suggest the putative neural circuit of honeybee auditory system; the air-borne pulse vibration in the waggle dance can be encoded in the timing of spike discharges of specific interneurons by means of coordinated excitatory and inhibitory inputs to these interneurons.\n", "acknowledgements": "Supported by the Japan Science and Technology Agency (JST) and the Federal Ministry of Education and Research (Grant 01GQ1116)", "id": 131073, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Kazuki Kai"}, {"epithet": "2", "name": "Hidetoshi Ikeno"}, {"epithet": "3", "name": "Stephan S. Haupt"}, {"epithet": "4", "name": "Philipp L. Rautenberg"}, {"epithet": "4", "name": "Thomas Wachtler"}, {"epithet": "1", "name": "Hiroyuki Ai"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] von Frisch K (1967) The tail-wagging dance as a means of communication when food source are distant. In von Frisch K, editor. The dance language and orientation of bees. Cambridge, MA: Belknap Press of Harvard University Press. pp. 57-235.\n[2] Ai H, Itoh T (2012) The auditory system of the honey bee. In: Honeybee Neurobiology and Behavior (Eds. G.C. Galizia, D. Eisenhardt, and M. Giurfa), pp. 269-284."}, {"correspondence": ["Carlos.Carvajal@inria.fr"], "figid": 2, "doi": "10.12751/nncn.bc2013.0002", "affiliations": [{"index": "1", "address": "Inria Research Center, Bordeaux, France"}, {"index": "2", "address": "LORIA, Universit\u00e9 de Lorraine, Nancy, France"}, {"index": "3", "address": "Inria Research Center, LaBRI and IMN, Bordeaux, France"}], "title": "To flee or not to flee? Neural Field dynamics shape information flows in a model of the thalamocortical visual system ", "abstract": "Pre-processed motion information has been reported to trigger active exploration responses (tracking, pursuit) or the opposite (avoidance) (1,2). Two thalamic information flows (the Magno and Koniocellular pathways) carry this information, directly to the superior colliculus for rapid reaction and via the cortex where they are integrated. The former thalamic pathway has been broadly studied, whilst the latter lacks understanding.\nTo address this question, we study the responses to motion information in a reduced bio-inspired computational model (10), emulating the thalamo-cortico-collicular visual system of mammals. This model integrates knowledge about the properties of both pathways (6) and is based on known projections between these structures (4,8). Its cortical and collicular maps are implemented with Dynamic Neural Fields (DNF) (7). We study how from such local operators emerge decisions corresponding to complex behaviors (9), such as to approach or to flee.\nThe analysis of the responses of the model to image sequences, resulting from the interplay between the dynamics of the DNFs, yields interesting phenomena. Thanks to the Konio pathway (3), providing raw information about the identity of the stimulus (threat/target), the superior colliculus may choose the upcoming behavior (to flee in presence of a threat), while the cortical mechanisms modulate this rudimentary sensory-motor loop. Such detection is based on two functional interacting ingredients: 1) The capability of the retina to provide coarse, rapid visual event detection (e.g. a looming motion expected to correspond to an approaching target), thus a-priori \"assumptions\" about the visual surroundings. 2) The algorithmic capability of dual kinds of connectivity of the thalamic neurons (precise/diffuse connectivity standing for core/matrix (5)) to treat, in sequence, different perceptual hypotheses. Our modeling and related numerical experiments demonstrate the functionality of such dual mechanism.", "acknowledgements": "This work is supported by the ANR/CONICYT KEOpS project, the Lorraine Region and the CORTINA associated team.", "id": 131074, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Carlos Carvajal"}, {"epithet": "1", "name": "Thierry Vi\u00e9ville"}, {"epithet": "3", "name": "Fr\u00e9d\u00e9ric Alexandre"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1) 10.1016/0166-2236(89)90052-0\n2) 10.1523/JNEUROSCI.2924-12.2013\n3) 10.1146/annurev.neuro.23.1.127\n4) 10.1038/nrn2619\n5) 10.1098/rstb.2002.1168\n6) 10.1098/rstb.2002.1161\n7) 10.3109/0954898X.2012.721573\n8) 10.1016/j.pneurobio.2005.11.001\n9) 10.1016/j.tics.2005.03.012\n10) C. Carvajal, T. Vi\u00e9ville and F. Alexandre. Impact of the Konio pathway in the thalamocortical visual system: a modeling study. CNS*2013, Paris"}, {"correspondence": ["arne.f.meyer@uni-oldenburg.de"], "figid": 3, "doi": "10.12751/nncn.bc2013.0003", "affiliations": [{"index": "1", "address": "Institute of Physics, Carl von Ossietzky University Oldenburg, Oldenburg, Germany"}, {"index": "2", "address": "Leibniz Institute for Neurobiology, Magdeburg, Germany"}, {"index": "3", "address": "Institute of Physics, Carl von Ossietzky University Oldenburg, Germany"}], "title": "Towards on-line estimation of non-Gaussian stimulus receptive fields using large-margin classification", "abstract": "The integration of stimulus features by sensory neurons is usually investigated by means of the receptive field (RF), the linear part of a combined linear-nonlinear model relating the presented stimulus to the evoked response. Traditional RF estimation methods like the spike-triggered average (STA, [1]) assume a linear stimulus-response relation and result in biased estimates for non-Gaussian stimulus ensembles. Recently, a class of semi-parametric divergence-based approaches have been developed to obtain theoretically unbiased kernel estimates independent of stimulus statistics and neural nonlinearity at the expense of non-convex objective functions [2].\n\nHere, we present an approach that learns RFs from binary spike decisions. It is assumed that spikes are generated from projections onto a linear kernel by a noisy threshold operation. The model is determined by the decision rule that optimally separates stimulus examples that elicited a spike from all non-elciting examples in a high-dimensional stimulus space [3]. We present a method that seeks to minimize the risk of misclassifying stimulus examples and show that this approach is similar to maximization of mutual information between stimulus and response.\n\nUsing simulated responses we demonstrate that this approach is robust to asymmetric stimulus distributions and second- and even higher-order correlations in the stimulus ensemble. These findings are validated using recordings from the inferior colliculus in gerbils for responses to highly non-Gaussian stimuli. In the large data regime the proposed approach performs equal to information-theoretic estimators with the benefit of much better convergence properties. Furthermore, convexity of the objective function allows approximate solutions using stochastic gradient descent. The obtained RF estimates are highly correlated with the full solution while requiring only a small fraction of the time, enabling this approach to monitor RF properties during experiments.", "acknowledgements": "The work was supported by the DFG SFB/TRR 31 \"The active auditory system\"", "id": 131075, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Arne F. Meyer"}, {"epithet": "2", "name": "Jan-Philipp Diepenbrock"}, {"epithet": "2", "name": "Frank W. Ohl"}, {"epithet": "3", "name": "J\u00f6rn Anem\u00fcller"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] EJ Chichilnisky: A simple white noise analysis of neuronal light responses. Network, Systems Neurobiology, 2001, 12, 199-213.\n[2] T Sharpee, NC Rust & W Bialek: Analyzing neural responses to natural signals: maximally informative dimensions. Neural Computation, 2004, 16, 223-250.\n[3] AF Meyer, MFK Happel, FW Ohl & J Anemueller: Estimation of spectro-temporal receptive fields based on linear support vector machine classification BMC Neuroscience, 2009, 10, P147."}, {"correspondence": ["andrea.carbone@univ-paris8.fr"], "doi": "10.12751/nncn.bc2013.0004", "affiliations": [{"index": "1", "address": "Universit\u00e9 Paris 8 Vincennes, France"}], "title": "The motion gist is a predictor of eye movements", "abstract": " Motion is known to play a significant role in capturing eye fixations and recent saliency\nmodels have incorporated it as relevant feature.\n\nYet in particularly dynamic setups (like in first person-viewed video-games) the player is\npresented with a complex motion field, which is determined by her control strategy.\nIn this case the whole optical flow pattern configuration (motion scene gist) can be better predictive than motion features at pixel locations.\n\nWe suggest that the motion gist is a suitable cue for this category of dynamic stimuli\nand can explain fixation distribution and be used to produce plausible  saliency maps.\n\nThe assumption is that scenes with common global motion properties  also share a common distribution of fixations. We formulate this dynamics as a supervised learning problem where the function lo learn is a multivariate  kernel regression between the motion gist space and the target space of fixation densities.\n\nWe introduce the Histogram of Motion Field Orientations (HMFO) to capture the global\nmotion pattern and explore three different kernel methods to compute the mapping: Kernel Partial Least Squares, Kernel Ridge Regression and the Nadaraya-Watson regression.\n\nResults show that the motion-gist performs  better than chance in the prediction of fixated regions on unseen stimuli and get a NSS score significantly higher than a control predictor learned on the dataset.\n\nSo, if it is true that we look at what we need or what draws our attention and  that fixated\nimage regions correlate with local low- and high-level features that can then be incorporated in computational models of visual attention, it is as well true that global scene information and eye movement patterns can improve the overall understanding of the subject activity and characterize its behaviour in response to external stimuli and task context.\n", "acknowledgements": "", "id": 131076, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Andrea Carbone"}, {"epithet": "1", "name": "Thierry Baccino"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Three snapshots from different clips. From left to right and from top to bottom for each\nvideo we display the original frame with the heatmap overlaid, the motion flow, the true discretized fixation density and the predicted fixation density.", "figpath": "004.png", "refs": ""}, {"correspondence": ["katrin_fr88@gmx.de"], "figid": 5, "doi": "10.12751/nncn.bc2013.0005", "affiliations": [{"index": "1", "address": "Centre for Integrative Neuroscience (CIN), Institute for Ophthalmic Research, Graduate Training Centre of Neuroscience, University of T\u00fcbingen, Germany"}, {"index": "2", "address": "Centre for Integrative Neuroscience (CIN), Institute for Ophthalmic Research, Bernstein Center for Computational Neuroscience (BCCN), University of T\u00fcbingen, Germany"}], "title": "Dendritic integration in mouse retinal ganglion cells", "abstract": "The retina is a powerful image processor that sequentially decomposes spatio-temporal photoreceptor activation patterns into increasingly specific parallel channels. Modulations of the channels in the retina\u2019s two synaptic layers give rise to highly specific visual features present in the output of retinal ganglion cells (RGCs). How the RGC type-specific response profiles are generated from the dendritic integration of bipolar cell (BC) inputs is still not fully understood.\nBased on earlier work[1], we have developed a technique to sparsely label individual retinal neurons with synthetic calcium indicators in the ex vivo intact retina, preserving full connectivity. Using 2P imaging we measure Ca2+ changes within BC presynaptic terminals and RGC dendrites in response to visual stimuli. This allows us to gain detailed insight into how visual input from BCs is processed and integrated within RGC dendrites to ultimately yield the distinct response properties observed at the level of the RGC spike output.\nUsing spatio-temporally modulated stimuli, single BC terminals[2] as well as activity hotspots on RGC dendrites, presumably representing sites of synaptic input, can be reliably resolved by our imaging technique. We find that spatial receptive fields (RFs) of various dendritic locations differ in size, location and their spatial structure, consistent with the morphology of the RGC dendritic arbor. Dendritic segments further from the soma systematically exhibit smaller RFs until BC RF sizes are reached for the very distal segments. When applying frequency/contrast modulated full-field stimuli, different temporal properties can be identified in the dendritic input of distinct RGC types, presumably representing the input of different BC types.\nIn conclusion, spatial integration in RGC dendrites can be studied at the resolution of single BCs using 2P Ca2+ imaging. This technique will allow studying principles of synaptic integration in the inner retina in great detail.\n", "acknowledgements": "Centre for Integrative Neuroscience (DFG EXC307), T\u00fcbingen; Bernstein Centre for Computational Neuroscience T\u00fcbingen (BMBF FKZ 01GQ1002); Baden-W\u00fcrttemberg Stiftung (AZ 1.16101.09); fort\u00fcne program, Medical Faculty of the University T\u00fcbingen.", "id": 131077, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Katrin Franke"}, {"epithet": "2", "name": "Thomas Euler"}, {"epithet": "2", "name": "Tom Baden"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Briggman KL, Euler T (2011) J Neurophysiol 105(5):2601-9.\n[2] Baden T, Berens P, Bethge M, Euler T (2013) Curr Biol 23(1):48-52.\n"}, {"correspondence": ["didem.korkmaz@tuebingen.mpg.de"], "figid": 6, "doi": "10.12751/nncn.bc2013.0006", "affiliations": [{"index": "1", "address": "Vision & Cognition Lab, Centre for Integrative Neuroscience (CIN), University of T\u00fcbingen, Germany"}], "title": "Viewing of Natural Scenes: are scene-processing regions responsive to visual motion?", "abstract": "The vast majority of prior studies on scene processing are based on stationary scenes. Therefore, brain regions responsive to visual scenes have not been studied in context of visual motion, even though self-motion during natural behavior frequently induces retinal scene-motion. Regions involved in scene processing typically involve the parahippocampal place area (PPA) [1], the retrosplenial cortex (RSC), and transverse occipital sulcus (TOS) [2]. Some evidence suggests that PPA responses differentiate between different views of the same scene, while those of RSC are more viewpoint independent but distinguish between distinct scenes [3]. \n    In this study we used fMRI to examine to which extent responses of regions involved in scene processing are modulated by visual motion as a function of scene content. We designed stimuli according to a 2x2 factorial design with the factors 2D planar motion (on/off), and scene content (gray scale landscape and cityscape scenes or Fourier scrambled versions of these scenes).  To balance attention across all conditions, subjects performed a central character matching task at all times. We performed GLM whole-brain analyses as well as region of interest (ROI) analyses.  Scene related regions were identified using a dedicated localizer scan. \nWe found that PPA and TOS showed a significant interaction effect: they responded more to motion (vs. still) in context of scenes compared to the context of scrambled scenes. This effect was not found in RSC, even though all three regions responded significantly to scene vs. scrambled. PPA and TOS also showed a main effect of motion. We conclude that PPA and TOS are specifically sensitive to motion of meaningful scenes, whereas RSC is either not modulated by motion, or in a non-specific or content-independent way. \nFurther studies in order to investigate the effects of motion speed, as well as eye movements are going to be conducted.", "acknowledgements": "", "id": 131078, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Didem Korkmaz Hacialihafiz"}, {"epithet": "1", "name": "Andreas Bartels"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1.    Epstein R, Harris A, Stanley D, Kanwisher N. The parahippocampal place area, recognition, navigation or encoding?. Neuron 23, 115\u2013125  (1999).\n2.    Nasr S, Liu N, Devaney KJ,Yue X, Rajimehr R, Ungerleider LG, Tootell RBH. Scene-selective cortical regions in human and nonhuman primates. J. Neurosci. 31, 13771-13785 (2011). \n3.    Park S, Chun M M. Different roles of the parahippocampal place area (PPA) and retrosplenial cortex (RSC) in panoramic scene perception. Neuroimage, 47,1747\u20131756 (2009)."}, {"correspondence": ["irinaburciu31@gmail.com"], "figid": 7, "doi": "10.12751/nncn.bc2013.0007", "affiliations": [{"index": "1", "address": "Institute for Neuro- and Bioinformatics, University of L\u00fcbeck, Germany"}], "title": "Manifold Sensing for Face Recognition", "abstract": "We present a new method for sequential sensing that localizes data points on manifolds of increasing dimension, thereby limiting the total number of samples required to solve a particular recognition task. The method involves a two-fold adaptation process: (i) the algorithm adapts to particular data sets, and (ii) every new sample depends on the previously acquired samples. \n\nNatural images are sparse and lie on low-dimensional manifolds. For a given data set, we first learn a manifold of dimension N, typically 2 or 3, by using Locally Linear Embedding (LLE) [1].  Any new data point is first projected to this manifold by using the pseudo-inverse matrix that minimizes the mean projection error on the whole data set. By using the location of the projected point, we define a neighborhood, and by that a subset of the original data set, which is then embedded in a higher dimension N+1. The process is iterated up to a dimension N+M yielding a total number of 1/2(M+1)(2N+M) samples. Any new sample depends on the previous ones by the transfer of neighborhoods. The parameters are the number of neighbors in the LLE algorithm, the (decreasing) size of the transferred neighborhoods, and the dimension N. \n\nWe evaluated our algorithm on a face database with 20 different persons at different poses and a total of 1000 images of size 256x256. To evaluate the performance of the algorithm we computed (i) the Signal to Noise Ratio (SNR) between the test images and the corresponding nearest images, and (ii) the person-classification performance. With only 30 samples, i.e. a compression ratio > 2000, we obtained an average SNR of 22.70 dB (the best possible SNR is 22.73 dB, PCA with 30 components yields 22.60 dB) and a 100% recognition rate. With 3 samples, the classification rate is 75%. \n\nWe expect these results to provide new insights in explaining visual processes such as retinal and cortical projections [2], peripheral vision, gist, and eye movements.", "acknowledgements": "The research is funded by the DFG Priority Programme SPP 1527, grant number MA 2401/2-1.", "id": 131079, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Irina Burciu"}, {"epithet": "1", "name": "Adrian Ion-Margineanu"}, {"epithet": "1", "name": "Thomas Martinetz"}, {"epithet": "1", "name": "Erhardt Barth"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] S. Roweis, and L. Saul, Nonlinear dimensionality reduction by locally linear embedding. In Science, volume 290(5500), pages 2323-2326, 2000.\n\n[2] W. Coulter, C. Hillar, G. Isley, and F. Sommer. Adaptive compressed sensing: A new class of self-organizing coding models for neuroscience. In IEEE International Conference on Acoustics Speech and Signal Processing, volume 5370, pages 5494-5497, 2010."}, {"correspondence": ["jurgis.pods@iwr.uni-heidelberg.de"], "doi": "10.12751/nncn.bc2013.0008", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Heidelberg-Mannheim, Germany"}], "title": "Models of Axon and Surrounding Extracellular Space - Numerical Simulation of LFP Generation", "abstract": "In Computational Neuroscience, computer simulations have established as a useful tool to accompany electrophysiological experiments to study brain function. Cable equation models based on the seminal work of Hodgkin and Huxley [1], implemented in simulators like NEURON or GENESIS, are now widely used by experimentalists and theoreticians alike.\n\nHowever, those models do not include the extracellular space. As the focus in Neuroscience has shifted from the properties of single cells towards networks of cells, one is mainly interested in aggregate extracellular signals called Local Field Potentials (LFPs), representing the joint activity of a (possibly large) number of cells, and the interpretation of those. There exist models that try to approximate the extracellular signal from the membrane currents of the single cells, but there has not yet established a self-consistent model which enables the direct simulation of electric potential intra- and extracellularly.\n\nWe present a three-dimensional mathematical model of an axon surrounded by extracellular fluid based on the Poisson-Nernst-Planck equations of electrodiffusion. The flow of different ions (Na, K, Cl) within the fluids as well as across the cell membrane is simulated numerically, directly yielding the electric potential at any point in space. Results [1] show that the model is able to reproduce crucial qualitative features of experimental measurements. Comparisons with a popular reduced model for the extracellular potential - the line source approximation (LSA) [2] - shows significant deviations. We found a second component next to membrane currents contributing to the extracellular potential, the electric field of the intracellular action potential spreading into extracellular space.", "acknowledgements": "We thank Prof. Andreas Draguhn and Dr. Martin Both for fruitful discussions and information about extracellular signals in slice recordings.\nThis work was funded through a grant from the German Ministry of Education and Research (BMBF No. 01GQ1003A).", "id": 131080, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Jurgis Pods"}, {"epithet": "1", "name": "Peter Bastian"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Simulated extracellular potential at various distances from the membrane during the course of an action potential traveling along the axon. The signal shows three major components: A peak followed by a trough and a second, less pronounced peak. It rapidly attenuates with distance.", "figpath": "008.png", "refs": "[1] Pods, J., Sch\u00f6nke J., and Bastian P.. 2013. Electrodiffusion Models of Neurons and Extracellular Space Using the Poisson-Nernst-Planck Equations\u2014Numerical Simulation of the Intra- and Extracellular Potential for an Axon Model. Biophys. J., 105:242-254. http://dx.doi.org/10.1016/j.bpj.2013.05.041\n[2] Holt, G. R., and C. Koch. 1999. Electrical interactions via the extracellular potential near cell bodies. J. Comput. Neurosci. 6:169\u2013184. http://dx.doi.org/10.1023/A:1008832702585"}, {"correspondence": ["markus@nld.ds.mpg.de"], "figid": 9, "doi": "10.12751/nncn.bc2013.0009", "affiliations": [{"index": "1", "address": "Max Planck Institute for Dynamics and Self-organization, G\u00f6ttingen; Bernstein Center for Computational Neuroscience G\u00f6ttingen, Germany"}, {"index": "2", "address": "Cognitive Neuroscience Laboratory, German Primate Center, G\u00f6ttingen; Institute of Neuroinformatics, Ruhr-University, Bochum, Germany"}, {"index": "3", "address": "Cognitive Neuroscience Laboratory, German Primate Center, G\u00f6ttingen; Bernstein Center for Computational Neuroscience G\u00f6ttingen, Germany"}], "title": "Non-multiplicative attentional modulation patterns in area MT", "abstract": "We analyzed single unit recordings in area MT from macaque monkeys performing an attentional task. They were presented a stimulus made out of two moving random-dot-patterns (RDPs) within the receptive field of the recorded MT cell. In one experiment the two RDPs were spatially separated, in another they were overlapping at the same location. Attention was directed to a fixation spot or to only one of the two RDPs. The angle between the two RDPs was kept fixed at 120 degrees. This allowed the recording of tuning curves that plot the response of a given neuron to different overall directions of this stimulus. These tuning curves also represent the population response to this stimulus type.\n\nUsing a combination of model-based and model-free approaches we found a variety of non-multiplicative effects underlying the integration of two stimuli and attentional modulation. This includes changes in peak position and shape as well as significant differences between the spatially-separated and transparent stimulus configurations.\n\nIn order to understand these effects we explore multiareal network models with multiple coupled rings, in which functional interactions between hypercolumns of area MT and lower hierarchical order, like V1, are taken into account. This results in a high-dimensional system of non-linear equations constrained by data from the experiments described above. Analysis of its solutions allows the identification of qualitative correlation patterns between local and inter-areal functional interactions and attentional spotlight mechanisms in our modeling framework.", "acknowledgements": "Volkswagen Foundation (grant I/79868);\nBernstein Center of Computational Neuroscience G\u00f6ttingen (grants 01GQ0433 and 01GQ1005C) of the BMBF and the German Research Foundation (DFG) Collaborative Research Center 889 \u201cCellular Mechanisms of Sensory Processing\u201d \n", "id": 131081, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Markus Helmer"}, {"epithet": "2", "name": "Vladislav Kozyrev"}, {"epithet": "3", "name": "Anja Lochte"}, {"epithet": "3", "name": "Stefan Treue"}, {"epithet": "1", "name": "Theo Geisel"}, {"epithet": "1", "name": "Demian Battaglia"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["agos@nld.ds.mpg.de"], "figid": 10, "doi": "10.12751/nncn.bc2013.0010", "affiliations": [{"index": "1", "address": "Max Planck Institute for Dynamics and Self-Organization, Bernstein Center for Computational Neuroscience Goettingen, Germany"}], "title": "Inter-areal directed communication in synchronous transients", "abstract": "Behavior requires changes in effective connectivity in time scales much faster than the ones given by synaptic plasticity. The mechanisms that allow precisely targeted switching between communication pathways that might for example, be necessary for selective attention are not yet fully understood. A strong hypothesis [1] states that oscillatory coherence of population's activity allows pliable channel selectivity.\n\nIn this work we investigate through spiking network models how interacting local populations can set their collective oscillatory activity into multistable phase-locked patterns, and which are constraints this imposes to the dynamics of information flow. In the case of networks with homogeneous inputs, due to spontaneous symmetry breaking, the mean activity of the local population displays an out-of-phase locking [2], in which a hierarchy of phase-leading and lagging areas emerge. When heterogeneity in the inputs is included,the system looses this symmetry and presents a whole plethora of shapes in the phase distribution.\n\nWe show that the inter-areal information flow is determined by this dynamics [3]. We observe that out-of-phase locking is associated to anisotropic information flow with a dominant direction from leader to laggard areas, as revealed by a transfer entropy analysis of simulated LFPs. Moreover, we show that the degree of synchrony regulates the lengths of the coherent transients, during which the effective information flow shows strong anisotropic properties. We furthermore show that when the phase relations are not symmetric due to input heterogeneity the anisotropy is only truncated for highly synchronous states.\n\nWe finally made a time-resolved trial based transfer entropy analysis. By means of the phase response curve of the individual networks, we can estimate the optimal phase range such that a short stimulation succeeds to induce a switch form a laggard to a leader configuration, building a framework for controlled communication.", "acknowledgements": "", "id": 131082, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Agostina Palmigiano"}, {"epithet": "1", "name": "Theo Geisel"}, {"epithet": "1", "name": "Demian Battaglia"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Fries, Pascal. \" Trends in cognitive sciences 9.10 (2005): 474-480.\n[2] Battaglia, D., Brunel N., & Hansel. D.\" Physical review letters 99.23 (2007): 238106.\n[3] Battaglia, D., Witt, A., Wolf, F., & Geisel, T. (2012). PLoS computational biology, 8(3), e1002438.\n[4] Witt, A., Palmigiano, A., Neef, A., El Hady, A., Wolf, F., & Battaglia, D.Frontiers in Neural Circuits, 7, 49."}, {"correspondence": ["jonas.kubilius@ppw.kuleuven.be"], "doi": "10.12751/nncn.bc2013.0012", "affiliations": [{"index": "1", "address": "Laboratories of Biological and Experimental Psychology, KU Leuven, Belgium"}, {"index": "2", "address": "Laboratory of Experimental Psychology, KU Leuven, Belgium"}, {"index": "3", "address": "Laboratory of Biological Psychology, KU Leuven, Belgium"}], "title": "A generic model architecture for perceptual grouping", "abstract": "Gestalt grouping principles provide important cues for organizing visual inputs into coherent percepts. While a number of models for each grouping principle have been proposed, a unifying architecture that would flexibly incorporate all of them is still lacking. Moreover, many of these models operate in mathematical terms, rendering them unsuitable for a wider testing on real input images. Here we present a generic biologically plausible unsupervised architecture, which we term gmin [1], geared towards a unified implementation of the grouping principles. The model operates by extracting a certain feature of interest from an input image (e.g., edges) and selecting maximally informative units to decrease computational load; then it proceeds to iteratively compute grouping strength between all pairs of units and update informative unit selection using a particular grouping principle (e.g., good continuation). This process is repeated for all features of interest. Finally, a segmentation of an image into (provisional) objects is provided by an unsupervised learning procedure on the computed grouping strengths, such as clustering or belief propagation. We illustrate the validity and the general usefulness of our approach by testing it on a few very different grouping displays. Using the cues of proximity, good continuation, or orientation similarity, we were able to obtain a satisfying model performance on the classic Gestalt displays of dot lattices, contour integration, and texture segregation.", "acknowledgements": "Jonas Kubilius is a Research Assistant of the Research Foundation \u2013 Flanders (FWO), and Johan Wagemans has long-term structural funding from the Flemish Government (METH/08/02).", "id": 131083, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Jonas Kubilius"}, {"epithet": "2", "name": "Johan Wagemans"}, {"epithet": "3", "name": "Hans P. Op de Beeck"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Example model implementation. Left column: input images.  Right column: clustering of images into groups of units via a simple grouping propagation. At each step of propagation, new elements are added to a cluster if their grouping strength with any element from that cluster is above a certain threshold. The process is repeated with increasingly stringent thresholds until the desired number of clusters (which is dependent on the task) is reached. Black dots indicate ungrouped (background) elements. Units around borders are missing due to a 25 px margin and due to image undersampling (more samples lead to more accurate estimates but at a cost of memory and a longer model running time).", "figpath": "012.png", "refs": "[1] https://github.com/qbilius/gmin"}, {"correspondence": ["clemens.boucsein@biologie.uni-freiburg.de"], "figid": 13, "doi": "10.12751/nncn.bc2013.0013", "affiliations": [{"index": "1", "address": "University Freiburg, Germany"}, {"index": "2", "address": "Ludwig Maximillians University Munich, Germany"}, {"index": "3", "address": "University T\u00fcbingen, Germany"}], "title": "A sub-threshold bifurcation as the determinant for spiking precision in neocortical pyramidal cells", "abstract": "Pyramidal cells lock their firing with millisecond precision to strong stimuli, but can show long and variable spike delays under conditions resembling sparser input regimes. This behavior has been observed in experiments as well as in dynamical models of spike generation. Recent in vivo data revealed that sparse activity regimes are more prevalent than previously thought. However, eliciting spikes with sparse input requires a certain degree of synchronization, which is difficult to achieve with cells firing with variable spike delays. It is, thus, unclear in how far networks consisting of pyramidal cells could sustain activity modes with sparse firing.\n\nTo resolve this ambiguity, we iterated experiments for characterizing spiking precision in neocortical pyramidal neurons with refinements of generic models for spike generation. Our experiments revealed that, even though pyramids in the neocortex are classical type-I cells, they show precise PSP-spike coupling under most conditions mimicking sparse network activity, except for a small window that allows for the occurrence of the variable spike delays. This window openes if cells retain a high input resistance at membrane potentials close to spiking threshold. However, increases in leak conductance diminished this window of imprecise spiking and turned pyramids into cells that couple their spikes precisely to even small stimuli, a behavior typical for type-II neurons. In contrast to previous studies in other cell types, we could show that this change in precision of PSP-spike coupling is not associated with a switch from type-I to type-II dynamics, but depends on the presence of a second qualitative change, or bifurcation, in the dynamics of the spike generating mechanism, that occurs below threshold. Applying phase plane analysis of two-dimensional generic models of spike generation, we formulate a mechanistic description of the underlying dynamics, and use it as a new approach to understand PSP-spike coupling.\n", "acknowledgements": "Supported by BMBF (01GQ0420 BCCN Freiburg, 01GQ0830 BFNT Freiburg) and EU (15879-FACETS).", "id": 131084, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Clemens Boucsein"}, {"epithet": "2", "name": "Julian Ammer"}, {"epithet": "3", "name": "Jan Benda"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["grewe@bio.lmu.de"], "figid": 14, "doi": "10.12751/nncn.bc2013.0014", "affiliations": [{"index": "1", "address": "Department Biologie II, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Germany"}, {"index": "2", "address": "Department of Biology, Lund University, Sweden"}, {"index": "3", "address": " Institut f\u00fcr Neurobiologie, Eberhard Karls Universit\u00e4t T\u00fcbingen, Germany"}], "title": "Interplay of Intrinsic Noise and Receptive Field Sizes in Electrosensory Encoding in Weakly Electric Fish", "abstract": "Neuronal noise can increase the coding performance in populations of spiking neurons. The noise decorrelates the responses of individual neurons such that each neuron encodes slightly different aspects of the stimulus. For a given level of the independent noise the mutual information between stimulus and the population response increases with the number of neurons, i.e. the receptive field size of the target neuron, but eventually saturates setting an upper limit for a useful population size. \nWe here study the interplay between intrinsic noise, population size, population heterogeneity, and stimulus bandwidth using the electrosensory system of the weakly electric fish Eigenmannia virescens. The electrosensory system is a multi-purpose system that is used for electrolocation -navigation as well as communication purposes. The electrosensory system we observe high levels of intrinsic noise as well as a high degree of population heterogeneity. We thus ask if and how the noise in the electrosensory system is adapted to optimize the processing of sensory information. We find that for low-frequency stimuli the mutual information between the population response and the stimulus saturates at small populations sizes and the beneficial effect of noise is small whereas at broad-band and high-frequency stimuli noise together with larger population sizes considerably boosts the mutual information. \nFurther, the organization of subsequent information processing by the pyramidal cells in the electrosensory lateral line lobe (ELL) appears perfectly suited to reliably encode low-frequency and local localization signals and global high-frequency signals in specialized segments. While the noise in the input elements can be tolerated in the centro-medial segment where low-frequency object signals are processed it boosts the representation of high-frequency communication signals in the lateral segment where large populations are integrated.", "acknowledgements": "", "id": 131085, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Jan Grewe"}, {"epithet": "2", "name": "Anna St\u00f6ckl"}, {"epithet": "1", "name": "Henriette Walz"}, {"epithet": "3", "name": "Jan Benda"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["henninger@bio.lmu.de"], "figid": 15, "doi": "10.12751/nncn.bc2013.0015", "affiliations": [{"index": "1", "address": "Neuroethology, Universit\u00e4t T\u00fcbingen, Germany"}, {"index": "2", "address": "Dept. Biology, McGill University, Canada"}], "title": "Discreet long-term monitoring of electric fish behavior", "abstract": "A prerequisite for the full understanding of sensory systems is knowledge about the natural context these systems evolved in. The electric sense of the gymnotiform electric fish Apteronotus leptorhynchus is a successful model system in research on the neural computations underlying behavior. These fish generate an electric organ discharge, which can be modulated in amplitude and frequency to create various communication signals. Much is known about the sensory system's anatomy and physiology as well as the fish's behavior and intra-specific communication signals. However, recent laboratory studies indicate that electrocommunication behavior depends strongly on the experimental situation. Further, the fish's behavior is subject to seasonal changes, e.g. mating-related behaviors occur during specific phases of the year only. Therefore, a better knowledge about the fish's behavior in its natural habitat is desirable, in particular for interpreting electrophysiological data of the electrosensory systems.\n\nThe present study targets just this question by providing and applying a novel method for undisturbed long-term monitoring of electric fish behavior. Using an array of electrodes, which is spread out over the fish's habitat and continuously records the electric fields of the fish, allows for tracking of individual fish's motion, communication signals, and conspecific interactions. Although the recorded signal traces often are superpositions of multiple fish signals, the method provided is able to robustly retrieve and analyze the original signals on a fine timescale. Here, we discuss the underlying principles, prospects and limits of our method. We present recent data from our study-site in Panama, where we monitored and characterized the local electric fish community, including Apteronotus rostratus, during the transition from dry to rainy season.", "acknowledgements": "", "id": 131086, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "J\u00f6rg Henninger"}, {"epithet": "2", "name": "R\u00fcdiger Krahe"}, {"epithet": "1", "name": "Jan Benda"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["fabee@epagoge.de"], "figid": 16, "doi": "10.12751/nncn.bc2013.0016", "affiliations": [{"index": "1", "address": "University T\u00fcbingen, Germany"}, {"index": "2", "address": "Lund University, Sweden"}], "title": "Least Informative Dimensions", "abstract": "We present a novel non-parametric approach to maximally informative dimensions (MID). MID tries to find stimulus features that are most informative about the occurrence of a spike [3]. In order to learn the features, MID repeatedly needs to estimate the relative entropy between the features and the responses during optimization. It is therefore not easily extendable to several feature dimensions or to several spike responses like spike patterns or population responses. Our approach avoids the direct estimation and can potentially deal with multiple dimensions, spike patterns, or populations of neurons. Instead of maximizing the information between features and responses directly, we minimize the information between non-informative features and the combination of informative features and responses using integral probability metrics in kernel Hilbert spaces which are easy to compute and whose empirical estimators exhibit good theoretical convergence properties [1,2]. By using a particular expansion of the mutual information, we show that the informative features must contain all information if we can make the uninformative features independent of the rest. We demonstrate that our approach is able to find the correct informative features at several artificial and real world examples. ", "acknowledgements": "We thank Lucas Theis and Arthur Gretton for helpful discussions and comments on the manuscript. ", "id": 131087, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Fabian Sinz"}, {"epithet": "2", "name": "Anna St\u00f6ckl"}, {"epithet": "1", "name": "Jan Grewe"}, {"epithet": "1", "name": "Jan Benda"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Fukumizu, Bach, Jordan. Dimensionality Reduction for Supervised Learning with Reproducing Kernel Hilbert Spaces. Journal of Machine Learning Research, 5(1):73\u201399, 2004.\n[2] Gretton, Borgwardt, Rasch, Sch\u00f6lkopf, Smola. A kernel method for the two sample problem. Advances in Neural Information Processing Systems 19\n[3] Sharpee, Rust, Bialek. Analyzing neural responses to natural signals: maximally informative dimensions. Neural Computation 16(2):223\u2013250, 2004."}, {"correspondence": ["a.bernacchia@jacobs-university.de"], "figid": 17, "doi": "10.12751/nncn.bc2013.0017", "affiliations": [{"index": "1", "address": "School of Engineering and Science, Jacobs University Bremen, Germany"}], "title": "Decorrelation by synaptic plasticity in recurrent networks ", "abstract": "The brain receives a large amount of information through its sensory system, but the information received at a given time is small compared to the capacity of encoding and storing by the hundred billions available neurons and the synapses connecting them. The brain not only encodes the moment-by-moment sensory signals, it also stores memories and encodes cognitive variables, such as plans of future actions and filtering of inputs according to these plans.\n\nIt has been suggested that one fundamental task accomplished by the sensory system is to maximize information, and this view has been partially confirmed by measures of neuronal activity in different brain areas, especially those involved in first-order processing of sensory signals. However, it is unclear whether this maximum information principle also applies for non-sensory items, such as stored memories.\n\nI show that decorrelation of neurons in recurrent networks is necessary for learning the appropriate actions in tasks requiring memory. If a network is redundant, different neurons encode nearly the same information, and it is difficult for a decision system to recognize how the signals from those neurons should be combined to determine the correct output. As a consequence, learning in redundant networks is slow and unfeasible in most situations.\n\nI study possible plasticity mechanisms underlying decorrelation in recurrent networks. I show that a synaptic plasticity rule based on the commutator operation is able to decorrelate the activity of neurons in recurrent networks. Decorrelation applies even in presence of memory and for different statistics of the input stimuli. I conclude by showing the performance of this plasticity rule for learning a variety of decision-making tasks. ", "acknowledgements": "", "id": 131088, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Alberto Bernacchia"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["shervin.safavi@gmail.com"], "doi": "10.12751/nncn.bc2013.0018", "affiliations": [{"index": "1", "address": "Max Planck Institute for Biological Cybernetics, Germany"}], "title": "Analyzing locking of spikes to spatio-temporal patterns in the macaque prefrontal cortex", "abstract": "Previous analysis of LFPs recorded from the macaque inferior convexity of the Prefrontal Cortex with Utah arrays revealed a dominant travelling wave in the beta band propagating along the ventral-dorsal plane [1, 2]. We hypothesized that propagating rhythmic activity reflects the intrinsic dynamics of the underlying neural populations which might be instrumental to information processing functions such as sensory integration. Here, we investigated the relationship between multi-unit spiking activities and LFPs in the same area of the Prefrontal Cortex. \nWe computed spike-field coherence for each channel of the array. The results showed that many recording sites exhibited a distinctive peak in the beta frequency range both for spontaneous activity and during visual stimulation (A). Then we computed the beta band phase locking of spikes for each channel to a common LFP reference channel. The results showed that many recording sites exhibited locking of spikes to the same phase of remote beta band LFP (B). This result was observed for many LFP reference channels, suggesting spikes in all channels are synchronized to a common phenomenon.\nTo characterize this phenomenon, we developed a new methodology inspired by spike triggered analysis to capture the dominant underlying spatio-temporal pattern of beta oscillations associated to spiking activity. The dominant spatio-temporal pattern estimated by matrix factorization, exhibits a phase gradient along the ventral-dorsal plane (C), suggesting that multi-unit activities across the array are synchronized to the global travelling wave previously observed along this direction in the LFP signal. \nOur result suggests spikes are synchronized to large scale travelling wave in the beta band. We postulate this reflects an endogenous mechanism for the large scale coordination of population activity. Further information theoretic analysis will address how this mechanism serves distributed sensory encoding and processing in this area. ", "acknowledgements": "This study was supported by the Max Planck Society.", "id": 131089, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Shervin Safavi"}, {"epithet": "1", "name": "Theofanis Panagiotaropoulos"}, {"epithet": "1", "name": "Vishal Kapoor"}, {"epithet": "1", "name": "Nikos K. Logothetis"}, {"epithet": "1", "name": "Michel Besserve"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "(A) Spike-Field coherence computed for one channel (B) Result of phase locking analysis of the spikes in each channel of the array with reference to the LFP of the channel indicated by a plus (+) sign. Only the 50% most synchronized channels are depicted (C) Phase of the dominant LFP pattern associated with the phase-locking of spikes.\nColor values in B and C represent the phase (in degrees) of each channel in our 2D grid (10x10). The black pixels in B and C indicate channels with no or very few spikes (or unsynchronized ones in B).\n", "figpath": "018.png", "refs": "[1] Besserve M, Panagiotaropoulos T, Crocker B, Kapoor V, Tolias A, Panzeri S, Logothetis NK; Identifying endogenous rhythmic spatio-temporal patterns in micro-electrode array recordings, 9th annual Computational and Systems Neuroscience meeting (Cosyne 2012), Salt Lake City, UT, USA.\n[2] Panagiotaropoulos T, Besserve M, Logothetis NK; Beta oscillations propagate as traveling waves in the macaque prefrontal cortex, 42nd Annual Meeting of the Society for Neuroscience (2012), New Orleans, LA, USA."}, {"correspondence": ["tara.farzami@bethgelab.org"], "figid": 19, "doi": "10.12751/nncn.bc2013.0019", "affiliations": [{"index": "1", "address": "Graduate School of Neural Information Processing, University of T\u00fcbingen"}, {"index": "2", "address": "Werner Reichardt Centre for Integrative Neuroscience, University of T\u00fcbingen"}, {"index": "3", "address": "Max Planck Institute for Biological Cybernetics, T\u00fcbingen, Germany"}], "title": "Neural Adaptation as Bayesian Inference", "abstract": "Capturing stimulus-response relationships is one of the key problems in sensory neuroscience. Due to the stochasticity inherent in neural responses, probabilistic models provide a natural framework for approaching this problem. Generalized linear models (GLMs) are a family of probabilistic models frequently used for characterizing neural spike responses. Popular special cases include the linear nonlinear Poisson model (LNP) and, history dependent LNP models. We applied both types of models to data recorded from whisker-sensitive neurons in the right trigeminal ganglion cells of adult Sprague-Dawley rats stimulated with white noise. We found that the LNP model falls short of explaining the experimental data. Since most of these types of cells are highly adaptive, a likely explanation of the observed shortcoming of LNP models is their inability to represent adaptation effects. Here, we explore the idea that adaptation can be understood as a form of Bayesian inference. We use a dynamical latent variable model to infer parameters of the stimulus. Using the inferred parameters, we adjusted the history dependent LNP models. This not only allows us to improve the spike prediction performance of these models, but also to study the assumptions about the stimulus encoded in the cells, as well as their rate of adaptation.", "acknowledgements": "", "id": 131090, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Tara Farzami"}, {"epithet": "1", "name": "Lucas Theis"}, {"epithet": "2", "name": "Matthias Bethge"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["leon.gatys@bethgelab.org"], "figid": 20, "doi": "10.12751/nncn.bc2013.0020", "affiliations": [{"index": "1", "address": "CIN, Uni T\u00fcbingen, Germany"}, {"index": "2", "address": "BCCN T\u00fcbingen; CIN, Uni T\u00fcbingen; (Department of Neuroscience), Baylor College of Medicine., Germany"}, {"index": "3", "address": "Max Planck Institute for Brain Research Max-von-Laue-Str. 4 60438 Frankfurt am Main, Germany"}, {"index": "4", "address": "BCCN T\u00fcbingen; CIN, Uni T\u00fcbingen; MPI Biological Cybernetics, T\u00fcbingen, Germany"}], "title": "Information Coding in the Variance of Neural Activity", "abstract": "Neural activity in the cortex appears to be notoriously noisy. A widely accepted explanation for this finding is that excitatory and inhibitory inputs to downstream neurons are balanced in a way that the upstream population activity does not affect the mean but only the variance of the input current. \nThis can be thought of as a multiplicative noise channel. However, the capacity limits imposed by this information channel are not known. Here we develop a general understanding of the encoding process in terms of scale mixture processes and derive information-theoretic bounds on their performance. Our results show that signal transmission via instantaneous changes in the variance can behave quite differently from the common additive noise channel. We perform systematic numerical analyses to maximize the information across the variance channel and thus obtain tight lower bounds to its capacity. Furthermore, we found that additional noise, resembling the unreliable synaptic transmission of spikes, can surprisingly enhance the coding performance of the channel. \n", "acknowledgements": "", "id": 131091, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Leon Gatys"}, {"epithet": "2", "name": "Alexander Ecker"}, {"epithet": "3", "name": "Tatjana Tchumatchenko"}, {"epithet": "4", "name": "Matthias Bethge"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["tsawallis@gmail.com"], "figid": 21, "doi": "10.12751/nncn.bc2013.0021", "affiliations": [{"index": "1", "address": "Schepens Eye Research Institute, Massachusetts Eye and Ear Infirmary, Harvard Medical School, United States"}, {"index": "2", "address": "(Present address: Universit\u00e4t T\u00fcbingen, Bernstein Zentrum f\u00fcr Computational Neuroscience)"}], "title": "Sensitivity to gaze contingently presented contrast increments in freely viewed naturalistic video: Contrast response functions", "abstract": "Sensitivity to luminance contrast is a fundamental property of the visual system. We examine contrast increment detection performance in a way that approximates the natural environmental input of the visual system by presenting targets gaze-contingently within a naturalistic video that was freely viewed by observers. One spatial scale of the video sequence was incremented in contrast in a local region at one of four locations relative to the observers' current gaze point, and this increment was spatiotemporally blended with the unmodified video. The observer made a forced-choice response to the location of the target (4AFC). Performance was modelled as a discrimination function arising from an underlying contrast response function (Foley function), the parameters of which were estimated via Bayesian inference in a multilevel framework. In our data there is no evidence of an accelerating nonlinearity of the type producing a ``dipper''; instead the function simply rises with base contrast level consistent with masking. Consequently a simplified version of the Foley function provides the most parsimonious fit to our data. While some properties of the contrast response found with impoverished stimuli were not evident in our data, in general the rising contrast response of the Foley-type function provides a good account of human sensitivity to contrast increments under naturalistic conditions.", "acknowledgements": "TSAW was supported by the National Health and Medical Research Council of Australia (NHMRC training fellowship 634560).\nPJB was supported by NIH grants EY019281 and EY018664.", "id": 131092, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Thomas S. A. Wallis"}, {"epithet": "1", "name": "Michael A. C. Dorr"}, {"epithet": "1", "name": "Peter J. Bex"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["kellaithy@informatik.uni-leipzig.de"], "figid": 22, "doi": "10.12751/nncn.bc2013.0022", "affiliations": [{"index": "1", "address": "Universitaet Leipzig, Germany"}, {"index": "2", "address": "Universitaet Tuebingen, Germany"}], "title": "Quantitative Analysis of Transitions in Visual Awareness Using the Level-of-Recall from Synaptic Dynamics", "abstract": "This work postulates that multistable visual perception can be studied and analysed from the associative-memory perspective. Within the paradigm of visual perception, Binocular rivalry (BR) and binocular flash suppression (BFS) represent two of the most extensively used paradigms of such perceptual multistability where two or more perceptual interpretations compete for access to awareness during periods of unchanged sensory stimulation [1,2]. Similar (if not identical) behaviours have been widely observed while investigating the recall of associative memory patterns within spiking neural networks (SNN). That is, a spiking neural network that is stimulated with background noise exhibits a switching behaviour among the stored patterns of neural activities (firing patterns) [3]. The span of appearance of each pattern and the switching frequency can be modulated through the noise intensity as well as the neuronal and synaptic parametrization.\n\nThe work presented here is based on the assumption that the dynamics of multistable visual perception can indeed be studied and investigated in terms of switching among different memory patterns. Usually the switching dynamics (within both paradigms of visual perception or associative memory) are analysed using either mean-field reduction or stability analysis, both are not straightforward within SNN especially when dynamic synaptic models are involved. In this study novel measures are introduced based on extracting the level-of-recall of the memory patterns from the synaptic activity. A cost-like function is defined for the separation between patterns in memory recall. Moreover, the relative strength\nof recall between pairs of patterns is proposed as well. Using these measures, show-cases\nare introduced via both hypothetical situations and network simulations.\n\nResults show that the introduced measures give novel insights about the performance of the network and help in comparing the outputs from different setups.", "acknowledgements": "", "id": 131093, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Karim El Laithy"}, {"epithet": "2", "name": "Georgios Keliris"}, {"epithet": "2", "name": "Wolfgang Rosentiel"}, {"epithet": "1", "name": "Martin Bogdan"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] David A. Leopold and Nikos K. Logothetis. Multistable phenomena: changing views\nin perception. Trends in Cognitive Sciences, 3(7):254\u2013264, 1999.\n[2] G. A. Keliris, Logothetis, N. K., and A. S. Tolias. The role of the primary visual cortex in\nperceptual suppression of salient visual stimuli. J. Neuroscience, 30(37):12353\u201312365,\n2010.\n[3] G. Mongillo, O. Barak, and M. Tsodyks. Synaptic theory of working memory. Science,\n319(5869):1543\u20131546, 2008."}, {"correspondence": ["till@hms.harvard.edu"], "figid": 23, "doi": "10.12751/nncn.bc2013.0023", "affiliations": [{"index": "1", "address": "Harvard Medical School, United States"}], "title": "Does V1 anticipate moving stimuli?", "abstract": "From our daily experience it is apparent that we can predict the trajectories of moving objects in order to, for example, catch a thrown ball. Where in the neural pathways between eye and hand does the system begin to compensate for the considerable delays introduced by early visual processing? We were interested to know whether predictive signals exist in primary visual cortex (V1), because previous studies have reported compensation as early as retinal ganglion cells (Berry et al., Nature 1999). We recorded multiunit activity (MUA) from 96 electrodes simultaneously in V1 of a fixating monkey. In the motion conditions, a white bar moved either to the left or right across a gray background at a constant velocity. In the stationary condition, an identical bar was flashed briefly at random locations along the motion trajectory, thus allowing us to measure the impulse response function of the neurons in both space and time. The spatio-temporal population kernel\u2014estimated from the impulse response functions convolved with the representation of the moving bar\u2014results in a response comparable to the motion response (linear model prediction). We found that the actual motion response led the linear model prediction slightly. The linear model matched the rising phase of the motion response far better than the decline, mainly because the motion response dropped sharply after the bar passed the center of the receptive field (RF). A second model, in which we added a negative feedback component, improved the fit and reproduced the drop in firing rate after the bar passed the center of the RF. Importantly, there was no delay in the response of the feedback model.\nIn conclusion, the majority of V1 neurons do not start firing before a stimulus moves into the RF. The peak response time for a moving stimulus compensates partially for the visual latency, but it is doubtful that this plays an important role in object position prediction.", "acknowledgements": "This work was supported by the Alice and Joseph Brooks Fund and NIH grant R01 EY011379", "id": 131094, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Till Hartmann"}, {"epithet": "1", "name": "Richard Born"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Anticipation of moving stimuli by the retina; Berry MJ, Brivanlou IH, Jordan TA, Meister M; (1999) Nature. 398:334-338."}, {"correspondence": ["christoph.braun@uni-tuebingen.de"], "figid": 24, "doi": "10.12751/nncn.bc2013.0024", "affiliations": [{"index": "1", "address": "MEG-Center, University of T\u00fcbingen Medical School, T\u00fcbingen, Germany"}, {"index": "2", "address": "Department of Psychology, Stanford University, Stanford, United States"}, {"index": "3", "address": "Institute of Medical Psychology and Behavioral Neurobiology, University of T\u00fcbingen, T\u00fcbingen, Germany"}, {"index": "4", "address": "Departamento de Psiquiatr\u00eda, Escuela de Medicina Universidad Cat\u00f3lica de Chile, Santiago di Chile, Chile"}, {"index": "5", "address": "Department of Biomedical Engineering, University of Florida, Gainesville, United States"}, {"index": "6", "address": "Department of Physiology and Biophysics, University of Washington, Seattle, United States"}], "title": "Modulating Connectivity between Left and Right Primary Motor Cortex Using Neurofeedback", "abstract": "Magnetoencephalography (MEG) records the magnetic activity of the brain from sensor arrays covering the head. Coherence measures based on MEG recordings provide information about the dynamic interaction between different brain regions. A previous study has shown that coherence can be modulated using neurofeedback (Sacchet et al., 2012). In addition to the modulation of functional connectivity, the present experiment aimed to investigate the behavioral effects induced by modulation of coherence.\nTen healthy subjects participated in the study. The experiment comprised of 5 phases: (1) pre-test, (2) \u201cSMR region identification\u201d, (3) behavior identification, (4) feedback training, and (5) post-test. Pre- and post-test are performed to quantify effects of the feedback training on behavioral performance in a self-paced finger tapping task. In the \u201cSMR region identification task\u201d, we identified the areas of the brain generating the mu-rhythm during a repetitive, self-paced finger extension-contraction task. In the \u201cbehavior identification task\u201d we tested which two out of the five motor behaviors yielded the largest difference in coherence. This pair of tasks was further employed in the feedback training.  During the feedback training, participants were directed a ball depicted on a computer screen towards a target. The position of the ball was controlled by the strength of coherence between left and right MI. Half of the trials required increase (up-training), the other half decrease of coherence (down-training). The target stimulus for up- and down-regulation of coherence was also presented as discriminative stimulus in the pre- and post-test.\nWe were able to show that subjects obtained voluntary control over the modulation of coherence between left and right primary MI. Notably, the control of coherence improved steadily over training sessions. In addition, we could show that the spontaneous rate of the finger tapping sequence increased from pre- to post-test.\n", "acknowledgements": "The project is part of the Bernstein Center Neurofokus (Freiburg/T\u00fcbingen) and was funded by the BMBF. The project was further supported by the Werner Reichardt Center for Integrative Neuroscience (CIN), T\u00fcbingen.", "id": 131095, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Diljit Singh Kajal"}, {"epithet": "2", "name": "Matthew D. Sacchet"}, {"epithet": "3", "name": "J\u00fcrgen Mellinger"}, {"epithet": "4", "name": "Sergio Ruiz"}, {"epithet": "5", "name": "Ranganatha Sitaram"}, {"epithet": "6", "name": "Eberhard E. Fetz"}, {"epithet": "3", "name": "Niels Birbaumer"}, {"epithet": "1", "name": "Christoph Braun"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Sacchet MD, Mellinger J, Sitaram R, Braun C, et al. Volitional control of neuromagnetic coherence. Front of Neurosc, 2012;doi:10.3389\n\n"}, {"correspondence": ["felix.leibfried@tuebingen.mpg.de"], "figid": 25, "doi": "10.12751/nncn.bc2013.0025", "affiliations": [{"index": "1", "address": "Max Planck Institute for Biological Cybernetics, Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany"}], "title": "Signaling in sensorimotor interactions", "abstract": "Communication relies on signals that convey information. In non-cooperative game theory, signaling games [1] are used to investigate under what conditions two players may communicate with each other when their ultimate aim is to maximize their own benefit. In this case, one player (the sender) possesses private information (the type) that the other player (the receiver) would like to know. However, signaling this information is costly. At the same time the receiver has control over a variable that influences the sender\u2019s payoff. The key question is under which circumstances so-called Perfect Bayesian Nash equilibria with reliable signaling occur. Here, we investigate whether human sensorimotor behavior conforms with optimal strategies corresponding to these equilibria [2].\nWe designed a sensorimotor task, where two participants controlled a two-dimensional cursor. Importantly, each player could control only one of the two dimensions. The sender\u2019s dimension could be used to communicate a target position that the receiver had to hit without knowing its location. The sender\u2019s aim was to maximize a point score displayed on a two-dimensional color map. The point score decreased with the magnitude of the signal and increased with the reach distance of the receiver. The sender therefore had a trade-off between communicating the real target distance with the hope that the receiver would learn to interpret this signal and give appropriate reward, and trying to avoid signaling costs. We found that participants developed strategies that resulted in separating equilibria as predicted by analytically derived game theoretic solutions.\n", "acknowledgements": "This study was supported by the DFG, Emmy Noether grant BR4164/1-1.", "id": 131096, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Felix Leibfried"}, {"epithet": "1", "name": "Jordi Grau-Moya"}, {"epithet": "1", "name": "Daniel A Braun"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] I.-K. Cho and D. M. Kreps. Signaling games and stable equilibria. The Quarterly Journal of Economics, 102(2):179-221, May 1987.\n[2] D. A. Braun, P. A. Ortega and D. M. Wolpert. Nash Equilibria in Multi-Agent Motor Interactions. PLoS Computational Biology, 5(8):1-8, Aug 2009."}, {"correspondence": ["tim.genewein@tuebingen.mpg.de"], "figid": 26, "doi": "10.12751/nncn.bc2013.0026", "affiliations": [{"index": "1", "address": "MPI for Biological Cybernetices, Tuebingen, Germany"}], "title": "Occam's Razor in sensorimotor learning", "abstract": "Prediction is a ubiquitous phenomenon in biological systems ranging from basic motor control in\nanimals [1] to scientific hypothesis formation in humans. A central problem in prediction systems\nis how to choose one\u2019s predictions if there are multiple competing hypothesis that explain the\nobserved data equally well. Following Occam's Razor the simpler explanation requiring fewer\nassumptions should be preferred. An implicit and elegant way to apply Occam\u2019s Razor is\nBayesian inference. In particular, a Bayesian Occam's Razor effect arises when comparing\ndifferent hypothesis based on their marginal likelihood [2].\nHere we investigate whether sensorimotor prediction systems implicitly apply Occam\u2019s Razor\nin everyday movements. This question is particularly compelling, as recent studies have found\nevidence that the sensorimotor system makes inferences about unobserved latent variables in a\nway that is consistent with Bayesian statistics [3,4].\nWe designed a sensorimotor task, where participants had to draw regression trajectories\nthrough a number of observed data points, representing noisy samples of an underlying ideal\ntrajectory. The ideal trajectory was generated by one of two possible Gaussian process (GP)\nmodels\u2014a simple model with a large length-scale, leading to smooth trajectories and a complex\nmodel with a short length-scale, leading to more wiggly trajectories. Participants were trained\non the two different trajectory models and then exposed to ambiguous stimuli to see whether\nthey showed a preference for the simpler model.\nIn case the presented stimulus could be fit equally well by both models, we found that\nparticipants showed a clear preference for the simpler model. For general stimuli, we found\nthat participants\u2019 behavior was quantitatively consistent with Bayesian Occam\u2019s Razor. We\ncould also show that participants\u2019 drawn trajectories were similar to samples from the posterior\npredictive GP and significantly different from two non-probabilistic heuristics.", "acknowledgements": "This study was supported by the DFG, Emmy Noether grant BR4164/1-1.", "id": 131097, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Tim Genewein"}, {"epithet": "1", "name": "Daniel A. Braun"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] R. Shadmehr, M. A. Smith, and J. W. Krakauer. Error correction, sensory prediction, and adaptation in motor control. Annu.Rev.Neurosci., 2010\n[2] D. J. C. Mackay. Information theory, inference and learning algorithms. Cambridge University Press, 2003\n[3] M. O. Ernst and M. S. Banks. Humans integrate visual and haptic information in a statistically optimal fashion. Nat., 2002\n[4] K. P. Koerding and D. M. Wolpert. Bayesian decision theory in sensorimotor control. Trends in Cogsci, 2006"}, {"correspondence": ["zhen.peng@tuebingen.mpg.de"], "figid": 27, "doi": "10.12751/nncn.bc2013.0027", "affiliations": [{"index": "1", "address": "Max Planck Institute for Biological Cybernetics, Max Planck Institute for Intelligent Systems, Graduate Training Center of Neuroscience, T\u00fcbingen, Germany"}, {"index": "2", "address": "Max Planck Institute for Biological Cybernetics, Max Planck Institute for Intelligent Systems., Germany"}], "title": "Assessing randomness in human motion trajectories", "abstract": "Intelligence is often related to the behavioural complexity an agent can generate. For example, when studying human language one typically finds that sequences of letters or words are neither completely random nor totally determinate. This is often assessed quantitatively by studying the conditional entropy of sequences [1]. Similarly, entropy can be used to assess the human ability to generate random numbers. Humans have often been found to be not very good at generating random numbers[2]. Here we test human randomness when generating trajectories and compare entropic measurements of random vs. non-random motion. \n\nWe designed a motor task where participants controlled a cursor by moving a Phantom manipulandum in a three-dimensional virtual environment. The cursor was constrained to move inside a 10x10 grid. In the first part of the experiment participants were asked to (1) perform a rhythmic movement, (2) write pre-specified letters, and (3) perform a random movement. In the second part of the experiment participants were asked again to perform random movements, but this time they received feedback from an artificial intelligence (based on context-tree weighting algorithm) predicting their next move. We found that the conditional entropy revealed different patterns for different motion types and that participants\u2019 motion randomness was only weakly susceptible to feedback.", "acknowledgements": "This study was supported by the DFG, Emmy Noether grant BR4164/1-1.", "id": 131098, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Zhen Peng"}, {"epithet": "1", "name": "Tim Genewein"}, {"epithet": "2", "name": "Daniel A. Braun"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Rao, R. P. N., Yadav, N., Vahia, M. N., Joglekar, H., Adhikari, R., & Mahadevan, I. (2009). Entropic evidence for linguistic structure in the Indus script. Science, 324(5931), 1165. DOI: 10.1126/science.1170391\n[2] Figurska, M., Sta\u0144czyk, M., & Kulesza, K. (2008). Humans cannot consciously generate random numbers sequences: Polemic study. Medical Hypotheses, 70(1), 182-185. Elsevier."}, {"correspondence": ["chrbauermeister@googlemail.com"], "doi": "10.12751/nncn.bc2013.0028", "affiliations": [{"index": "1", "address": "Center for Behavioral Brain Sciences, Magdeburg, Germany"}, {"index": "2", "address": "Universitat Pompeu Fabra, Barcelona, Spain"}, {"index": "3", "address": "Technion \u2013 Israel Institute of Technology, Haifa, Israel"}], "title": "Hierarchical recruitment in neuronal assemblies with heterogeneous connectivity", "abstract": "In neuronal assemblies with synaptic short-term depression and appropriate recurrent connectivity, brief bursts of collective activity (\u2018network spikes\u2019) alternate with far longer quiescent periods. Experimental work has revealed that \u2018network spikes\u2019 develop in a non-random and hierarchical fashion in that a few neurons are recruited reliably before others (\u2018early-to-fire neurons\u2019 [1]). Several hypotheses have been advanced as to reasons for the existence of \u2018early-to-fire\u2019 neurons: number of outgoing connections [1], low firing threshold [2], and availability of synaptic resources [3]. Here we show that a particular kind of heterogeneous random connectivity ensures the presence of \u2018early-to-fire\u2019 neurons. Specifically, if the number of incoming connections follows a flat distribution, this ensures the presence of a neuronal cohort with an incoming connectivity that is (i) large enough to bring the membrane potential close to firing threshold and (ii) small enough to preserve synaptic resources. \u2018Early-to-fire\u2019 neurons are found within this cohort. Neither homogeneous random connectivity nor other kinds of heterogeneous random connectivity (e.g., scale-free) have this effect. Simulated networks used conductance synapses (AMPA, GABA) with short-term depression and facilitation. Neurons were identical (except for incoming connectivity) and received identical background currents. We discuss the causal importance of early-to-fire neurons for \u2018network spikes\u2019 and compare both population activity (rate, strength, and shape of \u2018network spike\u2019) and individual neuronal activity (rate, latency relative to \u2018network spike\u2019) to experimental observations from an in vitro model of cortical neuronal assemblies. We conclude that hierarchical recruitment of \u2018network spikes\u2019 offers unexpected insights into the connectivity of neuronal assemblies.", "acknowledgements": "Supported by EU FP7-269459 Coronet and BMBF Bernstein Network.", "id": 131099, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Christoph Bauermeister"}, {"epithet": "2", "name": "Gustavo Deco"}, {"epithet": "3", "name": "Shimon Marom"}, {"epithet": "1", "name": "Jochen Braun"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Simulated neuronal assemblies with different connectivities. (a) Population activity over 15 s in a recurrently connected assembly of 400 excitatory and 100 inhibitory neurons. \u2018Network spikes\u2019 are brief events separating far longer quiescent periods. (b) Probability p_n number of incoming excitatory-excitatory connections n, for heterogeneous (red solid) and homogeneous (red dashed) random connectivity. In both cases, the average is 80 (20% connectivity). (c) Average activity of neurons, from least to most active, for heterogeneous (green) and homogeneous (blue) random connectivity. Heterogeneous connectivity results in a greater spread of activity. (d) Firing density of individual neurons, relative to the population firing density during \u2018network spike\u2019 (thick black). Representative early-to-fire (blue), normal (red), and late-to-fire (green) neurons are shown. (e) Time T_n of peak firing density of individual neurons (relative to population peak), as a function average activity, from least to most active, for heterogeneous connectivity. A distinct cohort of early-to-fire neurons is evident. (f) Time T_n of peak firing density of individual neurons (relative to population peak), as a function average activity, from least to most active, for homogeneous connectivity. No early-to-fire neurons are evident.", "figpath": "028.png", "refs": "[1] D. Eytan and S. Marom. Dynamics and e\ufb00ective topology underlying synchronization in networks of cortical neurons. J Neurosci, 26(33):8465-8476, 2006\n[2] C. Zbinden. Leader neurons in leaky integrate and fire neural network simulations. J Comput Neurosci. 31(2):285-304, 2011\n[3] M. Tsodyks, A. Uziel and H. Markram. Synchrony generation in recurrent networks with frequency-dependent synapses. J Neurosci, 20:RC50 (1\u20135), 2000"}, {"correspondence": ["drdanielbush@gmail.com"], "figid": 30, "doi": "10.12751/nncn.bc2013.0030", "affiliations": [{"index": "1", "address": "UCL Institute of Cognitive Neuroscience, UCL Institute of Neurology, United Kingdom"}], "title": "A Hybrid Oscillatory Interference / Continuous Attractor Network Model of Grid Cell Firing", "abstract": "Grid cells in the rodent medial entorhinal cortex (mEC) exhibit remarkably regular, hexagonally spaced receptive fields that tessellate all environments visited by an animal. Two theoretical mechanisms that could generate this spatially periodic activity pattern have been proposed: oscillatory interference and continuous attractor dynamics. Although a variety of evidence has been cited in support of each model alone, some aspects of the two mechanisms are complementary, suggesting that a combined model may best account for experimental data. The oscillatory interference model proposes that the grid pattern is formed from linear interference patterns or \u201cperiodic bands\u201d in which velocity controlled oscillators integrate self-motion to code displacement along preferred directions. However, it also affords the use of symmetric recurrent connectivity between grid cells to provide stability and continuous attractor dynamics. Here, we present simulations of this type of hybrid model. We demonstrate that this model generates intracellular membrane potential profiles which closely match those observed in vivo, and can address several prominent criticisms aimed at pure oscillatory interference and continuous attractor models. Finally, we discuss the experimental predictions generated by this new model.", "acknowledgements": "", "id": 131100, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Daniel Bush"}, {"epithet": "1", "name": "Neil Burgess"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["drdanielbush@gmail.com"], "figid": 31, "doi": "10.12751/nncn.bc2013.0031", "affiliations": [{"index": "1", "address": "UCL Institute of Behavioural Neuroscience, UCL Institute of Neurology, United Kingdom"}, {"index": "2", "address": "UCL Institute of Behavioural Neuroscience, UCL Institute of Neurology, UCL Institute of Cognitive Neuroscience, UCL Department of Cell and Developmental Biology, United Kingdom"}, {"index": "3", "address": "UCL Institute of Cognitive Neuroscience, UCL Institute of Neurology, United Kingdom"}], "title": "Optimal Configurations of Spatial Scale for Grid Cell Firing under Noise and Uncertainty", "abstract": "We examine the accuracy with which the location of an agent moving within an environment can be decoded from simulated activity in a population of grid cells [Mathis et al. 2012]. Grid cells are modelled with Poisson spiking dynamics and organised into multiple modules, with firing patterns of similar spatial scale within modules and a wide range of spatial scales across modules, following experimental observations. The number of grid cells per module, the spatial scaling factor between modules, and the size of the environment are varied. Errors in decoded location can take two forms: small errors of precision and larger errors resulting from ambiguity in decoding periodic firing patterns. With sufficient cells per module (e.g. 8 modules of 100 cells each), the simulated grid cell network is highly robust to ambiguity errors, even over ranges much larger than the largest grid scale (e.g. over a 500m range when the maximum grid scale is 264cm). Results do not depend strongly on the precise organisation of scales across modules (geometric, co-prime, or random). However, independent spatial noise across modules, which would occur if modules receive independent spatial inputs and might increase with spatial uncertainty, dramatically degrades the encoding precision of the grid cell network. We demonstrate that this effect of spatial uncertainty can be mitigated by uniform expansion of grid scales. Thus, in the realistic regimes simulated here, the optimal overall scale for a grid system represents a trade-off between minimising spatial uncertainty (requiring large scales) and maximising precision (requiring small scales). Within this view, the temporary expansion of grid scales observed in novel environments may be an optimal response to increased spatial uncertainty induced by the unfamiliarity of the available spatial cues.", "acknowledgements": "", "id": 131101, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Benjamin W Towse"}, {"epithet": "2", "name": "Caswell Barry"}, {"epithet": "3", "name": "Daniel Bush"}, {"epithet": "3", "name": "Neil Burgess"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Mathis A, Herz AVM and Stemmler M (2012) Optimal Population Codes for Space: Grid Cells Outperform Place Cells. Neural Computation 24: 2280\u20132317. (doi:10.1162/NECO_a_00319)"}, {"correspondence": ["laura.busse@cin.uni-tuebingen.de"], "figid": 32, "doi": "10.12751/nncn.bc2013.0032", "affiliations": [{"index": "1", "address": "Centre for Integrative Neuroscience, University of Tuebingen, Germany"}], "title": "Effects of locomotion on response properties and functional connectivity in mouse primary visual cortex", "abstract": "Neural responses not only depend on sensory input but also on behavioral state. Recently, it has been proposed that the desynchronized brain state studied in rodents has similarities to effects of selective attention typically studied in primates (Harris & Thiele, 2011). Here, we used locomotion in the mouse as a behavioral indicator of desynchronized brain state, and tested whether locomotion-based modulations of neural responses in primary visual cortex (V1) indeed resemble those found by attention.\n\nTo investigate modulations of neural responses by locomotion, we placed head-fixed mice on an air-cushioned Styrofoam ball, on which they could run or remain quiescent. We inserted tetrodes or high-density linear multi-electrode arrays spanning all layers of cortex into area V1 to record extracellular activity from single neurons.\n\nSimilar to previous reports (Niell & Stryker, 2010; Keller et al., 2012; Ayaz et al., 2013), we found that locomotion modulated both spontaneous activity and responses to drifting gratings, but importantly, the magnitude and sign of this modulation depended on laminar location. Locomotion enhanced neural activity of ~30% of neurons in supragranular layers. In infragranular layers, however, fewer neurons were affected, and the overall population response decreased rather than increased.\n\nWe next assessed the influence of locomotion on processing of stimulus contrast and investigated its impact on functional connectivity by measuring correlated response variability in pairs of neurons (noise correlations). Similar to signatures of attention, locomotion not only enhanced responsiveness but also increased contrast sensitivity. Furthermore, locomotion decreased average noise correlations. \n\nWe conclude that effects of locomotion on both the response properties of single neurons and network activity in V1 share similarities with those reported for selective attention.", "acknowledgements": "This work is supported by funds awarded to the Centre for Integrative Neuroscience (DFG Exec 307); by a DAAD grant awarded to AV; and by a Starting Independent Researcher Grant from the European Research Council (project acronym: PERCEPT) awarded to SK.", "id": 131102, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Sinem Erisken"}, {"epithet": "1", "name": "Agne Vaiceliunaite"}, {"epithet": "1", "name": "Steffen Katzner"}, {"epithet": "1", "name": "Laura Busse"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Ayaz A, Saleem AB, Sch\u00f6lvinck ML, & Carandini M (2013). Locomotion controls spatial integration in mouse visual cortex. Curr Biol, 23:890\u20134.\nHarris KD & Thiele A (2011). Cortical state and attention. Nat Rev Neurosci, 12:509\u201323.\nKeller GB, Bonhoeffer T, & H\u00fcbener M (2012). Sensorimotor mismatch signals in primary visual cortex of the behaving mouse. Neuron, 74:809\u201315.\nNiell CM, and Stryker MP (2010). Modulation of visual responses by behavioral state in mouse visual cortex. 65:472\u201379"}, {"correspondence": ["belardinelli@uni-tuebingen.de"], "doi": "10.12751/nncn.bc2013.0033", "affiliations": [{"index": "1", "address": "Computer Science Department, University of T\u00fcbingen, Germany"}], "title": "Attentional Landscapes for Object Interaction", "abstract": "Computational models of visual attention have been proposed in the last decades to prioritize and extract meaningful, interesting regions out of the bulk of visual information present in a scene, depending both on task-related and appearance-based factors. In this sense, most models focus on vision for perception and can serve as first selective processing step for object detection and recognition. Yet, similar competition issues arise when considering vision for action and, specifically, object interaction. In this case selection of \u2018actionable\u2019 points is driven by the action to be performed and the perceived affordances.\nWe conducted an eye-tracking experiment showing participants images of real-world graspable objects and asking to categorize (classification task), to pantomime lifting (lifting task) and to mime opening the objects (opening task) (Belardinelli & Butz,2013).\nMean fixation locations and attention heatmaps show different modes in gaze distribution around task-relevant locations, in accordance with previous literature and touch heatmaps (as collected via a touchscreen). \nAffording points depend both on the task and the shape of the object (for example, openings can be found on top or on sharpened parts of objects). The relation between fixation distribution according to task and object categories can be learnt by using suitable object descriptors as input vectors and the fixation or touch heatmaps as target function. We use a shape descriptor widely established in the computer vision community (Histograms Of Gradients) to encode objects global shape and Kernel Ridge Regression to learn the mapping function to the fixation distribution. Leave-one-out validation shows promising results in predicting object areas relevant for the intended task, suggesting the proposed method as suitable for predicting both attentional landscapes (Baldauf & Deubel, 2010) and contact points in object interaction, basing on a coarse shape description of daily-use objects.\n", "acknowledgements": "", "id": 131103, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Anna Belardinelli"}, {"epithet": "1", "name": "Martin V. Butz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Two examples for the 'opening' task. Left, presented stimulus. Center, fixation heat map. Right, predicted attention map.", "figpath": "033.png", "refs": "Belardinelli, A. and Butz, M.V. (2013). Gaze strategies in object identification and manipulation. Proc. of the 35th annual meeting of the Cognitive Science Society.\nBaldauf, D., & Deubel, H. (2010). Attentional landscapes in reaching and grasping. Vision Research, 50(11), 999\u2013 1013.\n"}, {"correspondence": ["stefan.ehrlich@tum.de"], "doi": "10.12751/nncn.bc2013.0034", "affiliations": [{"index": "1", "address": "Institute for Cognitive Systems, Technical University of Munich, Germany"}, {"index": "2", "address": "Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore"}], "title": "Closed-loop Brain Interactions with Affective Brain-Computer Music Interface", "abstract": "Emotions play a critical role in rational and intelligent behavior; a better fundamental knowledge is indispensable for understanding higher-level brain processes [1]. We propose a novel online Brain-Computer Interface (BCI) architecture to feedback a subject's emotional state in a way such that a closed-loop affective brain interaction is established.\n \nMusic can evoke strong emotions [2] and is commonly used in emotion research as reliable stimulus. Moreover, music is freely synthesizable (unlike e.g. pictures) and can thus serve as a continuous affective display. Based on psycho-physiological studies [3] we developed an algorithm (see Figure, (a)) capable of generating synthesized affective music, presented to a subject during initial training (see Figure, left). Brain activity is measured simultaneously via electroencephalography (EEG). Based on machine-learning techniques a model is built (see Figure, (b)), associating neural correlates with corresponding settings for the music-algorithm. In an online application (see Figure, right) the system translates the subject's brain activity in real-time into a continuous musical representation, played back to establish an affective closed-loop.\n\nWe technically validated our concept in a functional prototype, showcased on the annual event Techfest 2012 in Singapore. Fifty-four exhibition visitors tested the prototype and reported meaningful system response and achievement of control over the affective music feedback (e.g. by recalling positive and negative memories).\n\nThe proposed BCI concept provides a platform to affectively stimulate the brain in a closed-loop fashion, offering novel approaches to study emotions and related brain processes (e.g. underlying temporal dynamics). Furthermore, it opens a new field of potential medical applications, such as diagnosis and treatment of neurological disorders related to emotions (e.g. depression, schizophrenia).\n", "acknowledgements": "This work has been supported by the BrainComputerInterfaceLab (Dr. Cuntai Guan), Institute for Infocomm Research (I2R), Agency for Science, Technology and Research (A*STAR), Singapore.", "id": 131104, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Stefan Ehrlich"}, {"epithet": "2", "name": "Cuntai Guan"}, {"epithet": "1", "name": "Gordon Cheng"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Affective music BCI architecture, consisting of an initial training (left) and the online application (right). (a) Algorithm to generate synthesized music, (b) emotion model.", "figpath": "034.jpeg", "refs": "[1] Antonio Damasio. Descartes\u2019 error: Emotion, reason and the human brain. Vintage Digital, 2008.\n[2] Carol L Krumhansl. An exploratory study of musical emotions and psychophysiology. Canadian journal of experimental psychology, 51(4):336\u2013353, 1997\n[3] P. Gomez and B. Danuser. Relationships between musical structure and psychophysiological measures of emotion. Emotion, 7(2):377, 2007"}, {"correspondence": ["andreas.holzbach@tum.de"], "doi": "10.12751/nncn.bc2013.0035", "affiliations": [{"index": "1", "address": "Institute for Cognitive Systems, TU M\u00fcnchen, Germany"}], "title": "A Biologically-Motivated Approach to Online Learning of a Dictionary of Features from Natural Images for Computational Object Recognition", "abstract": "Ongoing neuroscientific researches on information processing in the brain have gained sufficient knowledge to build simple computational models, which simulate the neuronal behaviour. However, there are still only a few applications that make use of the potential of neurobiological findings, although this could lead to a new generation of technical systems, which can exceed the capabilities of state-of-the-art systems. \n\nWith our research we aim to pursue the integration of neural information processing functionality into technical systems like humanoid robots.  Our system is based on HMAX, initially proposed by Serre, Wolf and Poggio, which models the ventral pathway in the areas of the visual cortex. It uses a set of patches as a so-called dictionary for the generation of feature vectors for classification. These patches can be seen as fixed and tuned artificial neurons, which react to certain stimuli. In the standard HMAX model, this set is created randomly over a set of images. Naturally this results in a non-optimal set with overrepresented and redundant features. \n\nOur method is motivated by the functionality of lateral-inhibition in neurons. We imitate this behaviour by allowing only one feature in our set to react to certain stimuli, while the other features remain under a certain response. With this method we gain a greater  representation in form of redundancy and a more distinct response to visual input, which enhance the training of a classifier. This gives us the advantage to choose any setting between a.) speeding up the computation by reducing the size of the dictionary while keeping the classification accuracy at the same level; and b.) keep the size of the dictionary gaining better classification accuracy when needed. The learning procedure is performed online by feeding the system with a continuing stream of natural images of positive and negative training examples until the dictionary is fully trained.", "acknowledgements": "This work was supported (in part) by the DFG cluster of excellence \u2019Cognition for Technical systems CoTeSys\u2019 of Germany, and also (in part) BMBF through the Bernstein Center for Computational Neuroscience Munich (BCCN-Munich).", "id": 131105, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Andreas Holzbach"}, {"epithet": "1", "name": "Gordon Cheng"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Object Classification System", "figpath": "035.png", "refs": "[1] T. Serre, L. Wolf, S. Bileschi, M. Riesenhuber, and T. Poggio, \u201cRobust\nobject recognition with cortex-like mechanisms.\u201d IEEE transactions on\npattern analysis and machine intelligence, vol. 29, no. 3, pp. 411\u201326,\n2007. "}, {"correspondence": ["maja.sarevska@rub.de"], "figid": 36, "doi": "10.12751/nncn.bc2013.0036", "affiliations": [{"index": "1", "address": "Faculty of Psychology, Ruhr University, Germany"}], "title": "Robustness of sequence association in a two-layer feedforward network", "abstract": "Abstract: Replay of sequential activity patterns in the hippocampus has been proposed as a mechanism for the consolidation of episodic memories [1,2]. It is thought that replay sequences that are first generated in area CA3 trigger neuronal sequences downstream, e.g., in CA1 and neocortex. However, under physiological conditions internal noise or external interference are likely to corrupt the precise sequential ordering of neuronal sequences [3]. It remains an open question how robustly the activation of a corrupted sequence in one brain area can induce the associated sequence in the second area. Here we study this question in a two-layer feedforward network that stores the association between two sequences in the two layers [4,5]. While keeping the synaptic weights fixed, we degrade the input sequence incrementally and observe the sequence induced in the output layer. We measure the similarity of sequences with the Spearman rank-order correlation. Surprisingly, we find that even when the input sequence is highly corrupted, the retrieved output sequence is similar to the associated sequence. This result is specific to the stored association and not found for random sequences. As expected, noise in the neural activity decreases the robustness of sequence association. The robustness is preserved when the synapses between the layers remain plastic during testing with the corrupted sequences because weight changes after the initial learning period are low. When we introduced recurrent connections into the output layer, which also store aspects of the output sequence, we found that robustness of sequence association is further increased. Our work shows that neuronal sequences in one area can robustly trigger sequences in a second area if the association between the sequences is stored in the network. It is therefore possible that sequential replay generated in CA3 could drive associated sequences in downstream areas during systems consolidation.\n\nKeywords: Sequential replay; Robustness; Sequence association; Two-layer network; Consolidation\n", "acknowledgements": "", "id": 131106, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Maja Sarevska"}, {"epithet": "1", "name": "Sen Cheng"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] L. Buhry, A. H. Azizi and S. Cheng (2011), Neural Plasticity, 2011:1-11 .\n[2] M. F. Carr, S. P. Jadhav and L. M. Frank (2011), Nature Neuroscience, 14:147-153.\n[3] P. A. Cariani (2004), IEEE Transactions on Neural Networks/IEEE Neural Networks Council, 15(5):1100\u20131111.\n[4] S. O. V. Flores, M. Bodner and B. Ermentrout (2011), J Comput Neurosci, 32(3):403-423. \n[5] J. Karbowski and G. Ermentrout (2002), Physical Review E, 65(3):1\u20135."}, {"correspondence": ["marta.bisio@iit.it"], "doi": "10.12751/nncn.bc2013.0037", "affiliations": [{"index": "1", "address": "Department of Neuroscience and Brain Technology, Istituto Italiano di Tecnologia (IIT), Genova, Italy"}], "title": "Characterization of electrophysiological activity of confined neuronal populations during development", "abstract": "The development of in vitro models of patterned neuronal networks is of significant interest in the neuroscientific community and requires the convergence of electrophysiological studies with micro/nano-fabrication of adapted devices. Neuronal assemblies coupled to Micro Electrode Arrays (MEAs) constitute a peculiar neurobiological model for investigating the strategies employed by the brain to represent and process information.\nConsidering the multitude of connections arising in un-patterned neuronal cultures, the constraint imposed to neurite outgrowth along specific pathways ensures a considerable control over network complexity. Indeed, in vitro models should be intrinsically modular, in order to provide a \u2018simplified\u2019 but plausible representation of in vivo nervous systems.\nIn order to facilitate the realization of reproducible patterned assemblies, a technique to induce self-organization of networks into two clusters connected by two macro-channels (50-100 \u03bcm width), on commercially available MEAs, has been developed. The spontaneous activity has been recorded during the development of patterned networks, from a few days up to 8 weeks. Unlike in vivo networks, in which multiple activation pathways impinge on any recorded region, these partially confined networks can be studied in a controlled environment. Moreover these networks exhibit synchronized events at later stages of the development with respect to homogeneous cultures.\nThe obtained results constitute important evidence that engineered neuronal networks are a powerful platform to systematically approach questions related to the dynamics of neuronal assemblies. Moreover, this engineered system can be easily interfaced to artificial artifacts in order to investigate coding properties towards the final goal of integrating brains and machines.", "acknowledgements": "The authors wish to thank Dr Marina Nanni and Claudia Chiabrera for the technical assistance in cell preparation.\nThe research leading to these results has received funding from Fondazione Istituto Italiano di Tecnologia and the EU Seventh Framework Programme FET Young Explorers (#284772 BRAIN BOW).", "id": 131107, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Marta Bisio"}, {"epithet": "1", "name": "Alessandro Bosca"}, {"epithet": "1", "name": "Luca Berdondini"}, {"epithet": "1", "name": "Michela Chiappalone"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "A. A detail of a patterned network. B. A raster plot of the spontaneous activity of a patterned network, showing both synchronous and asynchronous events.", "figpath": "037.png", "refs": ""}, {"correspondence": ["pjthomas@case.edu"], "figid": 38, "doi": "10.12751/nncn.bc2013.0038", "affiliations": [{"index": "1", "address": "Case Western Reserve University, United States"}], "title": "A Dynamical Architecture for Responding to Unpredictable Mechanical Loads During Rhythmic Behavior", "abstract": "Although many animals generate rhythmic motor behaviors when the\nenvironment is not changing, animals can respond rapidly and\nappropriately to unpredictable changes, for example, walking through\nmuddy or swampy terrain where each step may vary. A typical simplifying\nassumption is that the operating conditions are stationary, allowing\napproximation of the system as a limit cycle. Incorporating\nnonstationarity arising from environmental variability enriches the\nproblem mathematically and experimentally. Decomposition of rhythmic\nbehaviors into functional components, e.g. via fast/slow analysis,\nallows one to begin to explore differential sensitivity of a cycle to\nperturbations that may act differently depending on the phase (Shaw et al 2012). We have\nexplored a dynamical architecture based on stable heteroclinic channels\n(SHCs), i.e. a sequence of saddle equilibria whose unstable and stable\nmanifolds intersect to form an invariant circle. We develop a nominal\nneuromechanical model that can vary from smooth limit cycle (LC)\ndynamics to a stable heteroclinic channel. Using this model, we find\nthat mechanical perturbations at a particular phase of the cycle are\nbetter accommodated by the SHC than the LC. However, because the SHC\ndepends on sensory input to drive it from one saddle point to the next,\ncomplete removal of sensory input leads to greater slowing of cycle\ntimes for the SHC than the LC. We compare these predictions to data from\nthe feeding apparatus of the marine mollusk Aplysia californica, and\nshow that (a) the response to increased mechanical loading is a slowing\nof a single phase of the pattern generator (the retraction phase), and\n(b) removal of sensory input (in reduced preparations or the isolated\nganglia controlling feeding) lead to overall slowing of all phases of\nthe motor pattern. These results may be of general interest for\nunderstanding other pattern generators that must be sensitive to\nunpredictable loads at different points in their cycles.", "acknowledgements": "Supported by National Science Foundation grant DMS-1010434, the Council for the International Exchange of Scholars, and the Simons Foundation.", "id": 131108, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Peter Thomas"}, {"epithet": "1", "name": "Kendrick Shaw"}, {"epithet": "1", "name": "Hillel Chiel"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "(Shaw et al 2012): KM Shaw, YM Park, HJ Chiel, PJ Thomas. Phase resetting in an asymptotically phaseless system: On the phase response of limit cycles verging on a heteroclinic orbit. SIAM J. Appl. Dyn. Syst., 11(1), 350\u2013391."}, {"correspondence": ["claussen@inb.uni-luebeck.de"], "figid": 39, "doi": "10.12751/nncn.bc2013.0039", "affiliations": [{"index": "1", "address": "University of Luebeck, Germany"}], "title": "Sleep and wake stage switching: Extended diffusion model", "abstract": "The mammalian brain daily undergoes macroscopic state changes of consciousness from wakefulness to sleep and back. The quantitative assessment of sleep stages as well as their modeling remains a problem persitently difficult to tackle. Short awakenings during the night occur even during sleep of healthy subjects. These occur with peculiar statistics that cannot be well reproduced bu current models. Here we refer to a diffusion model and apply modifications to obtain an improved fit to the data. To approach this question, we analyze human sleep data consisting of manually scored hypnograms according to Rechtschaffen and Kales rules. We analyze the distribution of sleep and wake bout durations following the approach by [1]. In modification of the modeling approach in [1], we apply two modifications to the dynamics [3], namely an extension for REM sleep, and a modification to the restoring force within the wake state. From our model, we derive simulated sleep awakening statistics. We report consistency of sleep bouts with an exponential distribution, consistent with previous studies. Concerning the wake bout durations, our data suggests a fit by two power laws seperately. This is consistent with the results reported in  [3] but contradicts other studies [1]. Our results can give indications in which directions phenomenological models like the diffusion model are to be modified, and to indentify the neurophysiological mechanisms that lead to the non-trivial state switching statistics.\n", "acknowledgements": "", "id": 131109, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Anna Barkentien"}, {"epithet": "1", "name": "Jens Christian Claussen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] C.-C. Lo, L. A. Nunes Amaral, S. Havlin, P. Ch. Ivanov, T. Penzel, J.-H.\nPeter, and H. E. Stanley.  Dynamics of sleep-wake transitions during sleep. Europhysics Letters, 57, 631, 2002.\n[2] J. W. Kim, J. -S. Lee, P. A. Robinson, D. -U. Jeong, Markov Analysis of Sleep Dynamics. Phys. Rev. Lett. 102, 2009.\n[3] A. Barkentien and J. C. Claussen (in preparation)\n\n"}, {"correspondence": ["schellenberger@inb.uni-luebeck.de"], "figid": 40, "doi": "10.12751/nncn.bc2013.0040", "affiliations": [{"index": "1", "address": "University of L\u00fcbeck, Germany"}], "title": "A neural mass model of the thalamo-cortical system during sleep", "abstract": "Sleep has been shown to be crucial for the consolidation of memories. Furthermore consolidation of declarative memory\ncan be enhanced significantly by electric or sensory stimulation (Marshall2006, Ngo2013). The thalamo-cortical\nsystem is responsible for the generation of sleep phenomena seen in the EEG e.g. slow waves and spindles. Hence, a\ndetailed understanding of its dynamical properties is needed to explain the effect of stimuli on the sleeping\nbrain. Neural mass models have been extensively used to investigate the dynamic behaviour of brain networks on a\nstructural level (Ursino 2010 Sotero 2007, Bhattacharya 2011). Although they are able to show rhythmic behavior\nsimilar to that seen in the brain, the models lack the hallmarks of sleep e.g spindles. This can be explained by the\nsole focus on synaptic interaction between neural populations, while neglecting their intrinsic properties.\nHowever, specific currents are crucial for the generation of spindle activity (Destexhe 2003). Therefore we\nexpand a cortical mean field model proposed by (Steyn-Ross 2005) by a thalamic module and incorporate intrinsic\ncurrents into the cortex and the thalamus. The model closely resembles EEG data of deep sleep.", "acknowledgements": "", "id": 131110, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Michael Schellenberger Costa"}, {"epithet": "1", "name": "Arne Weigenand"}, {"epithet": "1", "name": "Thomas Martinetz"}, {"epithet": "1", "name": "Jens Christian Claussen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] L Marshall et al. Nature, 444(7119):610--3, November 2006.\n[2] HVV. Ngo et al. Neuron, Volume 78, Issue 3, May 2013\n[3] M Ursino et al. NeuroImage, 52(3):1080\u201394, September 2010.\n[4] R C Sotero et al. Neural computation, 19(2):478\u2013512, February 2007.\n[5] B S Bhattacharya et al. Neural networks, 24(6):631\u201345, August 2011.\n[6] A Destexhe et al. Physiological reviews, 83(4):1401\u201353,October 2003.\n[7] D Steyn-Ross et al. Journal of Biological Physics, 31(3-4):547\u2013569, December 2005.\n\n"}, {"correspondence": ["weigenand@inb.uni-luebeck.de"], "figid": 41, "doi": "10.12751/nncn.bc2013.0041", "affiliations": [{"index": "1", "address": "Institute for Neuro- and Bioinformatics, University of Luebeck, Germany"}], "title": "Response properties of the sleeping brain", "abstract": "Several experiments indicate a role for sleep spindles and sleep slow oscillations in the consolidation of declarative memories [1, 2, 3, 4]. \nHowever, the dissection of their different contributions to the consolidation process poses severe difficulties, as methods for their specific manipulation are rare. We developed a neural mass model that exhibits important features of brain activity in human sleep, e.g. spindles, cortical slow oscillations, gamma activity and clock-like delta oscillations, and fit this model to EEG data.\nBased on this model we find effective stimulation protocols and conditions for the induction/disruption of slow oscillations and sleep spindles. \nWe also investigate reasons for inter-individual differences in the response to sensory stimulation and learning induced changes.", "acknowledgements": "This work was supported by the Deutsche Forschungsgemeinschaft (DFG) within SFB 654 \"Plasticity & Sleep\"\nand the Graduate School for Computing in Medicine and Life Sciences funded by Germany\u2019s Excellence Initiative [DFG GSC 235/1].", "id": 131111, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Arne Weigenand"}, {"epithet": "1", "name": "Michael Schellenberger Costa"}, {"epithet": "1", "name": "Thomas Martinetz"}, {"epithet": "1", "name": "Jens Christian Claussen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Ngo HVV, Martinetz T, Born J, M\u00f6lle M. Neuron, 78(3):545-553, 2013.\n[2] Fogel SM, Smith CT. Neuroscience & Biobehavioral Reviews, 35(5):1154-1165, 2011.\n[3] Diekelmann S, Born J. Nat Rev Neurosci,11(2):114-126, 2010.\n[4] Marshall L, Born J. Trends in Cognitive Sciences, 11(10):442-450, 2007."}, {"correspondence": ["rodrigo.cofre_torres@inria.fr"], "figid": 42, "doi": "10.12751/nncn.bc2013.0042", "affiliations": [{"index": "1", "address": "INRIA Neuromathcomp Team, France"}], "title": "Can we ear the shape of a Maximum Entropy potential from a spike train ?", "abstract": "In recent years different maximum entropy models have been proposed to capture the statistics of spiking activity [1],[2]. However, little theoretical or empirical justification exist to guide the construction and selection of the set of constraints shaping the Gibbs distribution. A main drawback arising from this approach is the unclear interpretation of the effective interactions in terms of the underlying network structure and stimulus. \nThe problem can be stated as follows: assume we observe a raster plot generated by a neural network with a Markovian and stationary dynamics, we want to fit a probability distribution from raster plot using the Maximum Entropy Principle. We are faced with a priori infinitely choices to define constraints. Especially, dealing with markovian dynamics, we have to consider spatio temporal constraints. Is there a canonical way to fix the shape of potential? What are the links between the real synaptic interactions of the neural network and the \u201ceffective interactions\u201d of the potential? Can we deduce the exact form of the potential from transition probabilities? This work answer these questions. The method proposed here is based in one hand on Hammersley-Clifford theorem [3] and on the other hand on invariance of sums over periodic orbits on cohomologous potentials. This work has been inspired by the paper of Mark Pollicot and Howard Weiss \u201cFree Energy as a Dynamical Invariant\u201d (or Can You Hear the Shape of a Potential?) [4]. \nWe provide a detailed description of how the synaptic weights and stimulus in a neural network shape the form of maximum entropy potential. Our method is tested on data generated by a discrete time stochastic Integrate and Fire\nmodel with history dependence, rigorously analyzed in [5]. We compare synaptic weights to effective interactions. Our results can be used for more general neural networks models and experimental data.\n", "acknowledgements": "This work was supported by the French ministry of Research and University of Nice (EDSTIC), INRIA, ERC-NERVI number 227747, KEOPS\nANR-CONICYT and European Union Project # FP7-269921 (BrainScales), Renvision # 600847 and Mathemacs # FP7-ICT-2011.9.7.\n", "id": 131112, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Bruno Cessac"}, {"epithet": "1", "name": "Rodrigo Cofre"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] J. C. Vasquez, O. Marre, A. G. Palacios, M. J. Berry, and B. Cessac, J. Physiol. Paris 106, 120 (2012).\n[2] E. Schneidman, M. Berry, R. Segev, and W. Bialek, Nature 440, 1007 (2006).\n[3] J. M. Hammersley and P. Clifford, unpublished (1971) : http://www.statslab.cam.ac.uk/~grg/books/hammfest/hamm-cliff.pdf\n[4] M. Pollicott and H. Weiss, Communications in Mathematical Physics 240, 457 (2003).\n[5] Bruno Cessac, J. Math. Biol., 62:863-900, 2011"}, {"correspondence": ["christian.denk@tum.de"], "figid": 43, "doi": "10.12751/nncn.bc2013.0043", "affiliations": [{"index": "1", "address": "TU Munich, Germany"}, {"index": "2", "address": "University of Manchester, United Kingdom"}], "title": "Real-Time Interface Board  for Closed-Loop Robotic Tasks  on the SpiNNaker Neural Computing System", "abstract": "Various custom hardware solutions for simulation of neural circuitry have recently been developed, each focusing on particular aspects such as low power operation, high computation speed, or biologically detailed simulations. The SpiNNaker computing system has been developed to simulate large spiking neural circuits in real-time in a network of parallel operating microcontrollers, interconnected by a high-speed asynchronous interface. A potential application area is autonomous mobile robotics, which would tremendously benefit from on-board simulations of networks of tens of thousands of spiking neurons in real-time. Currently, the SpiNNaker hardware circuit boards provide a single Ethernet interface for booting, debug, and input and output of data, which results in a severe bottleneck for sensory perception and motor control signals. This poster shows a small and flexible real-time I/O-hardware interface to connect external devices such as robotic sensors and actuators directly to the fast asynchronous internal communication infrastructure of the SpiNNaker neural computing system. We evaluate performance in terms of package throughput and present a simple proof-of-concept application of a closed loop mobile robot interpreting visual data obtained using a silicon retina to approach the most salient stimulus using a Winner-Take-All network.", "acknowledgements": "", "id": 131113, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Christian Denk"}, {"epithet": "1", "name": "Francisco Llobet-Blandino"}, {"epithet": "2", "name": "Francesco Galluppi"}, {"epithet": "2", "name": "Luis A. Plana"}, {"epithet": "2", "name": "Steve Furber"}, {"epithet": "1", "name": "J\u00f6rg Conradt"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1.    Plana, L.A., Bainbridge, J., Furber, S., Salisbury, S., Shi, Y., Wu, J.: An on-Chip and Inter-Chip Communications Network for the SpiNNaker Massively-Parallel Neural Net Simulator. In: 2nd ACM/IEEE NoCS, pp. 215-216. IEEE,  (2008)\n2.    Conradt, J., Berner, R., Cook, M., Delbruck, T.: An Embedded AER Dynamic Vision Sensor for Low-Latency Pole Balancing. In: IEEE ECV, pp. 780-785. IEEE, (2009).\n"}, {"correspondence": ["indar@lsr.ei.tum.de"], "figid": 44, "doi": "10.12751/nncn.bc2013.0044", "affiliations": [{"index": "1", "address": "Neuroscientific System Theory - Technische Universit\u00e4t M\u00fcnchen, Germany"}], "title": "Optimizing Discrete Representation of Sensory Input and Motor Command in the Factor Graph", "abstract": "In the probabilistic inference mechanism like Factor Graph, a networked random variables is used for reasoning such as determining actions based on perception. This can be used for generating intelligent behavior artificially similar to neural computation: parallel distributed computing system which relies on local computation units communicating to each other. The \u201cmessage\u201d, which is basically a function of those variables, is propagated from one node to another nodes in the network. Usually it originates from the input and output part of the system. In many real world applications such as robotics, these variables take form of discrete probability distribution. One common way to represent a value in a discrete random variable is by using Kronecker delta function similar to 1-out-of-N coding scheme in digital system. In this representation, only single state is activated (i.e. the probability value of 1 is assigned for that specific state and 0 for the rests). This is also the most intuitive way to represent sensory data from a system such as a robot which utilizes probabilistic inference mechanism like Factor Graph to generate output actions. However, working with this scheme will easily encumber the computing unit, especially when involving many variables. In this work, we use discretization strategy to reduce the number of states used by the variables in the network. The strategy similar to the population coding in the sense that the encoding function has a peak value such that activity of the state  is greatest if the given value is close to the peak value, and becomes reduced accordingly for values less close to the peak value. In our method, we discretize Gaussian distribution for a given sensor value as well as the generated output value. This method has a benefit such that it also incorporates uncertainty in reading noisy sensor value. We apply this method on a 3-wheels omni-directional mobile robot to infer adequate motor commands given sensor input.", "acknowledgements": "This work is funded by German Academic Exchange Service (DAAD \u2013 Deutscher Akademischer Austausch Dienst).", "id": 131114, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Indar Sugiarto"}, {"epithet": "1", "name": "J\u00f6rg Conradt"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["cristian.axenie@tum.de"], "figid": 45, "doi": "10.12751/nncn.bc2013.0045", "affiliations": [{"index": "1", "address": "Technische Universit\u00e4t M\u00fcnchen, Germany"}], "title": "Multisensory Integration Network for Mobile Robot Self-Motion Estimation", "abstract": "Both real and artificial systems can build their spatial knowledge, using sensor fusion, by combining multiple sources of self-motion related signals (e.g. vestibular and proprioceptive signals, visual and auditory cues) [1]. Technical systems (such as mobile robots) usually employ probabilistic frameworks for sensor fusion with good results [2], but often need to balance a trade-off between algorithmic complexity and available computing resources. When investigating flexibility and robustness, neurobiology offers superior performance over today\u2019s engineered systems. We start from neuro-anatomical and neuro-physiological evidence that elementary processing functions are localized in discrete recurrently interacting cortical areas whereas complex functions are processed in parallel involving large parts of the brain, [3]. Using these principles the proposed neural network model for sensor fusion migrates from classical feed-forward computing paradigm to a loosely interconnected network of distributed computing units, each with local memory, processing and interpretation capabilities. Mutual influence among the different units that represent sensor data is based on the mathematical / physical relationships between the sensors, similar to work in [4]. Given various external sensory stimuli, the network settles into the best possible explanation of the underlying cause. The network infers which sources of information to trust by considering the mismatch between its internal belief and incoming sensor data. In this work we focus on one component of self-motion perception: heading estimation. We implement a simple test-case scenario with a 4 dimensional sensor fusion task (e.g. combining gyroscope, compass, wheel encoder and vision sensor information) for heading estimation on an autonomous mobile robot. By validating this simple scenario we expect to be able to expand this sensor fusion principle to vastly more complex tasks.", "acknowledgements": "The authors would like to thank Matthew Cook of INI, ETH/University Z\u00fcrich for intense and fruitful discussions about map based processing and networks of relations.", "id": 131115, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Cristian Axenie"}, {"epithet": "1", "name": "Jorg Conradt"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Dolins, F.L., Mitchell, R.W., Eds.: Spatial Cognition, Spatial Perception. Cambridge University Press, 2010\n2. Thrun, S. et al.: Probabilistic Robotics. MIT Press, 2005\n3. Bressler, S.L.: Understanding Cognition Through Large-Scale Cortical Networks. Current Directions in Psychological Science, Vol.11, No.2, 2002, DOI 10.1111/1467-8721.00168\n4. Cook, M., et al.: Interacting maps for fast visual interpretation. Proc. of Intl. Joint Conf. on Neural Networks, 2011, DOI 10.1109/IJCNN.2011.603329"}, {"correspondence": ["raphaelholca@gmail.com"], "figid": 46, "doi": "10.12751/nncn.bc2013.0046", "affiliations": [{"index": "1", "address": "Institute of Neuroinformatics, Uni/ETH Zurich, Switzerland"}], "title": "The shunting inhibition of back-propagating action potentials as a mechanism to impose competition between neurons", "abstract": "Already in 1973, Von der Malsburg suggested an experience-dependent mechanism that could explain the emergence of stimulus preference in a population of neurons [1]. His approach relied on a combination of correlation-based learning and reciprocal inhibition, a method that remains to this day at the core of modern models of receptive field development [2-4]. Although this approach respects several biological constraints, discrepancies with biological data exist. Importantly, alterations in the response properties of neurons are known to be sensitive to the timing of pre- and post-synaptic spikes, in a way that is consistent with spike-timing-dependent plasticity (STDP) [5-7]. This form of plasticity was also suggested to better explain receptive field plasticity than correlation-based learning [8], revealing a possible disagreement between earlier models and biology. To resolve this discrepancy, I propose an approach making use of a known interaction between inhibition and STDP. Specifically, the model relies on an abstraction of NMDA receptors (NMDARs) to detect the difference in the arrival time of a back-propagating action potential (bAP) and a pre-synaptic spike, giving rise to STDP. In this approach, inhibition, acting as a conductance shunt, suppresses the depolarization associated with a bAP, which reduces the activation of NMDARs and ultimately limits synaptic plasticity. This chain of events is consistent with numerous experimental observations [9-13] and endows inhibition with a potent means to control synaptic plasticity. I show that, when combined with spatially organized horizontal connections, this mechanism leads to the emergence of decorrelated receptive fields organized in maps that are qualitatively similar to those observed in mammalian cortices. These results demonstrate that an interaction between inhibitory conductance and a biologically realistic model of STDP is sufficient to explain the emergence of decorrelated receptive fields.", "acknowledgements": "", "id": 131116, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Raphael Holca-Lamarre"}, {"epithet": "1", "name": "Matthew Cook"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. von der Malsburg, Kybernetik, 1973\n2. Wiltschut and Hamker, Visual Neurosci., 2009\n3. Zylberberg et al., PLoS Comput. Biol., 2011\n4. Miikkulainen, et al., 2005: Springer.\n5. Schuett et al., Neuron, 2001\n6. Yao and Dan, Neuron, 2001\n7. Fu et al., Science, 2002\n8. Young et al., Nat. Neurosci., 2007\n9. Letzkus et al., J. Neurosci., 2006\n10. Sjostrom and Hausser, Neuron, 2006.\n11. Kanemoto et al., PloS one, 2011\n12. Zhou and Antic, J. Physiol., 2012.\n13. Nakayama et al., Neuron, 2012"}, {"correspondence": ["bcipolli@cogsci.ucsd.edu"], "doi": "10.12751/nncn.bc2013.0047", "affiliations": [{"index": "1", "address": "UC San Diego, United States"}], "title": "Interhemispheric connectivity endures across species, as exposed by allometric regression.", "abstract": "Two seminal papers claim that there is decreased functional (Ringo et al., 1994) and anatomical (Rilling & Insel, 1999) interhemispheric connectivity over the corpus callosum (CC) with increasing brain size, and that this decreased connectivity leads to functional lateralization.  We hypothesize that lateralization requires strong CC connectivity and previously challenged the conclusion of reduced functional CC connectivity in larger brains (Cipollini & Cottrell, 2013).  Here we challenge the conclusions of Rilling & Insel (1999) by extending and reinterpreting their work.\n\nRilling & Insel (1999) used allometric regression (log-log regression, appropriate for scale-free power-law relationships common to the brain) to relate grey matter surface area (GMSA) and CC cross-sectional area (CCA) across primates.  They found that CCA increases sub-linearly with GMSA (exponent: 0.88), suggesting that the number of CC connections (NCC) increases at a slower rate than the total number of white-matter connections (NWM).\n\nWe aimed to estimate the NCC and NWM across species directly.  Using recently published data (Wang et al., 2008), we found a power-law relationship between CC fiber density and brain weight (exponent: -0.29).  Using data from Wang et al. (2008), Rilling & Insel (1999), and Tower (1954), we found that the NCC increases at a much slower rate of NWM than estimated previously (exponent: 0.57).  \n\nWhat does this small exponent mean?  There is evidence that the number of area-area connections (AAC) increases with brain volume (exponent: 0.31; Changizi & Shimojo, 2005).  This increase represent new intrahemispheric AACs; CC connections remain largely homotopic across species.  We found that the proportion of interhemispheric AACs precisely matched the proportion of CC fibers across species (exponent: 1.04).  This suggests that the number of fibers scales similarly for interhemispheric and intrahemispheric AACs; i.e. CC fibers are not selectively reduced.", "acknowledgements": "This work was partly funded by a Center for Academic Research and Training in Anthropogeny (CARTA) fellowship and by NSF grant SMA 1041755 to the Temporal Dynamics of Learning Center, an NSF Science of Learning Center.", "id": 131117, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Ben Cipollini"}, {"epithet": "1", "name": "Garrison Cottrell"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "(a) Log-log regression of fiber density of the corpus callosum (CC) against brain weight (data from Wang et al., 2008).  Human data point was taken from Aboitiz et al. (1992) and corrected for shrinkage (reported) and age (derived from data from LaMantia & Rakic, 1990).  Human data point was not used in regression.  \n(b) Regression of ratio of interhemispheric (callosal) and intrahemispheric area-area connections on the ratio of interhemispheric (callosal) and intrahemispheric white matter fiber counts, across primate species from Rilling & Insel (1999).  The exponent is not different from unity.  When we regress on unity, we determine that the average callosal (homotopic) area-area connection has approximately 3.5-8 times more fibers than the average intrahemispheric connection.  This is true on average across the brain, and consistent across primate species.", "figpath": "047.png", "refs": "see abstract. full references did not fit in this space."}, {"correspondence": ["niklas1983@gmx.de"], "figid": 48, "doi": "10.12751/nncn.bc2013.0048", "affiliations": [{"index": "1", "address": "Technische Universit\u00e4t Berlin and Bernstein Center for Computational Neuroscience, Germany"}, {"index": "2", "address": "Humboldt-Universit\u00e4t Berlin, Germany"}], "title": "Bifurcation Analysis of a Reduced Ionic Model for Cortical Spreading Depression", "abstract": "A minimal ion-based model of neural activity is developed to analyse the fundamental mechanisms of ignition and recovery in cortical spreading depression (SD) in terms of nonlinear bifurcation theory. The model is an extended Hodgkin-Huxley membrane model with ion channels and dynamic concentrations of sodium, potassium, and chloride ions. Concentrations vary according to the transmembrane currents through active and passive ion channels, and pump currents. Extracellular potassium is further regulated by a phenomenological control term mimicking diffusion in a potassium bath and glial buffering. The minimal ion-based model of SD is reduced to four dynamic variables, which is the minimum required for an appropriate description of the bifurcation behavior. In the absence of extracellular potassium control the model shows bistability between a physiological equilibrium and a strongly depolarized inactive state. It is the effect of glial buffering that renders the system excitable (with respect to SD) rather than bistable. We further investigate the dynamical regimes for varying concentration levels of an extracellular potassium bath. Simulations show transitions from quiescence to seizure-like activity, and from seizure-like activity via tonic firing to periodic SD for increasing bath concentrations. In a bifurcation analysis we demonstrate that the observed seizure-like activity is an extremely slow transient oscillation in the ion concentrations after an applied extracellular potassium elevation. The beginning of periodic SD, however, is marked by a torus bifurcation. This shows that spreading depression falls in a manifestly different dynamical regime than firing and bursting activity. The SD threshold value for the bath concentration is about 14.1 mMol/l which is a physiologically realistic value. We investigate the dependence of this bifurcation point on the system parameters.", "acknowledgements": "We acknowledge support by the Federal Ministry of Education and Research (BMBF), Germany (Grant No. 01GQ1001B).", "id": 131118, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Niklas H\u00fcbel"}, {"epithet": "1", "name": "Eckehard Sch\u00f6ll"}, {"epithet": "2", "name": "Markus Dahlem"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Lauritzen, M.: Trends Neurosci. 10, 8 (1987)\nKager, H., Wadman, W. J. and Somjen, G. G.: J. Neurophysiol. 84, 495 (2000)\nKager, H., Wadman, W. J. and Somjen, G. G.: J. Neurophysiol. 88, 2700 (2002)\nBarreto, E. and Cressmn, J. R.: J. Biol. Phys. 37, 361 (2010)\nZandt, B. J. and ten Haken, B. and van Dijk, J. G. and van Putten, M. J.: PLoS ONE 6, e22127 (2011)"}, {"correspondence": ["pastukhov.alexander@gmail.com"], "doi": "10.12751/nncn.bc2013.0049", "affiliations": [{"index": "1", "address": "Center for Behavioral Brain Sciences, Magdeburg, Germany"}, {"index": "2", "address": "Instituci\u00f3 Catalana de Recerca i Estudis Avan\u00e7ats, Barcelona, Spain"}], "title": "Altering operating regimes of multi-stable perception", "abstract": "We have recently reported (Pastukhov et al., 2013) that multi-stable perception operates in a consistent and functionally optimal dynamical regime, which balances the conflicting goals of stability and sensitivity. In that work, with the help of a simple computational model, we deduced the operative balance of stabilizing and destabilizing factors \u2013 competition, adaptation, and noise \u2013 from the reversal statistics of individual observers (mean and variance of dominance time, correlation and time-constant of history-dependence). We further tested this approach investigating two conditions. In first condition we compared reversal statistics when axis of rotation remained stationary (baseline) and when it \u201cwobbled\u201d sideways. Latter manipulation is known to reduce neural adaptation (Blake, Sobel, & Gilroy, 2003). Our second condition was aimed at enhancing the competition. We compared perception when rotational axis was vertical (baseline) and when it was tilted front-to-back. Tilting the rotational axis front-to-back impedes reversals, as they entail sudden axis shifts (Pastukhov, Vonau, & Braun, 2012). Both manipulations altered reversal statistics significantly. Exactly as predicted, for wobbling vs. stationary axes the computational analysis revealed reduced adaptation, while in the case of tilted vs. vertical axes it showed enhanced competition. Our results confirm our earlier findings. They demonstrate that multi-stable dynamics is well described by a balance of competition, neural adaptation and neural noise. In addition, they show that the reversal statistics of individual observers faithfully reflects both normal and altered operating regimes of multi-stable perception. Our method can be a sensitive diagnostic for perceptual dynamics with potential applications for developmental and patient populations.", "acknowledgements": "The authors were supported by the BMBF Bernstein Network of Computational Neuroscience and the State of Saxony-Anhalt.", "id": 131119, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Alexander Pastukhov"}, {"epithet": "1", "name": "Jochen Braun"}, {"epithet": "2", "name": "Gustavo Deco"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "A) Dynamical model: A simple dynamical model generates a wide range of reversal statistics. Its main parameters are competition \u03b2, adaptation \u03a6a, and signal-to-noise I0. Depending on parameter values, the model generates adaptation-driven, noise-driven, or intermediate reversal sequences. B) Reversal statistics: We characterize reversal statistics in terms of mean Tdom and variance CV of dominance periods, plus correlation cH and time-constant \u03c4H of history-dependence. Values measured for a stationary vertical (red), wobbling (blue), and tilted (green) axes of rotation are shown to the right. C) Wobbling vs. stationary axis of rotation: \u2018Wobbling\u2019 the rotational axis sideways is known to reduce neural adaptation. Indeed, the reversal statistics (above) does show longer mean dominance periods Tdom and smaller history dependence cH. The computational analysis confirms reduced values of adaptation \u03a6a. D) Titled vs. vertical axis of rotation: Tilting the rotational axis front-to-back impedes reversals, as they entail sudden axis shifts. The computational analysis reveals enhanced competition \u03b2. Apparently, the small ecological likelihood of sudden axis shifts is encoded in terms of stronger competition between neural representations.", "figpath": "049.png", "refs": "Blake, Sobel & Gilroy (2003) Visual motion retards alternations between conflicting perceptual interpretations. Neuron,39(5),869\u201378.\nPastukhov, Rodriguez, Haenicke, Guillamon, Deco & Braun (2013) Multi-stable perception balances stability and sensitivity. Frontiers in Comp Neuroscience,7(17) doi:10.3389/fncom.2013.00017\nPastukhov, Vonau & Braun (2012). Believable change: bistable reversals are governed by physical plausibility. Journal of vision,12(1),17. doi:10.1167/12.1.17"}, {"correspondence": ["ralph.bourdoukan@gmail.com"], "figid": 50, "doi": "10.12751/nncn.bc2013.0050", "affiliations": [{"index": "1", "address": "Ecole Normale Sup\u00e9rieure, France"}, {"index": "2", "address": "Champalimaud Center for the Unknown, Portugal"}], "title": "Spiking networks learning to balance excitation and inhibition develop an optimal representation.", "abstract": "Cortical activity is typically irregular, asynchronous, and Poisson-like. This variability seems to be predominantly caused by a balance of excitatory and inhibitory neural input (Haider, B. et al., 2006). However, the learning mechanisms that develop this balance and the functional purpose of this balance are poorly understood. Here we show that a Hebbian plasticity rule drives a network of integrate-and-fire neurons into the balanced regime while simultaneously developing an optimal spike-based code. The remarkable coincidence of balance and optimality in our model occurs when synaptic plasticity is proportional to the prod- uct of the postsynaptic membrane potential and presynaptic firing rate. This plasticity rule acts to minimise the magnitude of neural membrane potential fluctuations. Balance develops because, without it, membrane potential fluctuations are too large. Meanwhile, an optimal representation develops because membrane potentials corre- spond to representation errors for a signal encoded by the network (Boerlin, M. and Den\u00e8ve, S., 2011). This signal may be a sensory signal or the result of some network computation. It can be extracted from the network spike trains with a fixed linear decoder (a summation of postsynaptic potentials), with a precision on the order of 1/N, where N is the number of neurons. This is much more precise than a typical rate model. Our work suggests that several of the features measured in cortical networks, such as the high trial-to-trial variability, the balance be- tween excitation and inhibition, and spike-time-dependent plasticity are all signatures of an optimal spike-based representation.", "acknowledgements": "Emmy-Noether grant of the Deutsche Forschungsgemeinschaft (CKM), Chaire d\u2019excellence of the Agence National de la Recherche (CKM, DB), James McdonnellFoundation Award (SD, RB) EU grants BACS FP6-IST-027140,BIND MECT-CT-20095-024831, and ERC FP7-PREDSPIKE (SD, RB).", "id": 131120, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Ralph Bourdoukan"}, {"epithet": "1", "name": "David Barrett"}, {"epithet": "2", "name": "Christian Machens"}, {"epithet": "1", "name": "Sophie Den\u00e8ve"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Boerlin, Martin, and Sophie Den\u00e8ve. \"Spike-based population coding and working memory.\" PLoS computational biology 7.2 (2011): e1001080.\nHaider, Bilal, et al. \"Neocortical network activity in vivo is generated through a dynamic balance of excitation and inhibition.\" The Journal of neuroscience 26.17 (2006): 4535-4545.\n"}, {"correspondence": ["a.reichenbach@ucl.ac.uk"], "doi": "10.12751/nncn.bc2013.0052", "affiliations": [{"index": "1", "address": "Institute of Cognitive Neuroscience, University College London, United Kingdom"}, {"index": "2", "address": "Computational and Biological Learning Lab, Engineering, University of Cambridge, United Kingdom"}], "title": "Computational processes underlying the integration of visual hand and target information for feedback control of reaching movements ", "abstract": "Visually guided movements rely on visual feedback from both the target and hand[1]. The classical view on feedback control is that the brain extracts estimates of target and hand position from a visual scene, calculating a difference vector used by the motor system for online corrections[2]. However, the complex computations[3] required to calculate this difference vector could be too time consuming given the tight temporal constraints[4]. We propose that the fastest feedback correction are generated by processing the two visual cues independently, combining them only at the end effector. This simpler computation might be better suited to the time demands for fast feedback control.\nWe tested these models by studying rapid visuomotor responses to combinations of hand (h) and target (t) displacements during a reaching movement (A). Because of the saturation of the response with increasing displacement size (B), we could distinguish three models using Gaussian process regression: \n1)    difference vector model (DVM):    r = f (t \u2013 h)\n2)    weighted DVM (wDVM):         r = f (t \u2013 a*h)\n3)    multi-channel model (MCM):     r = f(t) + g(h)\nt, h: shifts in target and hand position; f, g: arbitrary non-linear functions; a: weighting factor for proprioception on hand position estimate. These models allowed us to calculate each model\u2019s prediction for specific conditions (C), and overall model performance over the time course of movement (D). The early feedback response (t = 0ms) is characterized well as an additive mixture of an isolated target and cursor response (E). Therefore, the MCM captures its characteristics better than both DV models (D). In later phases of the movement correction (t = 150ms) the DV models outperform the MCM (D,F). This suggests that the brain first computes a quick but sub-optimal solution to enable rapid response onset, which is later displaced by the sophisticated calculation that enables achievement of the task goal. ", "acknowledgements": "This work was supported by a Postdoctoral Fellowship from the DFG, a Sir Henry Wellcome Postdoctoral Fellowship, and a project grant from the BBSRC (BB/J009458/1).", "id": 131121, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Alexandra Reichenbach"}, {"epithet": "2", "name": "David Franklin"}, {"epithet": "2", "name": "Sae Franklin"}, {"epithet": "1", "name": "J\u00f6rn Diedrichsen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Experimental paradigm, behavioral and modeling results. Shaded areas and error bars denote SEM across participants (n=12). A) Combination of the experimental manipulations (49 conditions in total). B) Exemplary behavioral responses to pure target displacements (see color-code in A). C) Behavioral responses (averaged over the time window marked in B) to the main diagonal (0 difference vector, see color-code in A), and the predictions of the different models (based on the data from the remaining conditions). D) Crossvalidated model performance over the time course of the reaching response. E) Data and MCM prediction for the time window at response onset (t = 0ms). See A for the 49 conditions. Warm colors represent positive responses (to the right), cold colors negative responses (to the left) (cf. B). F) Data and wDVM prediction for the time window 150ms after response onset analogue to E.", "figpath": "052.png", "refs": "1. Sarlegna F, et al. (2003) Target and hand position information in the online control of goal-directed arm movements. EBR 151\n2. Cisek P, et al. (1998) cortico-spinal model of reaching and proprioception under multiple task constraints. JCognNeurosci 10\n3. Pouget A & Sejnowski T (1997) Spatial transformations in the parietal cortex using basis functions. JCognNeurosci 9\n4. Day B & Lyon I (2000) Voluntary modification of automatic arm movements evoked by motion of a visual target. EBR 130"}, {"correspondence": ["a.maximov@fz-juelich.de"], "figid": 53, "doi": "10.12751/nncn.bc2013.0053", "affiliations": [{"index": "1", "address": "Institute of Neuroscience and Medicine (INM-6) and Institute for Advanced Simulation (IAS-6), J\u00fclich Research Centre and JARA, J\u00fclich, Germany"}, {"index": "2", "address": "Medical faculty, RWTH Aachen University, Germany"}], "title": "Toward a biologically realistic spiking model of a rodent barrel column", "abstract": "The barrel cortex is a primary sensory area of the rodent cortex which processes whisker-related information. Layer 4 of the barrel cortex contains a 2D array of thalamic-input hot spots (barrels) [1]. The cortical column corresponding to a barrel is called a \u201cbarrel column\u201d and is believed to be a basic processing unit of whisker-related information.\nThe activity patterns of the barrel cortex depend on behavioral state and sensory input. Asynchronous irregular spiking is seen during active whisking, while quiet wakefulness and anesthesia are accompanied by highly synchronous slow-wave oscillations [2]. Whisker-evoked and spontaneous activity propagates across layers in characteristic patterns [3]. Moreover, the barrel cortex is highly excitable: stimulation with only a few pulses can activate an entire barrel column for several hundred ms [4].\nWe aim to capture the minimal set of neuronal and synaptic mechanisms that reproduces membrane potential and spiking dynamics of the barrel column in various brain states. We construct a full-scale multi-layer spiking model of a barrel column without parameter scaling. The model is implemented in NEST [5] and consists of single-/multi-compartment AdEx neurons [6] connected with conductance-based synapses expressing short-term plasticity according to population-specific connection probabilities. NMDA and corresponding desensitization effects are included. Parameter values are chosen in biologically realistic ranges based on an extensive literature review.  \nSpontaneous and stimulated conditions were modeled using Poisson input and trains of high-frequency pulses, respectively. Transient thalamic stimulation kindled Layer 4 followed by Layers 2/3 and 5, with  parameters closely based on known physiology. Such realistic excitability depended on NMDA and log-normal synaptic weight distributions and was enhanced by multiple compartments. However, the suppression of excess activity requires mechanisms beyond the ones included.", "acknowledgements": "Supported by EU FP7 Grant 269921 (BrainScaleS) and the Helmholtz Association: HASB and portfolio theme SMHB.\n", "id": 131122, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Andrei Maksimov"}, {"epithet": "1", "name": "Sacha van Albada"}, {"epithet": "1,2", "name": "Markus Diesmann"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Bosman,Houweling,Owens,Tanke,Shevchouk,Rahmati,Teunissen,Ju,Gong,Koekkoek,De Zeeuw (2011) Front. Integr. Neurosci. 5:53\n[2] Gentet,Avermann,Matyas,Staiger,Petersen (2010) Neuron 65, 422\u2013435\n[3] Armstrong-James,Fox,Das-Gupta (1992) J. Neurophysiol. Vol. 68, No. 4\n[4] Beierlein,Fall,Rinzel,Yuste (2002) J. Neurosci.,  22(22):9885\u20139894\n[5] Eppler,Helias,Muller,Diesmann,Gewaltig (2008) Front Neuroinformatics 2: 12\n[6] Brette,Gerstner (2005) J Neurophysiol 94: 3637\u2013364"}, {"correspondence": ["j.schuecker@fz-juelich.de"], "doi": "10.12751/nncn.bc2013.0054", "affiliations": [{"index": "1", "address": "Inst. of Neuroscience and Medicine (INM-6) and Inst. for Advanced Simulation (IAS-6) Juelich Research Centre and JARA, Juelich, Germany"}], "title": "Static and dynamic mean-field theory of a layered macroscopic network model", "abstract": "The emergence of slow oscillations, i.e. resting state activity, was studied theoretically over the last years in case of simple network models [1]. Our goal is to extend these studies to a biological more realistic regime considering a layered macroscopic model of the macaque visual cortex, currently developed in our group [2].  \nAs a first step, the mean activity in the model is determined theoretically, based on a mean-field approach [3]. The fixed point solution is challenged by the high dimensionality of the system. Here we show that the fixed point can be found by integrating a first order exponentially relaxing quasi dynamics [4] and the predicted firing rates are in good agreement with the rates found in the full spiking simulation (Fig.1A). The results indicate a linear input-output relationship for individual populations. This raises hope that the model can be mapped to a simple system of linear equations, which will allow a stability analysis and will expose the mechanisms that lead to slow resting-state oscillations.\nIn order to study fast oscillations (gamma band), the local feedback loops of the macroscopic model have to be considered. We aim to identify the responsible loops that shape the power spectra of population signals. The high dimensionality of the macroscopic model requires a reduction to a simpler system. Recently we have developed a suitable method that maps a spiking network to an effective linear rate model [5]. For this purpose the transfer function has to be determined, quantifying how single neurons transfer synaptic input to spiking output (Fig.1B). The results indicate that the rate relaxes  with two different time constants. The reduced rate model will enable us to determine correlations in the system [5] and to identify the mechanisms and recurrent loops controlling fast oscillations.", "acknowledgements": "Partially supported by the Helmholtz Association: HASB and portfolio\ntheme SMHB, the Juelich Aachen Research Alliance (JARA), the\nNext-Generation Supercomputer Project of MEXT, and EU Grant 269921\n(BrainScaleS). ", "id": 131123, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Jannis Schuecker"}, {"epithet": "1", "name": "Moritz Helias"}, {"epithet": "1", "name": "Markus Diesmann"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Figure 1: A Firing rates in different layers of a cortical area depending on the external drive. Theory (curves) and simulation (dots). B Firing rate response (transfer function) from simulation (dots) fitted by a sum of two exponentials (curve).", "figpath": "054.png", "refs": "[1] Deco, G.,  Jirsa, V. (2012), Journal of Neuroscience, 32, 3366--3375.\n[2] Schmidt, M., van Albada, S., Bakker, R., Diesmann, M.  (2013), 10th meeting of the German Neuroscience Society, T26 10D.\n[3] Fourcaud, N., Brunel, N. (2002), Neural Computation, 14, 2057--2110.\n[4] Wong, K., Wang, X. (2006), Journal of Neuroscience, 26, 1314--1328.\n[5] Helias, M., Tetzlaff, T., Diesmann, M. (2013), New J Physics, 15, 023002."}, {"correspondence": ["eleonora.russo@zi-mannheim.de"], "figid": 55, "doi": "10.12751/nncn.bc2013.0055", "affiliations": [{"index": "1", "address": "Bernstein-Center for Computational Neuroscience, Central Institute of Mental Health, Psychiatry, Medical Faculty Mannheim of Heidelberg University, Mannheim, Germany"}], "title": "Unsupervised Procedure for Neural State Space and Trajectory Reconstruction from Multiple Single Units Recordings", "abstract": "In recent years in-vivo electrophysiological techniques for recording from multiple single units (MSU) simultaneously have expanded rapidly, and with them the possibilities for studying neural population dynamics, interactions in larger ensembles, assembly patterns, or single-trial dynamics [e.g. 1, 2]. Compared with more traditional single neuron analysis, however, this approach also bears additional challenges with regards to the mathematical-statistical analysis of the multivariate point process time series formed by MSU recordings. For instance, from the whole set of recorded units, for various technical or systems-inherent reasons, many may just contribute 'noise' and thus actually degrade attempts to reconstruct neural network dynamics or relate it to task performance (the 'pruning problem', e.g. [3]). On the other hand, even with MSU recordings, not all the neurons which essentially contribute to the network dynamics will be accessed experimentally. The information obtained on neural dynamics from MSU recordings is thus both noisy and still incomplete. \nIn our work we address these issues by defining a general unsupervised procedure for reconstructing the neural population vector dynamics from MSU recordings. On the basis of minimal prediction error criteria [4] and by delay embedding techniques [5] we establish an optimal space where neural trajectories are completely separated and unfolded. For this space we then analyze how the quality of the trajectory reconstruction is affected by noise, signal variance, correlation among neurons, dynamical non-linearity and by the dimensionality of the underlying manifold on which the dynamics develop. This new analytical technique may open a wide field of investigation for addressing theoretical hypotheses on network dynamics (e.g. computational processing by attractor ruins, heteroclinic trajectories, or latching transitions) at an experimental level.", "acknowledgements": "This work was funded through a grant from the German Ministry of Education and Research (BMBF, 01GQ1003B) and from the German Science Foundation (DFG, Du 354/6-1, Du 354/7-2).", "id": 131124, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Eleonora Russo"}, {"epithet": "1", "name": "Daniel Durstewitz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1- Durstewitz D, Vittoz NM, Floresco SB, Seamans JK, Neuron, 2010 May;66(3):438-48.\n2- Churchland MM, Cunningham JP, Kaufman MT, Foster JD, Nuyujukian P, Ryu SI, Shenoy KV, Nature, 2012 Jul; 487(7405):51-6. \n3- Hastie T, Tibshirani R, Friedman J, Springer, 2009.\n4- Vlachos I, Kugiumtzis D, Nonlinear Phenomena in Complex Systems, 2008 Sep; Vol 11 (2): 241-249.\n5- Cao L, Mees A, Judd K, Physica D, 1998 Oct, 121(1-2): 75-88."}, {"correspondence": ["ychen@bccn-berlin.de"], "figid": 56, "doi": "10.12751/nncn.bc2013.0056", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience and Charit\u00e9 \u2013 Universit\u00e4tsmedizin Berlin, Germany"}], "title": "Direct Cortical Mapping Based On Laplacian Eigenspectral Embedding", "abstract": "Cortical surface-based brain mapping has been receiving tremendous research efforts ever since the introduction of fMRI technique, particularly along with the development and availability of several cortical surface reconstructing/analyzing packages, e.g. Caret and Freesurfer. One of the most challenging issues in surface-based brain mapping method, namely intersubject alignment of cortical spaces, is commonly approached via spherical reparameterization, followed by a minimization of mean curvature discrepancies. In so doing, large metric distortions are often unnecessarily introduced and difficult to control.\n\nHere we propose a computational framework for direct cortical alignment between subjects to address this problem. Exploiting the invariant properties of the discrete Laplacian-Beltrami operator under isometric transform, we embed the surface vertices into the eigenspaces of the discrete Laplacians. The eigenspaces are then aligned with each other through a partial least square procedure. This high dimensional embedding allows us to add additional attributes on the surfaces, such as functional activities, as extra dimensions to form a generalized, unified representation. We then take the proximity in this space as a probabilistic measure for vertex-vertex correspondence, and optimize the topological consistancy via an iterative belief propagation algorithm, constrained by the geodesic structures on the original surfaces.\n\nWe applied our method on a group of 12 subjects with coritical surfaces reconstructed from high resolution structural images together with two additional fMRI data sets. Our results showed an improved intersubject alignment in terms of group-level statistical power, particularly when rich functional attributes are available. Moreover, without imposing any specific limitation on the additional attributes for alignment, our method can be readily applied to a wide range of scenarios in both functional and anatomical neuroimaging studies.", "acknowledgements": "", "id": 131125, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Yi Chen"}, {"epithet": "1", "name": "John Dylan-Haynes"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Bajaj & Xu, (2003) Anisotropic diffusion of surfaces and functions on surfaces. ACM Trans. Graphics\n2. Dubrovina & Kimmel, (2011) Approximately isometric shape correspondence by matching pointwise spectral features and global geodesic structures. Adv. Adaptive Data Ana.\n3. Felzenszwalb & Huttenlocher, (2006) Efficient belief propagation for early vision. IJCV\n4. Jain et al., (2007) Non-rigid spectral correspondence of triangle meshes. IJSM"}, {"correspondence": ["felipe.gerhard@epfl.ch"], "figid": 57, "doi": "10.12751/nncn.bc2013.0057", "affiliations": [{"index": "1", "address": "Brain Mind Institute, Ecole Polytechnique Federale de Lausanne (EPFL), Lausanne, Switzerland"}, {"index": "2", "address": "Biology Department and Volen Center, Brandeis University, Waltham, MA, United States"}, {"index": "3", "address": "Department of Mathematics and Statistics, Boston University, Boston, MA, United States"}], "title": "Successful reconstruction of a physiological circuit with known connectivity from spiking activity alone", "abstract": "Identifying the structure and dynamics of synaptic interactions between neurons is the first step to understanding neural network dynamics. The presence of synaptic connections is traditionally inferred through the use of targeted stimulation and paired recordings or by post-hoc histology. More recently, causal network inference algorithms have been proposed to deduce connectivity directly from electrophysiological signals, such as extracellularly recorded spiking activity. Usually, these algorithms have not been validated on a neurophysiological data set for which the actual circuitry is known. Recent work has shown that traditional network inference algorithms based on linear models typically fail to identify the correct coupling of a small central pattern generating circuit in the stomatogastric ganglion of the crab Cancer borealis. In this work, we show that point process models of observed spike trains can guide inference of relative connectivity estimates that match the known physiological connectivity of the central pattern generator up to a choice of threshold. We elucidate the necessary steps to derive faithful connectivity estimates from a model that incorporates the spike train nature of the data. We then apply the model to measure changes in the effective connectivity pattern in response to two pharmacological interventions, which affect both intrinsic neural dynamics and synaptic transmission. Our results provide the first successful application of a network inference algorithm to a circuit for which the actual physiological synapses between neurons are known. The point process methodology presented here generalizes well to larger networks and can describe the statistics of neural populations. In general we show that advanced statistical models allow for the characterization of effective network structure, deciphering underlying network dynamics and estimating information-processing capabilities.", "acknowledgements": "FG is supported by SNSF 200020-132871 and BrainScaleS, EU-FP7-269921. EM and GJG are supported by NIH grant MH 46742. TK is supported by NIH grant F32 NS099590. UE is supported by NSF grant IIS 0643993 and NINDS grant R01 NS073118 and MK and UE acknowledge joint support by NINDS grant R01 NS072023.", "id": 131126, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Felipe Gerhard"}, {"epithet": "2", "name": "Tilman Kispersky"}, {"epithet": "2", "name": "Gabrielle J Gutierrez"}, {"epithet": "2", "name": "Eve Marder"}, {"epithet": "3", "name": "Mark Kramer"}, {"epithet": "3", "name": "Uri Eden"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["cc511@cam.ac.uk"], "doi": "10.12751/nncn.bc2013.0058", "affiliations": [{"index": "1", "address": "University of Cambridge, United Kingdom"}], "title": "Summarising the temporal correlations of spike trains- a review and a novel measure.", "abstract": "Voltage recordings from multi-electrode arrays (MEAs) have shown temporal and spatial correlations in spike trains of neurons in many systems. When analysing this data, the temporal correlation is frequently summarised with one value, as opposed to fitting a cross-correlation function, so that the effect of a different variable can be investigated (e.g. the spatial correlation). An early study of spontaneous activity in the developing retina (Wong et al, 1993) proposed a measure to summarise temporal correlation with one value,and it has since been frequently used in analysis of multiple spike trains. However, we show that this popular measure has several problems, e.g. such that spike patterns that appear quite different have similar correlation patterns (Demas et  al, 2006). \n\nIn addition to this measure, there is a wide literature proposing measures to summarise the temporal relationship between two spike trains, which can be applied to a variety of data but which appear to be less frequently used when analysing spike train data from MEAs. Our aim is to find a measure which can be used on MEA data in place of the Wong et al (1993) measure without the problems that have been highlighted. We draw up a list of properties which a measure should have to be able to summarise temporal correlations, and then test a large number of measures from the literature against these criteria. We also construct a novel measure, designed to have the required properties and then test this measure \"blindly\" along with previously published measures against a large amount of recordings from MEAs in order to recommend a more suitable measure for analysing spike-train data.\n\n", "acknowledgements": "This work is supported by an EPSRC PhD studentship.  We thank the following groups for providing their data: Leo Chalupa, David Feldheim, Marla Feller, Evelyne Sernagor, Rachel Wong.", "id": 131127, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Catherine S Cutts"}, {"epithet": "1", "name": "Stephen J Eglen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Retinal waves generate distance-dependent correlations in retinal ganglion cells. This is characterised by computing the correlation index for any given pair of electrodes on an MEA, and plotting the correlation as a function of distance separating those two electrodes. The data shown is from Wong et al, 1993 and from P0 Ferret retina. A description of the correlation index proposed in this study is also given.\n", "figpath": "058.png", "refs": "Transient period of correlated bursting activity during development of the mammalian retina. Wong RO, Meister M, Shatz CJ. Neuron 1993 Nov;11(5):923-38 doi:10.1016/0896-6273(93)90122-8\n\nFailure to maintain eye-specific segregation in nob, a mutant with abnormally patterned retinal activity. Demas J, Sagdullaev BT, Green E, Jaubert-Miazza L, McCall MA, Gregg RG, Wong RO, Guido W. Neuron 2006 Apr20;50(2):247-59 doi:10.10.16/j,neuron.2006.03.033\n"}, {"correspondence": ["d.dahmen@fz-juelich.de"], "doi": "10.12751/nncn.bc2013.0059", "affiliations": [{"index": "1", "address": "Inst. of Neuroscience and Medicine (INM-6) and Inst. for Advanced Simulation (IAS-6), J\u00fclich Research Center and JARA, 52425 J\u00fclich, Germany"}, {"index": "2", "address": "Dept. of Mathematical Sciences and Technology, Norwegian University of Life Sciences, \u00c5s, 1432, Norway"}, {"index": "3", "address": "Dept. of Computational Biology, Royal Institute of Technology (KTH), Stockholm 10044, Sweden"}], "title": "From spiking point-neuron networks to LFPs: a hybrid approach", "abstract": "The local field potential (LFP), the low-pass filtered extracellular potential, is a common measure of neural activity. Cortical LFPs seem to mainly stem from synaptic inputs, but the net LFP signal from several contributing laminar populations is difficult to interpret, as the individual contributions depend on the locations and morphologies of the postsynaptic neurons, the spatial distribution of active synapses, and the level of correlations in synaptic inputs [1]. While most comprehensive cortical-network simulations are done with single-compartment models [2], multicompartmental neuronal modeling is in general required to calculate LFPs [1].  Here we present a hybrid LFP modeling approach where a network of single-compartment LIF neurons generates the spiking activity (Fig. 1A), while detailed multicompartment neuronal models are used to calculate the accompanying LFP (Fig. 1B-C). Our model describes a 1mm2 patch of cat V1 cortex. It accounts for spatially specific pre- to post-synaptic inter- and intra-layer connectivity constrained by experimental observations [3] using reconstructed neuron morphologies of excitatory and inhibitory neurons in layers L2/3-L6 with passive membrane properties. Model specifications of neuron and synapse numbers within populations are taken from [2], while spatial connectivity profiles are based on [3]. Our hybrid framework allows detailed analysis of how the LFP correlates with the network activity and connectivity, and how spatially specific synapse distributions influence the LFP. Spiking network simulations [2] were implemented in NEST (http://www.nest-initiative.org), while simulations of LFPs from morphologically realistic neurons used LFPy (http://compneuro.umb.no/LFPy) along with NEURON [4]. This work was also presented at CNS 2013 and INCF 2013.", "acknowledgements": "This work has received funding from the Helmholtz Association: HASB and portfolio theme SMHB, the J\u00fclich Aachen Research Alliance (JARA), the European Union Seventh Framework Programme (FP7/2007-2013) under grant agreement no.269921(BrainScaleS) and the Research Council of Norway (eNeuro, Notur). ", "id": 131128, "topic": "Neural encoding and decoding", "figid": 59, "authors": [{"epithet": "1", "name": "David Dahmen"}, {"epithet": "2", "name": "Espen Hagen"}, {"epithet": "2", "name": "Maria Stavrinou"}, {"epithet": "3", "name": "Henrik Lind\u00e9n"}, {"epithet": "1", "name": "Tom Tetzlaff"}, {"epithet": "1", "name": "Sacha van Albada"}, {"epithet": "1", "name": "Markus Diesmann"}, {"epithet": "1", "name": "Sonja Gr\u00fcn"}, {"epithet": "2", "name": "Gaute T. Einevoll"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Lind\u00e9n H. et al.(2011). Modeling the spatial reach of the LFP. Neuron. doi: 10.1016/j.neuron.2011.11.006\n2. Potjans TC., Diesmann M (2012). The Cell-Type Specific Cortical Microcircuit. Cereb Cortex. doi: 10.1093/cercor/bhs358.\n3. Binzegger T. et al. (2004). A quantitative map of the circuit of cat primary visual cortex. J Neurosci. doi: 10.1523/\u200bJNEUROSCI.1400-04.2004\n4. Hines ML. et al (2009). Neuron and Python. Front NeuroInf (2009) 3:1-12. doi: 10.3389/neuro.11.001.2009"}, {"correspondence": ["cesare.parise@uni-bielefeld.de"], "figid": 60, "doi": "10.12751/nncn.bc2013.0060", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience (Tuebingen) & Max Planck Institute for Biological Cybernetics & University of Bielefeld, Germany"}, {"index": "2", "address": "University of Bielefeld, Germany"}, {"index": "3", "address": "University of Bielefeld & Bernstein Center for Computational Neuroscience (Tuebingen), Germany"}], "title": "On pitch-elevation mapping: Nature, nurture and behaviour", "abstract": "The association between sound frequency and spatial elevation is a remarkable example of cross-dimensional sensory mapping. In a wide range of cognitive, perceptual, attentional, and linguistic functions, humans consistently display a positive, sometimes absolute, association between sound frequency and spatial elevation, whereby increasing frequency is mapped to increasing elevation. However, a comprehensive account for the origins of such a pervasive cross-dimensional link is still missing. Here we demonstrate that the frequency-elevation mapping observed in human behaviour is already present in both the statistics of the acoustic stimuli in the environment, and in the filtering properties of the external ear. Specifically, we singled out the effects of head- and world-centred elevation and, through a combined analysis of environmental sounds and anthropometric measures, we show that, (1) in world-centred coordinates, high sounds are statistically more likely to come from higher elevations; moreover, (2) due to the external ear, sounds coming from higher head-centred elevations have more energy at high frequencies. To link these findings to human cognition, in a psychophysical task observers localized narrow band noises with different central frequencies, while head- and world-centred elevations were put into conflict by tilting participants\u2019 body. Sound frequency systematically biased localization in both head- and world-centred coordinates in agreement with the mappings measured in the ear and the environment. We argue that, in a shorter timescale, humans learn the statistics of the auditory signals; while, in a longer timescale, evolution might tune the filtering properties of the external ear to the statistics of the acoustic environment.", "acknowledgements": "", "id": 131129, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Cesare Parise"}, {"epithet": "2", "name": "Katharina Knorre"}, {"epithet": "3", "name": "Marc Ernst"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["axel@neuro.uni-bremen.de"], "figid": 61, "doi": "10.12751/nncn.bc2013.0061", "affiliations": [{"index": "1", "address": "Computational Neuroscience, Institute for Theoretical Physics, University of Bremen, Germany"}, {"index": "2", "address": "Center for Cognitive Sciences, University of Bremen, Germany"}], "title": "Contour integration in static and dynamic scenes ", "abstract": "Contour integration is an integral part of visual information processing which requires observers to combine colinear and cocircular edge configurations into coherent percepts. Psychophysical experiments have shown that humans are efficient in these tasks, reaching considerable contour detection performances for presentation times as low as 20ms. These studies have mainly used static stimulus which are briefly flashed, or shown for an extended period. However, in nature we rarely encounter brief presentations of a visual scene, rather, we observe a scene for an extended period and develop a coherent picture which takes into account dynamic elements. It is unknown how contour integration is performed in dynamic situations, and how top-down cognitive processes, such as selective attention, interact with bottom-up feature integration. \n\nWe investigate contour integration in dynamic stimulus configurations where slowly rotating Gabor elements generate dynamic contours at different times and locations on a screen. Preliminary results suggest that contours are better detected in flashed presentations of 200ms than in long presentations containing the same arrangements. Thus, contours 'pop-out' only when there is a sudden change in a visual scene, from a grey background to a field of Gabors, but require sustained attention to be detected in dynamic scenes. ", "acknowledgements": "This work has been supported by the BMBF (Bernstein Award Udo Ernst, grant no. 01GQ1106)", "id": 131130, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Axel Grzymisch"}, {"epithet": "2", "name": "Cathleen Grimsen"}, {"epithet": "1", "name": "Udo Ernst"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["daniel@neuro.uni-bremen.de"], "figid": 62, "doi": "10.12751/nncn.bc2013.0062", "affiliations": [{"index": "1", "address": "Neurophysics, University of Bremen, Germany"}], "title": "A model for selective visual attention predicts information gating and biased competition", "abstract": "Selective visual attention allows to focus on relevant information, and to ignore distracting features of a visual scene. These principles of information processing are reflected in response properties of neurons in visual area V4: If a neuron is presented with two stimuli in its receptive field, and one is attended, the neuron responds as if the non-attended stimulus was absent (biased competition [1,2]). Attention is thus assumed to selectively promote information transfer between visual areas. Recent experiments support this idea by showing that V4 local field potentials are correlated with a temporal modulation of the attended stimulus and not with the temporal modulation of a non-attended stimulus in the same receptive field (gating [3]).\n\nSeveral models were proposed to explain the effect of biased competition and gating separately [4,5]. In order to explain these results in one coherent framework, we present a two-layer spiking cortical network model with converging feed-forward connections. Each layer encompasses two populations with lateral connectivity that engage in oscillatory activity upon activation. We assume attention to manifest as an additional input to one population in the 1st layer. Deployment of attention results in a bias of firing rates between the 1st layer populations. This bias induces a phase relation between the 1st and the 2nd layer that is more suitable for information transmission from the attended stimulus. We systematically investigate the parameter space in a biologically plausible regime and show that this mechanism is capable to explain both, the biased competition effect of the firing rate, and selective gating of information. We thus propose a combination of cortical network topology, neuronal population dynamics, and selective additional input as putative neural underpinnings of attention.", "acknowledgements": "This work was supported by the BMBF (Bernstein Award Udo Ernst, grant no. 01GQ1106)", "id": 131131, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Daniel Harnack"}, {"epithet": "1", "name": "Klaus Pawelzik"}, {"epithet": "1", "name": "Udo Ernst"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Moran J, Desimone R, Science 1985, 229:782-784. \n2. Reynolds JH, Chelazzi L, Desimone R, J Neurosci 1999, 19:1736-1753.\n3. Grothe I, Neitzel SD, Rotermund D, Mandon S, Linke M, Ernst UA, Pawelzik KR, Kreiter AK,  Program No. 913.18. 2012 Neuroscience Meeting Planner. New Orleans, LA: Society for Neuroscience, 2012. Online.\n4. Zeitler M, Fries P, Gielen S,  J Comput Neurosci 2008, 25:89-107.\n5. Montijn JS, Klink PC, van Wezel RJA,  Front Neural Circuits 2012, 6:22."}, {"correspondence": ["nergis@neuro.uni-bremen.de"], "figid": 63, "doi": "10.12751/nncn.bc2013.0063", "affiliations": [{"index": "1", "address": "Institute for Theoretical Physics, University of Bremen, Germany"}], "title": "Improved information processing under attention is explained by phase transitions in cortical dynamics", "abstract": "Attention improves processing of visual stimuli and is required for perceiving complex shapes and objects (e.g. [1]). Electrophysiological studies investigating the neural correlates of selective visual attention revealed a strong increase of oscillations in the gamma frequency band (35-90 Hz) in visual cortical neurons [2]. This indicates that gamma oscillations are relevant for optimizing information processing under attention, but their functional role is currently not understood. Here we explore the relationship between increased synchrony and stimulus representation in a network of integrate-and-fire neurons. By increasing the efficacy of recurrent couplings, attention enhances spontaneous synchronization and renders activation patterns for different external stimuli more distinct. This result is in good agreement with recent experimental evidence [3]. Combining mathematical analysis of the network dynamics with parametric simulations reveals that the effect is particularly strong at the phase transition from a state of irregular activity towards a synchronized state. At this point, power-law distributions of synchronous events (avalanches) occur, which are characteristic for so-called 'critical' states previously observed in cortical cultures [4]. If cortical networks indeed operate at such a critical point, fine modulations of synaptic strengths lead to dramatic enhancements of stimulus representations, suggesting a functional role for synchronization and criticality in cortical information processing.", "acknowledgements": "", "id": 131132, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Nergis Tomen"}, {"epithet": "1", "name": "Udo Ernst"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Posner MI, Snyder CR, Davidson BJ (1980) Journal of Experimental Psychology: General 109:160-174.\n[2] Fries P, Reynolds JH, Rorie AE, Desimone R (2001) Science 291:1560-1563.\n[3] Rotermund D, Taylor K, Ernst UA, Kreiter AK, Pawelzik KR (2009) The Journal of Neuroscience 29:10120-10130.\n[4] Beggs JM, Plenz D (2003) The Journal of Neuroscience 23:11167-11177."}, {"correspondence": ["thomas.baden@uni-tuebingen.de"], "figid": 64, "doi": "10.12751/nncn.bc2013.0064", "affiliations": [{"index": "1", "address": "BCCN/CIN T\u00fcbingen/Inst. Opthalmic Res., Germany"}, {"index": "2", "address": "BCCN/CIN T\u00fcbingen, Germany"}, {"index": "3", "address": "CIN, Graduate Training Centre of Neuroscience, T\u00fcbingen, Germany"}, {"index": "4", "address": "BCCN/CIN, MPI Biol. Cybernetics, T\u00fcbingen, Germany"}], "title": "What the mouse eye tells the mouse brain: Recording the entire visual representation along the vertical pathway in the retina", "abstract": "Right at the first synapse, the stream of incoming visual information is split into multiple parallel channels, represented in the retina by different kinds of photo\u00acreceptors (PRs), bipolar cells (BCs) and ganglion cells (RGCs). Complex circuits and, in particular, synaptic interactions in the retina\u2019s two synaptic layers tune these channels to distinct sets of visual features. Cracking the \u201cretinal code\u201d, that is understanding how the visual scenery is encoded by the outputs of the ~20 RGC types, is a major aim of vision research. \nHere, we study the signal at different processing stages of the retinal signal channels by recording from the majority of cells in the vertical cone photoreceptor pathway, including PR, BC[1] and RGC types[2]. We use 2P imaging in the mouse retina to measure Ca2+ activity evoked by a comprehensive set of stimuli, including frequency/contrast modulated full-field and white noise stimuli. So far our database contains recordings of ~100 BCs and >7,000 RGCs. In addition, we started with electrical single-cell RGC measurements, which provide us with ground truth data about spiking activity underlying Ca2+ signals and anatomical descriptions that can be compared with published RGC catalogues. \nWe have implemented a probabilistic framework for clustering RGCs into functional types based on their responses to different visual stimuli. Clustering is refined and verified by employing reference data (e.g. soma size/shape and retinal tiling). A similar approach allowed us to cluster BC responses into 8 morpho-functional clusters[1]. For RGCs (and displaced amacrine cells), ~25-29 functional clusters can be distinguished, some of which were already verified using our single cell data (e.g. alpha RGCs). \nOur results suggest that this dataset allows us to study the computations performed along the retina\u2019s vertical pathway and to obtain a complete sample of the information the mouse eye sends to the mouse brain. \n", "acknowledgements": "Centre for Integrative Neuroscience (DFG EXC307), T\u00fcbingen; Bernstein Centre for Computational Neuroscience T\u00fcbingen (BMBF FKZ 01GQ1002); Baden-W\u00fcrttemberg Stiftung (AZ 1.16101.09); fort\u00fcne program, Medical Faculty of the University T\u00fcbingen.", "id": 131133, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,*", "name": "Tom Baden"}, {"epithet": "2,*", "name": "Philipp Berens"}, {"epithet": "3", "name": "Katrin Franke"}, {"epithet": "3", "name": "Miroslav Rezac"}, {"epithet": "4", "name": "Matthias Bethge"}, {"epithet": "1", "name": "Thomas Euler"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Baden T, Berens P, Bethge M, Euler T (2013) Curr Biol 23(1):48-52\n[2] Auferkorte ON, Baden T, Kaushalya SK, Zabouri N, Rudolph U, Haverkamp S, Euler T (2012) PLoS One 7:e35109.\n"}, {"correspondence": ["miroslav.rezac@gmx.de"], "figid": 65, "doi": "10.12751/nncn.bc2013.0065", "affiliations": [{"index": "1", "address": "Centre for Integrative Neuroscience (CIN), Graduate Training Centre of Neuroscience, University of T\u00fcbingen, Germany"}, {"index": "2", "address": "Bernstein Center for Computational Neuroscience (BCCN), Centre for Integrative Neuroscience (CIN), Institute for Ophthalmic Research, University of T\u00fcbingen, Germany"}], "title": "Linking form to function - Single unit recordings complementing large-scale classification of mouse retinal ganglion cells", "abstract": "In the mammalian retina, the photoreceptor signal is decomposed at the first synapse into multiple parallel channels, providing the foundation of the functional diversity of the retinal ganglion cells (RGCs). They encode different features of the visual world into spike trains and send this information to central targets. Systematic anatomical studies distinguished ~20 different RGC types based on stratification depth and shape of their dendritic arbours (e.g. [1,2]). In a collaboration between the Bethge group and our lab, we are compiling a functional classification of mouse RGC output using population Ca2+ imaging of RGC responses driven by a comprehensive set of visual stimuli (cf. poster by Baden, Berens et al.). Here, our aim is to complement this large-scale imaging approach by providing spiking activity and morphology of individual RGCs from the different clusters. \nWe use cell-attached recordings in whole-mounted mouse retina to monitor RGC spiking activity evoked by a set of stimuli (the same as is used in the aforementioned imaging approach), including frequency/contrast modulated full-field and spatial white noise. Recorded cells are then filled with dye and imaged to acquire their morphology, which is reconstructed offline using Simple Neurite Tracer (www.fiji.sc). In some experiments, the retina is electroporated with Ca2+ indicator [3] to allow targeting RGCs for electrical recordings by their Ca2+ signal. This way, integration of the single-cell data into the large-scale imaging data set can be greatly facilitated. Simultaneous voltage and Ca2+ measurements also allow us to assay how spiking relates to somatic Ca2+ changes in different RGC types. \nIn conclusion, this study, combined with the large-scale classification project, will allow linking functionally defined RGC types to the morphological correlates - adhering the classical credo of retinal research that form follows function.", "acknowledgements": "Centre for Integrative Neuroscience (DFG EXC307), T\u00fcbingen; Bernstein Centre for Computational Neuroscience T\u00fcbingen (BMBF FKZ 01GQ1002); fort\u00fcne program, Medical Faculty of the University T\u00fcbingen.", "id": 131134, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Miroslav Rezac"}, {"epithet": "2", "name": "Tom Baden"}, {"epithet": "2", "name": "Thomas Euler"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Volgyi B, Chheda S, Bloomfield SA (2009). J Comp Neurol 512, 664-687.\n[2] Kong JH, Fish DR, Rockhill RL, Masland RH (2005). J Comp Neurol 489, 293-310.\n[3] Briggman EL, Euler T (2011). J Neurophysiol 105, 2601-2609.\n"}, {"correspondence": ["a-czyz@wp.pl"], "doi": "10.12751/nncn.bc2013.0066", "affiliations": [{"index": "1", "address": "The John Paul Catholic University of Lublin, Poland"}], "title": "Are Event- and Fixation-Related Potentials comparable?", "abstract": "The purpose of the research project is to compare brain responses for \u201cblank stares\u201d effect revealed by two methods: FRP (Fixation-Related Potentials) and ERP (Event-Related Potentials).\nIn ERP method, a cognitive process and the recording of its EEG correlate are synchronized by linking to presented stimulus. Moreover subjects have to keep eyes fixed during experiment. It bears limitation with respect to the ecological validity. The FRP method allows synchronizing cognitive process and the EEG recording by relating a sequence of perceptual events to saccades and visual fixations [1]. The question is to what extend the results obtained by means of those two methods are comparable.\nIn July - August 2013 I am about to conduct experiments by means of ERP and FRP methods. There will be 30 subjects. Half of them will take part in ERP condition and half of them will join FRP condition. In both conditions subjects will perform change detection task related to luminance of the visual stimulus. However, in ERP condition subjects will do flicker task, in which sequential exposure to two scenes, original (100 ms)and modified (100 ms), is separated by blank screen (400 ms) [2]. In FRP condition there will be a combination of flicker task and saccadic task, to test detecting changes after saccadic eye movement. At the beginning of each trial subjects will be asked to focus their gaze on a fixation point. Random exposition time to the fixation point will be designed to prevent subjects from performing anticipatory eye movements. Then another fixation point will appear. In half of the trials the point will appear on the left side and in the other half on the right side of the screen. Subjects will be asked to shift gaze to that point. Exposition time for this stimulus (240 ms) has been defined taking into account research by Montigniani and Chelazzi [3]. After the saccadic eye movements subjects will perform a change detection task.", "acknowledgements": "The study will be carried out in the framework of a research grant from the European Union Program managing by PAIP organization.", "id": 131135, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Agnieszka Fudali-Czy\u017c"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Experimental procedure in FRP condition", "figpath": "066.jpeg", "refs": "[1] Hutzler, F., Broun, M., V\u00f5, M., Engl, V. (2007). Welcome to the real world: Validating fixation - related brain potentials for ecologically valid settings. Brain Research, 1172, 124\u2013129.\n[2] Kimura M., Katayama J., Murohashi H. (2005). Probability - independent and  - dependent ERPs reflecting visual change detection, Psychophysiology, 43, 180\u2013189.\n[3] Montagnini, A., Chelazzi, L. (2005). The urgency to look: Prompt saccades to the benefit of perception. Vision Research, 45, 3391-3401."}, {"correspondence": ["a-czyz@wp.pl"], "doi": "10.12751/nncn.bc2013.0067", "affiliations": [{"index": "1", "address": "The John Paul Catholic University of Lublin, Poland"}], "title": "Insight into the \"blank stares\" effect by FRP method", "abstract": "It has been reported that despite direct fixations, obvious scene changes remain undetected [1]. The new methodology was tested to study hypotheses about correlates of \"blank stares\" effect. The experiment was conducted by means of FRP method (Fixation-Related Potentials), which combines Eye-Tracking and Event-Related Potentials recordings. \nIt was presumed that comparison of fixation-related potentials on the changing locations under conditions where a change was noticed or not will show significant differences in mean amplitude of P100, positive component with latency of about 100 ms from onset of a fixation. The P100, so called lambda response, is the predominant FRP component and is considered to be associated with the level of attention [2]. It was hypothesized also there is negative correlation between the number of \u2018blank stares\u2019 and the working memory capacity. \nThere were 30 subjects (17 female, 13 male, M=21,7 years). Due to problems maintaining a satisfactory calibration results from nine subjects was eliminated. In individual FRP sessions forty pairs of natural scene images were presented in the flicker paradigm. After that subjects have done the working memory capacity task (AOSPAN).\nIf pairs of fixations were within 2 of visual angle of the regions boundary - both before and after introduction of a change - and ended with failure in change detection, they were classified as 'blank stares'.\nA significant smaller P100-like effect was found for 'blank steres' (F(1,19)=5,88, p<0,05) then for fixations ended with change detection. Moreover, repeated ANOVA with Greenhouse-Geisser correction analyses show significant smaller amplitude of negative potential N400 (F(1,19)=7,39, p<0,05) at occipital area for 'blank stares' effect than for fixations successful in change detection. Furthermore, there was significant negative correlation between the number of critical fixations resulted in  change blindness and working memory capacity (r=-0,65, p<0,05). ", "acknowledgements": "The study was carried out in the framework of a research grant from the Ministry of Research and Higher Education, No. N N 106 167 437.", "id": 131136, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Agnieszka Fudali-Czy\u017c"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Grand average fixation-related potentials (FRPs) - P100 and N400 - at sample left and right electrodes: occipital (O1, O2), parietal (P3, P4), temporal (T5, T6), central (C3, C4) and frontal (F3, F4). The FRP is time-locked to critical fixation onset on a changing area of modified image when followed either by a change detection or \"blank stares\" effect", "figpath": "067.jpeg", "refs": "[1] Caplovitz, G. P., Fendrich, R., Hughes, H. C. (2008). Failures to see: Attentive blank stares revealed by change blindness. Consciousness and Cognition, 17, 877-886.doi:10.1016/j.concog.2007.08.006\n[2] Rensink, R. (2002). Change detection. Annual Review of Psychology, 53, 245-277. \n[3] Yagi, A., Takeda, Y., Sugai, M. (2001). Eye fixation related potentials in a proof reading task. International Journal of Psychophysiology, 40, 181-186.\n"}, {"correspondence": ["handa@riken.jp"], "figid": 68, "doi": "10.12751/nncn.bc2013.0068", "affiliations": [{"index": "1", "address": "RIKEN Brain Science Institute, Japan"}, {"index": "2", "address": "Brain Science Institute, Tamagawa University, Japan"}], "title": "Neural ensemble dynamics in rat dorsomedial prefrontal cortex during probabilistic sensory-cued choice", "abstract": "Rodent dorsomedial prefrontal cortex (dmPFC), also called as secondary motor cortex, is one of candidate areas involved in spatial choice according to sensory information [1-2]. However, it remains unclear how single neurons as well as neural ensemble in dmPFC contribute to directing action according to familiar sensory cues as well as novel sensory cues. We recorded ensemble activity from dmPFC of head-restrained rats performing a sensory-cued choice task, in which they were required to lick one of spatially distinct spouts according to familiar and novel sensory cues.\nWe obtained, in total, 283 putative regular spiking (RS) neurons and 41 putative fast spiking interneurons (FS) with our spike-sorting algorithms [3-4], of which 200 neurons (RS 165, FS 35) exhibited event-related increases in firing rate. Single neuronal activity was modulated by cue presentation and/or by response execution. About half of them (RS: 86/165, FS: 21/35) selectively responded to upcoming choice. Neural activity in part of the choice-selective neurons was also differentially modulated by cue tones. Ensemble firing patterns of neural population simultaneously recorded from dmPFC revealed choice selectivity as early as cue tone modulation after cue onset until after choice execution, suggesting concomitant processing spatial choice and sensory information. Under novel cue tone condition, the trajectory of the ensemble firing patterns was choice selective as similarly as that under familiar cue tone condition, but more weakly cue tone modulation unlike that in correct choice under the familiar condition. The trajectories of ensemble activity were diverse depending on the choice behavior of individual animals. These results suggest that dmPFC population neurons process forthcoming choice and the divergent trajectory manners may reflect different tendencies in decision making of individual rats.\n", "acknowledgements": "", "id": 131137, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Takashi Handa"}, {"epithet": "1", "name": "Takashi Takekawa"}, {"epithet": "1", "name": "Rie Harukuni"}, {"epithet": "2", "name": "Yoshikazu Isomura"}, {"epithet": "1", "name": "Tomoki Fukai"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Cowey A, Bozek T (1974) Contralateral \u201cneglect\u201d after unilateral dorsomedial prefrontal lesions in rats. Brain Res 72:53-63.\n[2] Erlich JC, Bialek M, Brody CD (2011) A cortical substrate for memory-guided orienting in the rat. Neuron 72:330-343.\n[3] Takekawa T, Isomura Y, Fukai T (2012) Spike sorting of heterogeneous neuron types by multimodality-weighted PCA and explicit robust variational Bayes. Frontiers in Neuroinformatics 6:1-13.\n[4] http://etos.sourceforge.net/"}, {"correspondence": ["mkb2162@columbia.edu"], "doi": "10.12751/nncn.bc2013.0069", "affiliations": [{"index": "1", "address": "Columbia University, United States"}], "title": "Long-term memory with bounded synaptic weights", "abstract": "Every time we store a new memory we modify a population of synapses, which disrupts previously stored memories. This leads to a tradeoff between memory lifetime and the initial strength of the memory. This rigidity-plasticity dilemma imposes severe limitations on memory performance in the biologically relevant context of online learning with bounded synapses. Previous attempts to overcome these limitations revealed the importance of the complexity of biochemical processes that result in long-term synaptic modifications (Fusi et al. 2005). Models that incorporated cascades of processes operating on multiple timescales could achieve memory lifetimes and initial strengths that scale with the square root of N, where N is the number of synapses.\n    Here we introduce a new class of complex synapses that outperform all previous models, allowing for a memory lifetime that scales almost linearly with N and an initial memory strength that still increases approximately as the square root of N. The complexity of each synapse grows only logarithmically with the memory lifetime. These models have been constructed guided by the idea that memories should fade as gracefully as possible. The best performance is achieved when the memory trace decays slightly faster than the inverse square root of the time since storage. This decay can naturally and parsimoniously be accomplished by intrasynaptic dynamics resembling a diffusion process. It couples variables that represent biochemical processes operating on a wide range of different timescales. \n    While motivated by continuous diffusive systems, these models can be implemented as fully discretized stochastic processes without a significant drop in performance. Our study shows that biological complexity can be harnessed to achieve the optimal scaling of memory strength and lifetime with the number of synapses. We make specific predictions about the bidirectional interactions between biochemical processes involved in memory consolidation.", "acknowledgements": "", "id": 131138, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Marcus Benna"}, {"epithet": "1", "name": "Stefano Fusi"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Doubly logarithmic plot of the signal to noise ratio versus the number of stored memories in a numerical simulation of our fully discretized model (blue) compared to mean field computations for binary synapses with homogeneous (red) and heterogeneous (green) timescales, cascade model of Fusi et al. 2005 (purple) and multistage model of Roxin et al. 2013 (black). N = 2.5 \u00d7 10^6 in all cases. For our model we used 10 internal variables per synapse and similarly the cascade model had 10 metaplasticity states. Note the inverse square root power law decay of the blue SNR curve. The reference times on the upper axis are assuming the arbitrary rate of one new memory every two hours. Inset: Doubly logarithmic plot of the initial signal to noise ratio SNR_0 (red) and memory lifetime t_max at which the SNR crosses the retrieval threshold (assuming one new memory per unit time; blue) versus N, showing approximate power law scaling with exponents close to 1/2 and 1, respectively.", "figpath": "069.jpeg", "refs": "Stefano Fusi, Patrick J. Drew, L.F. Abbott, Cascade Models of Synaptically Stored Memories, Neuron, Volume 45, Issue 4, 17 February 2005, Pages 599-611, ISSN 0896-6273, 10.1016/j.neuron.2005.02.001."}, {"correspondence": ["lsuriya-arunroj@dpz.eu"], "figid": 70, "doi": "10.12751/nncn.bc2013.0070", "affiliations": [{"index": "1", "address": "Sensorimotor Group, German Primate Center, G\u00f6ttingen, Germany"}, {"index": "2", "address": "Bernstein Center for Computational Neuroscience, G\u00f6ttingen, Germany"}], "title": "Interdependence of movement planning and choice behavior for decisions among multiple reach goals in humans", "abstract": "According to an emerging view, the neuronal mechanisms of decision making are tightly entangled with the neural mechanisms of motor planning. Regarding decision making criteria, our choice is influenced not only by costs and benefits associated with different options, but can also be biased by other factors. Here we investigate whether the preliminary movement planning can induce choice biases independent of objective costs or benefits when a preliminary planned movement overlaps with one of the potential action choices.\nSubjects were requested to perform memory-guided reaches on a touch screen. The target location was instructed by two informative cues. A spatial pre-cue, two differently colored triangles pointing to opposite directions, was briefly represented at one of the four cardinal points to guide two possible targets, at 90o clockwise and counterclockwise from the cue. Then appeared a spatially neutral cue, instructing either only one correct target or both (free-choice) would be rewarded. Importantly, the size of each triangle could differ, cueing the probability of each target to be instructed (probabilistic task) or the amount of the reward of each target delivered at the end of the trial (amount task).\nResults showed that subjects responded faster to the target pre-cued to be higher probable or more rewarding. In the probabilistic task, subjects were more likely, and faster, to select the high-probability target in free-choice trials, in spite of no objective advantage from selecting this target. Whereas in the amount task, subjects were slightly biased to select the high-reward target in free-choice trials, and without significant reaction time difference.\nWe conclude that free-choice behavior is particularly biased when pre-cues allow the planning of the motor response. Our results provide behavioral evidence for tight interdependence of decision behavior and motor planning, thereby supporting the idea that the underlying neural mechanisms overlap.", "acknowledgements": "", "id": 131139, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Lalitta Suriya-Arunroj"}, {"epithet": "1,2", "name": "Alexander Gail"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Cisek P, Kalaska JF (2010) Neural mechanisms for interacting with a world full of action choices. Annu Rev Neurosci, 33, 269-98.\nEvans JS (2003) In two minds: Dual process accounts of reasoning. Trends in Cognitive Sciences, 7, 454-459.\nGold JI, Shadlen MN (2007) The neural basis of decision making. Annu Rev Neurosci, 30, 535-74.\nKlaes C, Schneegans S, Sch\u00f6ner G, Gail A (2012) Sensorimotor learning biases choice behavior: a learning neural field model for decision making. PLoS Comput Biol 8(11)."}, {"correspondence": ["btaghizadeh@dpz.eu"], "figid": 71, "doi": "10.12751/nncn.bc2013.0071", "affiliations": [{"index": "1", "address": "German Primate Center, Germany"}], "title": "Object-centered representations in monkey parietal reach region and dorsal premotor cortex", "abstract": "\nDuring visually-guided reach movements, neurons in parietal reach region (PRR) and dorsal pre-motor cortex (PMd) are selective for the spatial location of visual cues and the planed movement. Neurons in these areas have been shown to encode reach targets in egocentric reference frames (eye-centered, hand-centered or an intermediate eye-hand reference frames).  However, egocentric and allocentric spatial information is used for localizing spatial targets (Byrne & Crawford 2010). Human fMRI suggests that posterior parietal and premotor cortex are engaged in selecting goals relative to an object rather than goals directly defined by a visual target (Thaler & Goodale 2011). \nWe asked whether neurons in PRR and PMd used object-centered reference frames when a monkey was required to memorize a peripheral visual cue and to plan a center-out reach relative to other objects.  Each trial started with a brief appearance of a reference array (RA) of five horizontally arranged potential cue positions. After disappearance of the RA the cue was flashed in one of the five positions. After a memory period a decision array (DA), identical to the RA, was presented, but at random positions relative to the RA. While keeping ocular fixation, the monkey had to reach towards the DA position which corresponded to the RA position in which the cue had been shown. We found neurons in both areas that code the position of the visual cue and the movement plan in an object-centered reference frame (relative to the RA and DA, respectively), but also neurons with egocentric or intermediate reference frames. \nOur results show that neurons in PRR and PMd encode visual targets and motor goals partly in an object-based reference frame, at least when the task made it mandatory to subject to use object-relative spatial localizing. \n", "acknowledgements": "", "id": 131140, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Bahareh Taghizadeh"}, {"epithet": "1", "name": "Alexander Gail"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "PA.Byrne, JD. Crawford, J Neurophysiol 103:3054-3069 (2010)\nL. Thaler, MA. Goodale, Front Hum Neurosci 5:92 (2011)\n"}, {"correspondence": ["michael.herrmann@ed.ac.uk"], "figid": 72, "doi": "10.12751/nncn.bc2013.0072", "affiliations": [{"index": "1", "address": "BCCN G\u00f6ttingen, Germany"}, {"index": "2", "address": "Institute for Perception, Action and Behaviour, The University of Edinburgh, Scotland, United Kingdom"}, {"index": "3", "address": "MPI f\u00fcr Dynamik und Selbstorgansation, G\u00f6ttingen, Germany"}], "title": "Memory Capcity of a Critical Neural Network", "abstract": "Critical behaviour in neural networks is characterized by scale-free size distributions of neural avalanches. It can be explained by self-regulatory mechanisms on the synaptic or neural level. Theoretical and experimental evidence indicates that information storage capacity reaches its maximum in the critical regime. It is, nevertheless, not clear whether this optimality of the coding space actually translates into an enhanced capacity of associative memory. If the memory patterns are generated by standard Hebbian learning, their structural bias may compromise the critically of the neural activity dynamics. Using both, Hebbian and regulatory learning, concomitantly, we show that it is possible to store and to retrieve memorised information in a network that remains critical in the absence of patterned input. In other words, the network exhibits a critical dynamics for uncorrelated random input after learning, and follows an attractor dynamics towards the stored patterns if the input has correlations similar one of the patterns it was previously exposed to. We show that the two regimes are robust and do not depend on precise parameter values if the neural firing threshold is properly adjusted. We consider also other connectivities which are characterised e.g. by a small-world property which allow us to demonstrate a cooperative effect of the regulatory criticalisation and the long-term learning dynamics in the network.", "acknowledgements": "The authors are grateful to Hecke Schrobsdorff, Matthias Mittner, Sakyasingha Dasgupta, Andreas Iacovou, Dmitri Bibitchkov and Misha Tsodyks for useful discussions. This work is supported by the Federal Ministry of Education and Research (BMBF) Germany under grant number 01GQ1005B. ", "id": 131141, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Maximilian Uhlig"}, {"epithet": "1", "name": "Anna Levina"}, {"epithet": "2", "name": "J. Michael Herrmann"}, {"epithet": "3", "name": "Theo Geisel"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["alexander.gepperth@ensta.fr"], "doi": "10.12751/nncn.bc2013.0073", "affiliations": [{"index": "1", "address": "ENSTA ParisTech, France"}], "title": "Processing and transmission of confidence in recurrent neural hierarchies", "abstract": "This work addresses the construction of hierarchies from dynamic attractor networks.\nWe claim that such networks, e.g., dynamic neural fields (DNFs), contain a data model which is encoded in their lateral connections, and which describes typical properties of afferent inputs. This allows to infer the most likely interpretation of inputs, robustly expressed through the position of the attractor state.\n\nThe principal problem resides in the fact that positions of attractor states alone do not reflect the quality of match between input and data model, termed decision confidence. In hierarchies, this inevitably leads to final decisions which are not Bayes-optimal when inputs exhibit different degrees of ambiguity or conflict, since the resulting differences in confidence will be ignored by downstream layers.\n\nWe demonstrate a solution to this problem by showing that a correctly parametrized DNF layer can encode decision confidence into the latency of the attractor state in a well-defined way. Conversely, we show that input stimuli gain competitive advantages w.r.t. each other as a function of their relative latency, thus allowing downstream layers to decode attractor latency in an equally well-defined way. Putting these encoding and decoding mechanisms together, we construct a 3-stage hierarchy of DNF layers and show that the top-level layer can take Bayes-optimal decisions when the decisions in the lowest hierarchy levels have variable degrees of confidence.\n\nAs a last step, we attempt to generalize these findings,\nsuggesting a novel possibility to represent and manipulate probabilistic information in recurrent networks without any need for\nlog-encoding, just using the biologically well-founded effect of response latency as an additional coding dimension.", "acknowledgements": "", "id": 131142, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Alexander Gepperth"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Motivation and basic setting for the presented work.  Left: Perceptual decision hierarchy making use of response latency for optimal decision making. We imagine a hierarchical cortical network analyzing a small image patch (red rectangle) and analyzing it along two (or several) visual modalities as it has been demonstrated in lower visual areas of mammals. The (fixed) feed-forward connections between layers A,B cause feature selectivity in layer 1/2 neurons (indicated by small symbols for some neurons) whereas the (fixed) lateral connections (C) contain the data model for inputs to layers 1/2. Violations of this data model, e.g., by strong co-activation of unimodal layer 1 neurons, will amplify unimodal response latency, thus reducing influence on the multimodal integration layer 2. \n Right: actual neural hierarchy considered in this article. Layers (implemented by dynamic neural fields) and visual modalities correspond to the left diagram but stimulus structure has been simplified to admit only two possible stimulus types in each modality. For simplicity, these will often be termed the \"left\" and \"right\" stimulus. During experiments, one modality will always receive the same layer 0 inputs, whereas the other modality will receive inputs leading to variable decision confidence, and the resulting decisions in layers 1 and 2 will be observed.", "figpath": "073.png", "refs": "R.Kiani H.Esteky and K.Tanaka. Differences in onset latency of macaque inferotemporal neural reponses to primate and non-primate faces. J.Neurophysiol92(2), 2055.\n\nM.W. Oram, D.Xiao, B.Dritschel and K.R. Payne. The temporal resolution of neural codes: does response latency have a unique role? Philo Trans R Soc London Bio Sci 357(1424), 2002.\n\n"}, {"correspondence": ["friedemann.zenke@epfl.ch"], "figid": 75, "doi": "10.12751/nncn.bc2013.0075", "affiliations": [{"index": "1", "address": "EPFL, Switzerland"}, {"index": "2", "address": "University of Cambridge, United Kingdom"}], "title": "Synaptic plasticity in neural networks needs a fast control mechanism", "abstract": "Hebbian changes of excitatory synapses are caused by as well as enhance correlations between pre- and postsynaptic activities. The emerging positive feed-back loop can lead to instability in models of neural networks. To maintain stable activity levels, plasticity has to be matched by homeostasis or other compensatory control mechanisms. However, it is not clear on which timescale such mechanisms have to act to assure stability. We show in numerical simulations of recurrent networks with a physiological triplet-based spike-timing-dependent plasticity rule (triplet STDP) that the stabilizing mechanism has to act on a timescale of seconds to minutes. We confirm this result in a generic mean-field formulation of network activity and homeostatic plasticity. Our results suggest that there exists an unknown fast regulatory mechanism which is significantly faster than known forms of homeostasis.", "acknowledgements": "F. Z. was supported by the European Community\u2019s Seventh Framework Program under grant agreement no. 237955 (FACETS-ITN) and 269921 (BrainScales). G. H. was supported by the Swiss National Science Foundation. W. G. acknowledges funding from the European Research Council (no. 268689).", "id": 131144, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Friedemann Zenke"}, {"epithet": "2", "name": "Guillaume Hennequin"}, {"epithet": "1", "name": "Wulfram Gerstner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["r.memmesheimer@science.ru.nl"], "figid": 76, "doi": "10.12751/nncn.bc2013.0076", "affiliations": [{"index": "1", "address": "Department of Neuroinformatics, Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, Netherlands"}, {"index": "2", "address": "Department of Biophysics, Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, Netherlands"}], "title": "Cooperation and competition of gamma oscillation mechanisms", "abstract": "Oscillations in different frequency ranges and with different underlying mechanisms are a hallmark of cortical network dynamics. Here we investigate how different candidate mechanisms interact to give rise to a network oscillation. To be specific, we consider gamma oscillations generated by electrical synapses, ING (InterNeuronal Gamma), and PING (Pyramidal-InterNeuron Gamma) mechanisms in the hippocampus by means of a biologically plausible network model. We find that in this network electrical synapses generate weakly synchronous oscillations and support ING rhythms. In contrast, the highly synchronous ING and PING rhythms compete: The mechanism which yields the higher oscillation frequency determines the network dynamics and suppresses the other mechanism. The results are of particular importance as oscillations due to different mechanisms have been linked to different cognitive functions. Our results might suggest that frequency changes allow to switch between them. Further our work suggests methods to distinguish between ING and PING. Our predictions are experimentally testable with recently developed optogenetic techniques.", "acknowledgements": "", "id": 131145, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Atthaphon Viriyopase"}, {"epithet": "1", "name": "Raoul-Martin Memmesheimer"}, {"epithet": "2", "name": "Stan Gielen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["enrico.chiovetto@klinikum.uni-tuebingen.de"], "figid": 77, "doi": "10.12751/nncn.bc2013.0077", "affiliations": [{"index": "1", "address": "Section for Computational Sensomotorics, Department of Cognitive Neurology, Hertie Institute for Clinical Brain Research, Centre for Integrative Neuroscience, University Clinic T\u00fcbingen, T\u00fcbingen, Germany"}, {"index": "2", "address": "Department of Neuromotor Physiology, Santa Lucia Foundation, Rome, Italy"}], "title": "A unifying algorithm for the identification of kinematic and electromyographic motor primitives", "abstract": "It has been shown in the last years that the kinematic and electromyographic patterns underlying complex movements can be approximated by the combinations of a small number of temporal basis components, also referred to as motor synergies or motor primitives. Typically the identification of such components has been carried out by applying of a large set of different unsupervised learning algorithms, such as principal or independent component analysis (usually known respectively as PCA and ICA) and non-negative matrix factorization (NMF). While classical ICA, PCA and NMF are based on instantaneous mixture models [1], that superposition a set of basis functions linearly, more advanced techniques have also been proposed that include the estimation of temporal delays of the relevant mixture components [2,3]. The use of such a multitude of different algorithms may however complicate, for multiple reasons, the comparison and interpretation of the results obtained across studies. We propose a unifying framework for the description of motor synergies, starting from which a new algorithm for the identification of temporal motor primitives was developed. We show how all the different definitions of temporal synergies given in the literature can be derived from one single generative model which relies on the linear combination of synergies that can however be shifted in time. We demonstrate how, by embedding of smoothness prior in the underlying generative model, the algorithm can identify, from a given data set, mostly any kind of motor primitives with approximately no decrease of identification accuracy with respect to other standard techniques commonly used.  With this algorithm, which is going to be distributed online as a freeware toolbox, we aim to provide a large research community in the field of motor control with an easy tool for the identification of motor primitives that avoid the confusion and inhomogeneity that the use of too many different techniques may imply.", "acknowledgements": "EC, 7th Framework Programme: EC FP7-ICT-249858 TANGO, EC FP7-ICT-248311 AMARSi, DFG: DFG GI 305/4-1, DFG GZ: KA 1258/15-1, German Federal Ministry of Education and Research: BMBF, FKZ: 01GQ1002A, EU Commission, Fp 7-PEOPLE-2011-ITN (Marie Curie): ABC PITN-GA-011-290011, The Human Brain Project.", "id": 131146, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Enrico Chiovetto"}, {"epithet": "2", "name": "Andrea d'Avella"}, {"epithet": "1", "name": "Martin Giese"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Chiovetto, E., Berret, B., and Pozzo, T.(2010).Tri-dimensional and triphasic muscle organization of whole-body pointing movements. Neuroscience 170, 1223\u20131238. \n\n[2] d\u2019Avella, A., Portone, A., Fernandez, L., and Lacquaniti, F. (2006) Control of fast reaching movements by muscle synergy combinations. J Neurosci 26:7791\u20137810.\n\n[3] Omlor, L., and Giese, M.A. (2011) Anechoic blind source separation using Wigner marginals. Journal of Machine Learning Research 12: 1111-1148.\n"}, {"correspondence": ["tobias.beck@uni-tuebingen.de"], "figid": 78, "doi": "10.12751/nncn.bc2013.0078", "affiliations": [{"index": "1", "address": "Computational Sensomotorics, HIH, CIN, BCCN, Cognitive Neurology, University Clinic Tuebingen, Germany"}, {"index": "2", "address": "Cognitive Neurology, University Clinic Tuebingen, Germany"}, {"index": "3", "address": "BCCN, Cognitive Neurology, University Clinic Tuebingen, Germany"}, {"index": "4", "address": "CIN, BCCN, Cognitive Neurology, University Clinic Tuebingen, Germany"}], "title": "Me \u2013 Not Me \u2013 Or In Between?  Comparison of Causal Inference Models for Agency attribution in goal-directed actions", "abstract": "Perception of own actions is influenced by visual information and predictions from internal forward models [1]. Integrating these information sources depends critically on whether visual consequences are associated with one's own action (sense of agency) or with changes in the external world unrelated to the action [2,3] and the accuracy of integrated signals [4,5]. Attribution of percepts to consequences of own actions should thus depend on the consistency between internally predicted and actual visual signals, but what does the data support: binary (me vs not me)[6] or continuous (partially me) attribution? \n\nMETHODS. To examine this question, we used a virtual-reality setup to manipulate the consistency between pointing movements and their visual consequences and investigated the influence of this manipulation on self-action perception with visual stimuli of varying precision. In previous work we showed that a Bayesian causal inference model, assuming a binary latent agency variable controlling the attributed influence of the self-action on perceptual consequences [2,3], accounted for the empirical data [6]. Here, new models assuming a continuous variable for attribution of the visual feedback to own action are presented and their performance predicting the empirical data evaluated and compared to the binary model [2,3]. The models assume both visual feedback and internal estimate are directly caused by the (unobserved) real motor state.\n\nRESULTS AND CONCLUSION. The models correctly predict empirical agency ratings, showing attribution of visual signals to self-action for small, and stronger reliance on internal information for large deviations. We discuss the performance of these causal inference models, applying methods for model comparison.\n", "acknowledgements": "This work was supported by: BMBF FKZ: 01GQ1002, EC grants FP7-ICT-249858 TANGO, FP7-ICT-248311 AMARSi, FP7-PEOPLE-2011-ITN(Marie Curie), FP7 ABC (PITN-GA-2008-290011) and DFG GI 305/4-1, DFG GZ: KA 1258/15-1.", "id": 131147, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Tobias F Beck"}, {"epithet": "2", "name": "Carlo Wilke"}, {"epithet": "3", "name": "Barbara Wirxel"}, {"epithet": "1,*", "name": "Dominik Endres"}, {"epithet": "4", "name": "Axel Lindner"}, {"epithet": "1,*", "name": "Martin A Giese"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Wolpert et al.,Science,269,1995.\n[2] K\u00f6rding et al.,PLoS ONE,2(9),2007.\n[3] Shams & Beierholm, TiCS,14, 2010.\n[4] Alais & Burr,CurBio,14,2004.\n[5] Burge et al.,JVis,8(4),2008.\n[6] Beck et al.,JVis,11(11):955, 2011."}, {"correspondence": ["dominik.endres@klinikum.uni-tuebingen.de"], "figid": 79, "doi": "10.12751/nncn.bc2013.0079", "affiliations": [{"index": "1", "address": "HIH, CIN, BCCN, Univ. Clinic, Germany"}, {"index": "2", "address": "University of Leuven, Belgium & The Netherlands Institute for Neuroscience, Amsterdam, Belgium"}], "title": "Neurodynamical model for the multi-stable perception of biological motion", "abstract": "Standard point-light biological motion stimuli do not specify disparity information, inducing depth-ambiguities for specific views of the walker (Vanrie, Dekeyser, Verfaillie, 2004). In these cases perception becomes multi-stable, and the same stimulus can be perceived as a walker heading in two alternative directions (Vangeneugden et al. 2011). Existing neural and computational theories for biological motion perception are either based on learned 2D templates (e.g. Giese & Poggio, 2003; Lange & Lappe, 2006; Serre & Poggio, 2007) or the online fitting of 3D body models to image features (e.g. Marr & Vaina, 1982). The question arises whether such models can account for such multi-stable perception of the three-dimensional body structure from motion, and which predictions at the level of single cell and population activity follow from these models.  We present an extension of a physiologically-inspired dynamical neural model for the processing of body motion (Giese & Poggio, 2003), which accounts for such multi-stable perception by dynamically competing view-specific neural representations. The model reproduces qualitatively several key aspects from psychophysical experiments investigating such perceptual multi-stabilities in biological motion perception.\n\n", "acknowledgements": "German Federal Ministry of Education and Research: BMBF, FKZ: 01GQ1002A; DFG GI 305/4-1, DFG GZ: KA 1258/15-1, EU Commission, 7th Framework Programme: EC FP7-ICT-249858 TANGO, EC FP7-ICT-248311 AMARSi, FP7-PEOPLE-2011-ITN(Marie Curie): ABC PITN-GA-011-290011, Human Brain Project (FP7 Flagship)", "id": 131148, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Leonid Fedorov"}, {"epithet": "1", "name": "Dominik Endres"}, {"epithet": "2", "name": "Joris Vangeneuden"}, {"epithet": "1", "name": "Martin A Giese"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Giese, MA, & Poggio, T  (2003). Nat Rev Neurosci , 4, 179\u2013192.\nJhuang, H, Serre, T, Wolf, L, & Poggio, T (2007).Proc. IEEE ICCV, DOI 10.1109/ICCV.2007.4408988.\nLange, J. & Lappe, M. (2006). J Neurosci. 26(11):2894-2906.\nMarr, D, & Vaina, L (1982). Proc R Soc Lond B Biol Sci. 214(1197), 501-524.\nVangeneugden, J, De Mazi\u00e8re, P, Van Hulle, M, Jaeggli, T, Van Gool, & Vogels, R (2011). J Neurosci, 31: 385-401.\nVanrie, J., Dekeyser, M & Verfaillie K. (2004). Perception, 33(5):547-560"}, {"correspondence": ["merrittcody@gmail.com"], "figid": 80, "doi": "10.12751/nncn.bc2013.0080", "affiliations": [{"index": "1", "address": "Section for Computational Sensomotorics, Dept Cognitive Neurology, Centre for Integrative Neuroscience, Hertie Institute HIH, University Clinic Tuebingen, Germany"}, {"index": "2", "address": "Division of Neuropsychology, Dept Cognitive Neurology, Centre for Integrative Neuroscience, Hertie Institute HIH, University Clinic Tuebingen, Germany"}], "title": "Detecting errors of human action semantics using Markov logic networks as tool to quantify behavioral deficits in apraxia", "abstract": "Human action planning and understanding likely is tightly related to the neural encoding of semantic structures. In ideational apraxia, the encoding of these structures is likely impaired, resulting in a range of semantic errors in action execution [1]. Quantitative assessment of such errors is a methodological challenge due to the large variability of human action plans. Markov logic networks (MLN) [2] offer a flexible mathematical tool for analyzing semantic relationships within a probabilistic framework. As a first step towards a mathematical tool for objective measurement of apraxic errors, we applied MLNs to model the semantic structure of human cooking activities.\n\nWe recorded movements from normal unimpaired participants as they prepared and drank a cup of coffee with milk and sugar, and cleaned up. Involving multiple action sequences and objects, the task provided a rich set of semantically relevant relationships. In part of the trials actions were mimed in the absence of objects. Varying the difficulty of a secondary (cognitive) task concurrent to the motor activity resulted in a significant amount of action errors, similar to apraxic patients.\n\nMLN models were implemented exploiting the Alchemy inference engine. Through video and motion capture, trials were hand-labeled, describing at each time-point the participants' actions and the states of the objects. Labels were translated into a database of first-order logic (FOL) predicate groundings and FOL formulas were designed to express semantic and physical constraints. Together, they represent actions, object states, and apraxic errors. We successfully developed an MLN to model semantic relationships in 3 test data sets derived from a subset of the cooking activities. For this data the MLN perfectly identified the attainment of goal-states and the presence of apraxic errors. Currently, the MLN is being extended and scaled-up to address the complexity of the full data set using weight learning.", "acknowledgements": "Supported by DFG GZ: KA 1258/15-1, BMBF, FKZ: 01GQ1002A , EC FP7-ICT-249858 TANGO, EC FP7-ICT-248311 AMARSi, EC FP7-PEOPLE-2011-ITN (Marie Curie) ABC PITN-GA-011-290011, and The Human Brain Flagship Project.", "id": 131149, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Cody A. Merritt"}, {"epithet": "1", "name": "Dominik Endres"}, {"epithet": "2", "name": "Ann-Kristin Weiser"}, {"epithet": "2", "name": "Hans-Otto Karnath"}, {"epithet": "1", "name": "Martin A. Giese"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] B. Petreska, M. Adriani, O. Blanke, A. G. Billard. Apraxia: a review. Prog Brain Res. 164:61-83. 2007.\nDOI:10.1016/S0079-6123(07)64004-7\n\n[2] P. Domingos and D. Lowd. Markov Logic: An Interface Layer for Artificial Intelligence. Synthesis Lectures on Artificial Intelligence and Machine Learning. 3:1, 1-155. Morgan and Claypool Publishers. 2009. \nDOI:10.2200/S00206ED1V01Y200907AIM007"}, {"correspondence": ["sumitppai@gmail.com"], "figid": 81, "doi": "10.12751/nncn.bc2013.0081", "affiliations": [{"index": "1", "address": "Department of Cognitive Neurology, Section Computational Sensomotorics, BCCN, CIN, HIH and University Clinic T\u00fcbingen, Otfried-M\u00fcller-Str. 25, 72076 T\u00fcbingen, Germany"}], "title": "Modeling coarticulation in human motion with hierarchical probabilistic models", "abstract": "Coarticulation has been widely studied in human speech production and it has found applications in speech recognition, facial animation, etc [1]. Originally, coarticulation refers to the influence which a speech sound exerts on a preceding (anticipatory coarticulation) or following (carryover coarticulation) speech sound.\n\nA similar influence can also be observed in movements while performing goal directed actions. We are modeling these coarticulations between human movements with dynamical probabilistic models for the purposes of human movement analysis and on-line generation of dynamical stimuli for psychophysical experiments in motion perception. Such a model will e.g. enable us to study the effects of systematic coarticulatory changes on the perceived realism of the movement, and perceptual differences between healthy subjects and specific patient groups[2]. \n\nOur model is comprised of a hierarchical combination of Gaussian Process Dynamical Models (GPDM) with hidden Markov models (HMM). GPDMs have been successfully used to capture the dynamics of human  movement[3]. GPDMs are non-parametric models that capture smooth trajectories in latent dynamics space of a high dimensional dynamical system. However, when multiple types of movements are involved in an action, using a single GPDM to learn the latent trajectories typically leads to \u201ccross-talk\u201d between different movement models, resulting in unrealistic movements. Hence, we switch between GPDMs with a HMM, whose transition probabilities also represent co-articulatory dependence between movements. We train this model on motion capture data recorded from human actors performing a task which required coordination between upper and lower limbs, which evoked co-articulatory dependences between movement segments.", "acknowledgements": "EU Commission, 7th Framework Programme: EC FP7-ICT-249858 TANGO, EC FP7-ICT-248311 AMARSi, FP7-PEOPLE-2011-ITN (Marie Curie): ABC PITN-GA-011-290011, The Human Brain Project; DFG GI 305/4-1, DFG GZ: KA 1258/15-1, German Federal Ministry of Education and Research: BMBF, FKZ: 01GQ1002A\n", "id": 131150, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Sumit P. Pai"}, {"epithet": "1", "name": "Dmytro Velychko"}, {"epithet": "1", "name": "Dominik Endres"}, {"epithet": "1", "name": "Martin A. Giese"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1.Cohen M.M. and Massaro D.W. \"Modeling coarticulation in synthetic visual speech.\" Models & techniques in computer animation 92(1993).\n2.Kandil F.I., Pedersen A., Wehnes J.,and Ohrmann P. \u201cHigh-level,but not low-level,motion perception is impaired in patients with schizophrenia.\u201d Neuropsychology, 27(1):60-68 (2013).\n3.Wang J.M., Fleet D.J., and Hertzman \"Gaussian process dynamical models for human motion.\" Pattern Analysis and Machine Intelligence, IEEE Transactions on 30.2 (2008): 283-298."}, {"correspondence": ["ibiro@tnb.ua.ac.be"], "figid": 666, "doi": "10.12751/nncn.bc2013.0253", "affiliations": [{"index": "1", "address": "Biomed. Sci., Univ. of Antwerp, Wilrijk, Belgium"}, {"index": "2", "address": "Brain Mind Inst., Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne, Lausanne, Switzerland"}, {"index": "3", "address": "Dept. of Computer Sci., Univ. of Sheffield, Sheffield, United Kingdom"}], "title": "Response modulation in neurons with realistic background", "abstract": "Populations of neurons can track fast changing signals up to around 200 Hz, far beyond the cutoff frequency imposed by their membrane properties, as shown experimentally by (Kondgen et al., 2008), who injected sinusoidally modulated current signals at various frequencies, superimposed on a noisy current mimicking background synaptic activity. However, physiological inputs to a neuron are mediated by ionotropic synaptic receptors, resulting not only in excitatory and inhibitory net currents, but also in a stimulus-dependent change of membrane conductance. Thus, we asked whether neurons are able to track current- or conductance-based signals on a noisy conductance background. Employing the dynamic-clamp method, we studied input-output response properties of rat somatosensory cortical (L5) neurons in vitro, in a wide range of conditions and input frequencies, varying synaptic background intensity, postsynaptic firing rate, and signal modulation type (current or a conductance component). Our results indicate that neurons receiving synaptic inputs, closely resembling the in vivo high-conductance state, have ultra-fast reaction times and track fast changing inputs. The input-output transfer bandwidth shows a similar cutoff frequency in both cases of current- and conductance-based signals, with similar response phase-shift. The effect of input modulation type becomes prominent in signal gain, favoring encoding by only one conductance component -excitation or inhibition-, when output spike trains are highly irregular. Simultaneous modulation of both components results in similar behavior as for current inputs. Further, high levels of background activity only increase gain if a single conductance component carries the signal, otherwise throughput is decreased. Increased output firing rate results in a band-pass, rather than low-pass filter behavior. In conclusion, we confirmed the validity of previous studies and extend them to more realistic physiological conditions.", "acknowledgements": "", "id": 131151, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1*", "name": "Istvan Biro"}, {"epithet": "1", "name": "Daniele Linaro"}, {"epithet": "1,2,3", "name": "Michele Giuliano"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Kondgen H, Geisler C, Fusi S, Wang XJ, Luscher HR, Giugliano M (2008) The dynamical response properties of neocortical neurons to temporally modulated noisy inputs in vitro. Cereb Cortex (United States) 18:2086-2097."}, {"correspondence": ["p.macneilage@gmail.com"], "figid": 82, "doi": "10.12751/nncn.bc2013.0082", "affiliations": [{"index": "1", "address": "German Center for Vertigo, Univ. Hosp. of Munich, Bernstein Center for Computational Neuroscience, Munich, Germany"}], "title": "Statistics of natural vestibular stimulation and head orientation during human locomotion", "abstract": "Here we characterize naturalistic vestibular stimulation and relate these measurements to known properties of the vestibular system. Measurements were performed using a miniature integrated inertial measurement unit strapped to the head \u2013 MTx from XSENS. The unit itself consists of a 3D accelerometer, rate gyro, and magnetometer with an integrated embedded processor that uses an extended Kalman filter algorithm to calculate orientation in real time. All data is transformed from sensor coordinates into head coordinates using Reid\u2019s plane as a reference. In 10 subjects (5M, 5F) we recorded 6 minutes of running, walking, biking, soccer, and climbing stairs. Accelerometer and rate sensor data capture natural stimulation of the otoliths and semicircular canals respectively. Histograms characterize variation in stimulus magnitude and direction. Typically, head linear acceleration was modulated most along the head-vertical axis and head rotation was most often around the pitch axis, but with considerable variation across activities and individuals. Orientation data characterizes head stabilization performance, and allows decomposition of accelerometer data into gravitational and inertial components, which have most power at low and high frequencies, respectively. Dominant stimulus frequencies reflect typical stepping frequencies. For the most periodic activities (i.e. walking and running) we characterize the mean (+/-SD) stride cycle (two steps) by identifying heel strikes in the accelerometer data and averaging the individual strides across the 6 minute recording period. Stride traces are highly predictable with the stride cycle attractor accounting for up to 90% of variance (R2 statistic) of some stimulus components. This finding suggests predictive mechanisms alone (rather than actual vestibular sensation) could allow very good compensation for perturbations induced by head motion during locomotion, which can help explain compensation in vestibular-loss patients.", "acknowledgements": "The work was supported by a grant from the German Federal Ministry of Education and Research under the Grant code 01 EO 0901.", "id": 131152, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Paul MacNeilage"}, {"epithet": "1", "name": "Stefan Glasauer"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["paul.maier@lrz.uni-muenchen.de"], "figid": 83, "doi": "10.12751/nncn.bc2013.0083", "affiliations": [{"index": "1", "address": "Institute for Clinical Neurosciences, Germany"}, {"index": "2", "address": "BCCN Munich, Ludwig-Maximilians-Universita\u0308t, Munich, Germany"}, {"index": "3", "address": "Translational Neuromodeling Unit (TNU) of ETH Z\u00fcrich & University of Z\u00fcrich, Switzerland"}, {"index": "4", "address": "Integrated Center for Research and Treatment of Vertigo IFB LMU, Ludwig-Maximilians-Universita\u0308t, Munich, Germany"}], "title": "The effect of temporal stimulus correlation on distance estimation by path integration", "abstract": "When navigating, humans rely on continuous fusion of sensory inputs to estimate their own position and pose. For distance estimation this fusion is currently best explained by statistically near optimal integration of sensed information and prior stimulus statistics [1].\n\nIterative probabilistic models are used to explain how humans might learn these statistics through estimates that utilize statistical information about previous stimuli [2,3]. In particular, state estimation models assuming that stimuli are correlated over time are well suited to explain fast adaptive learning. However, experimenters often randomize stimuli to prevent adaptation. Here we ask whether this randomization might be the key driver for typical systematic errors observed, e.g., in distance estimation [2]. Simulations with our adaptive model predicted that the systematic error known as regression effect should virtually disappear when stimuli are strongly correlated over time.\n\nWe tested this prediction in a unimodal distance matching paradigm. In each trial, participants first moved in a virtual environment until they were stopped. Then they reproduced the experienced distance by moving again in the same direction. No feedback was given. Each new distance differed from the previous by a random but small amount, resulting in temporally correlated and hence more predictable stimuli. As control condition the same distances were presented in random order.\n\nThe results lend qualitative, but not quantitative support to the prediction. The regression effect was significantly diminished, but not as much as predicted by the model. Also, estimation accuracy (measured as R2) did not improve significantly. Thus, while range and regression effects with randomized stimuli are well explained by rapidly adapting Bayesian models, our results suggest that humans retain more information about the whole stimulus distribution than just the short-term estimate assumed by previous models [2,3].", "acknowledgements": "This research was supported by the BMBF (grants IFB 01EO0901 and BCCN 01GQ0440). We thank Paul MacNeilage for valuable comments.", "id": 131153, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Paul Maier"}, {"epithet": "3", "name": "Frederike Hermi Petzschner"}, {"epithet": "1", "name": "Mar\u00eda F. Guti\u00e9rrez Herrera"}, {"epithet": "1,2,4", "name": "Stefan Glasauer"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. K\u00f6rding KP, Wolpert DM (2006) Bayesian decision theory in sensorimotor control. Trends Cogn Sci 10:319-26.\n\n2. Petzschner FH, Glasauer, S (2011) Iterative Bayesian Estimation as an Explanation for Range and Regression Effects: A Study on Human Path Integration. J Neurosci 31:17220\u20139. \n\n3. Verstynen T, Sabes PN (2011) How each movement changes the next: An experimental and theoretical study of fast adaptive priors in reaching. J Neurosci 31:10050-9."}, {"correspondence": ["daisuke.takeshita@med.uni-goettingen.de"], "figid": 85, "doi": "10.12751/nncn.bc2013.0085", "affiliations": [{"index": "1", "address": "BCCN G\u00f6ttingen, University Medical Center G\u00f6ttingen, Department of Ophthalmology, Germany"}], "title": "Spatial integration in the receptive field surround of retinal ganglion cells", "abstract": "How a sensory neuron spatially integrates signals over its receptive field is one of the determinants of the neuron\u2019s function. In retinal ganglion cells, for example, it has long been known that signals are linearly integrated in some cells, whereas nonlinear integration occurs in others [1]. However, most of the previous studies have focused on the receptive center and very little has been known about spatial integration in the receptive field surround.\nHere we aim at quantifying how signals are spatially integrated in the receptive field surround in the salamander retina. We use multi-electrode arrays to record spiking activity from retinal ganglion cells and use closed-loop experiments to perform iso-response measurements, which enable one to study spatial integration. For iso-resopnse measurements, two distinct surround regions are stimulated with combinations of different contrast values while the receptive field center is stimulated with a fixed contrast. Iso-response curves are determined as a set of two surround contrasts that lead to the same pre-specified spike count. The shapes of these curves reveal the signal integration characteristics in the receptive field surround.\nThe iso-rate curve revealed two classes of ganglion cells with respect to the surround integration. One class showed a dependence of the nonlinearity on the contrast. For low contrast, the integration was threshold quadratic, while the integration tended to be linear for higher contrast. This cell class showed a threshold-quadratic nonlinearity in the receptive field center. The other cell class showed a threshold-quadratic nonlinearity in the surround, mostly independent of contrast. For these cells, the integration in the center was such a way that the cell was particularly sensitive to spatially homogeneous stimuli [2]. Therefore, it is suggested that retinal ganglion cells have distinct spatial integration properties in both the receptive field center and its surround.\n", "acknowledgements": "This work was supported by the German Initiative of Excellence, the International Human Frontier Science Program Organization, and the Deutsche Forschungsgemeinschaft (DFG-SFB 889).", "id": 131155, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Daisuke Takeshita"}, {"epithet": "1", "name": "Tim Gollisch"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Enroth-Cugell C and Robson JG (1966) Journal of Physiology 187:517\u2013552.\n[2] B\u00f6linger D and Gollisch T (2012) Neuron doi:10.1016/j.neuron.2011.10.039"}, {"correspondence": ["jbraun@physik3.gwdg.de"], "figid": 86, "doi": "10.12751/nncn.bc2013.0086", "affiliations": [{"index": "1", "address": "Georg-August University G\u00f6ttingen, Bernstein Focus Neurotechnology G\u00f6ttingen, Germany"}, {"index": "2", "address": "Georg-August University G\u00f6ttingen, Bernstein Center for Computational Neuroscience G\u00f6ttingen, Bernstein Focus Neurotechnology G\u00f6ttingen, Germany"}, {"index": "3", "address": "Otto Bock HealthCare GmbH Duderstadt, Germany"}, {"index": "4", "address": "Otto Bock HealthCare GmbH Duderstadt, Bernstein Center for Computational Neuroscience G\u00f6ttingen, Germany"}], "title": "Implementing a Gait-Aware Knee-Ankle-Foot-Orthosis using Neuro-Control and Internal Models", "abstract": "Knee-Ankle-Foot-Orthoses (KAFOs) are modular lower-extremity orthoses prescribed to people with gait disability. KAFOs should support, correct and assist the movement of the corresponding affected joints. Traditional KAFOs are controlled by non-adaptive thresholds; therefore, they can not adjust to common disturbances (floor unevenness, obstacles, ramps) in a satisfactory way [1]. Novel approaches include active elements, which do not directly act on the movement. Instead they allow continuous adjustment of parameters like the affected joint's damping, leading to new challenges for the controller of such actuators.\nTo take advantage of the fine grained control the active element offers and to overcome shortcomings of traditional control approaches, adaptive methods like artificial neural networks (ANN) are applied. These methods can manage the active element's flexibility and the high neuromuscular variability within specific patient groups, allowing individual support of a wider range of patients. Therefore, the development of advanced devices is imposing the need for individual (online) adaptation of gait parameters to adjust to (1) changing environments, like slopes & stairs, gait parameters, e.g. stride length/frequency, and (2) individual patients with respect to physiological conditions. \nThis study evaluates internal motion models based on ANNs to distinguish gaits. The controller operates a KAFO based on a controllable hydraulic damper, derived from OttoBock's C-Leg\u00a9. Investigated is the the controller's ability to detect the current gait, focussing on the ability to allow several fast changes inside one step, while the rate of misclassification should diminish. So that the patient may react to changes in the environment or perturbations.\nOur preliminary results indicate, that the motion models are an accurate and fast adaptive method for this purpose. It fits well into and extends the used paradigm of adaptive modular neuro-control [2].", "acknowledgements": "This research was supported by the BMBF-funded BFNT G\u00f6ttingen with grant number 01GQ0810 (project 3A) and BCCN G\u00f6ttingen with grant number 01GQ1005A (project D1) and the Emmy Noether Program (DFG, MA4464/3-1).", "id": 131156, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Jan-Matthias Braun"}, {"epithet": "2", "name": "Poramate Manoonpong"}, {"epithet": "3", "name": "Timo von Marcard"}, {"epithet": "3", "name": "Markus T\u00fcttemann"}, {"epithet": "2", "name": "Florentin W\u00f6rg\u00f6tter"}, {"epithet": "4", "name": "Bernhard Graimann"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Yakimovich T, Lemaire ED, Kofman J. (2009) Engineering design review of stance-control knee-ankle-foot orthoses. J Rehabil Res Dev. 46(2):257-67. DOI:10.1682/JRRD.2008.02.0024\n[2] Manoonpong P., Geng T., Kulvicius T., Porr B., W\u00f6rg\u00f6tter F. (2007) Adaptive, Fast Walking in a Biped Robot under Neuronal Control and Learning. PLoS Comput Biol 3(7): e134. doi:10.1371/journal.pcbi.0030134"}, {"correspondence": ["echeveste@itp.uni-frankfurt.de"], "doi": "10.12751/nncn.bc2013.0087", "affiliations": [{"index": "1", "address": "Institut f\u00fcr Theoretische Physik, Johann Wolfgang Goethe-Universit\u00e4t, Germany"}], "title": "Self-stabilizing Learning Rules in Neural Models driven by Objective Functions ", "abstract": "A large number of neuronal models accounting for intrinsic plasticity and associative synaptic learning mechanisms have been proposed in the past, successfully performing  tasks such as principal component analysis or processing of natural images. These models, however, usually require either the addition of a weight decay term to the Hebbian learning rule, or an extra weight vector normalization step, to avoid unbounded weight growth.\nIn the present work, learning rules for a neuronal model are derived from two objective functions. On the one hand, the neuron\u2019s firing bias is adjusted by minimizing the Kullback-Leibler divergence with respect to an exponential output distribution. On the other hand, learning rules for the synaptic weights are obtained by minimizing a Fisher information that measures the sensitivity of the input distribution with respect to the growth of the synaptic weights. In this way, we obtain rules that both account for Hebbian/anti-Hebbian learning and stabilize the system to avoid unbounded weight growth. As a by-product of the derivation, a sliding threshold, similar to the one found in BCM models, is obtained for the learning rules.\nAs a first application of these rules, the single neuron case is studied in the context of principal component analysis and linear discrimination. We observe that the weight vector aligns to the principal component when the input distribution has a single direction of maximal variance but, when presented with two directions of equal variance, the neuron  tends to pick the one with larger negative Kurtosis. In particular, this fact allows the neuron to linearly separate bimodal inputs. Robustness to large input sizes (~ 1000 inputs) is also studied, observing that the neuron is still able to find the principal component in a distribution under these conditions.", "acknowledgements": "", "id": 131157, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Rodrigo Echeveste"}, {"epithet": "1", "name": "Claudius Gros"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Evolution of the synaptic weight vector during training in Principal Component Analysis and Linear Discrimination tasks.", "figpath": "087.jpeg", "refs": "Marcovic D, Gros C (2012) Intrinsic Adaptation in Autonomous Recurrent Neural Networks. Neural Computation 24:  523\u2013540. DOI: 10.1162/NECO_a_00232\nTriesch J (2007) Synergies between intrinsic and synaptic plasticity. Neural Computation 19: 885-909. DOI: 10.1162/neco.2007.19.4.885\nBienenstock EL, Cooper LN, Munro PW (1982) Theory for the development of neuron selectivity: orientation specificity and binocular interaction in visual cortex. The Journal of Neuroscience 2: 32-48."}, {"correspondence": ["a.westhoff@fz-juelich.de"], "figid": 88, "doi": "10.12751/nncn.bc2013.0088", "affiliations": [{"index": "1", "address": " Simulation Lab Neuroscience - Bernstein Facility for Simulation and Database Technology, Institute for Advanced Simulation, J\u00fclich Aachen Research Alliance, Forschungszentrum J\u00fclich, Germany"}, {"index": "2", "address": "Institute for Advanced Simulation, J\u00fclich Supercomputing Centre, Forschungszentrum J\u00fclich, Germany"}, {"index": "3", "address": "Institute of Neuroscience and Medicin (INM-1), Forschungszentrum J\u00fclich, Germany"}], "title": "GPU-accelerated Segmentation of high-resolution Human Brain Images acquired with Polarized Light Imaging", "abstract": "High-resolution three-dimensional polarized light imaging (PLI) is an approach pursued by the INM-1 (Institute of Neuroscience and Medicine, Forschungszentrum J\u00fclich) to map nerve fibers and their pathways in human brains. The 100 micron thick sections of the cut post-mortem brain are imaged with a microscopic device using polarized light. This way the birefringence of the myelin sheaths surrounding nerve fiber axons allows to extract a vector field of fiber tract orientations that form the basis for tractography.\nThe section is moved during the imaging within the microscope so that a mosaic of about 30x30 image tiles is created for a gross-histological human brain section. These up to 900 tiles per section have to be handled in the 3D-reconstruction of the brain. One of the most challenging and expensive tasks of the reconstruction pipeline is the registration of the sections among each other which is needed due to non-linear deformations occurring during the brain preparation. A way to accelerate this process is a segmentation of the image tiles which leads to black-and-white masks marking the brain and background pixels of the original tiles. Hence, all non-brain parts of the tiles can be ignored during the registration.\nA region growing segmentation has been enhanced and specialised for the PLI data. The challenge to adapt this algorithm to the given dataset is to automatize the choice of seeds needed as starting points for the growing process. Therefore, an automated method of seed determination has been developed. It uses statistics of the whole brain based on the image histogram. This approach leads to a minimal fixed amount of required manual input which is independent of the number of image tiles to be segmented. The parallel software tool is developed to be executed on JUDGE, a supercomputer hosted by JSC (J\u00fclich Supercomputing Centre, Forschungszentrum J\u00fclich). Calculating parts of the algorithm on GPUs reduces their execution time by a factor of 100.", "acknowledgements": "(Partially) Funded by the Helmholtz Association through the Helmholtz Portfolio Theme \"Supercomputing and Modeling for the Human Brain\".", "id": 131158, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Anna Westhoff"}, {"epithet": "2", "name": "Oliver B\u00fccker"}, {"epithet": "3", "name": "Markus Axer"}, {"epithet": "2", "name": "Johannes Grotendorst"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Axer, M. et al. (2011) High-resolution fiber tract reconstruction in the human brain by means of three-dimensional polarized light imaging (3D-PLI). doi:10.3389/fninf.2011.00034\nAxer, M. et al. (2010) Towards ultra-high resolution fibre tract mapping of the human brain - registration of polarised light images and reorientation of fibre vectors. doi:10.3389/neuro.09.009.2010\nAdams, R., Bischof, L. (1994) Seeded Region Growing. doi:10.1109/34.295913"}, {"correspondence": ["j.ito@fz-juelich.de"], "figid": 89, "doi": "10.12751/nncn.bc2013.0089", "affiliations": [{"index": "1", "address": "Institute of Neuroscience and Medicine (INM-6) and Institute for Advanced Simulation (IAS-6), J\u00fclich Research Centre and JARA, Germany"}, {"index": "2", "address": "Graduate School of Frontier Biosciences, Osaka University, Osaka, Japan"}], "title": "Effects of complex background on the object selective response of current source in the inferior temporal cortex of macaque monkeys", "abstract": "Neuronal activities in the inferior temporal (IT) cortex exhibit object-selective visual responses [1,2]. Such selectivity is typically assessed by measuring the neuronal activities while subjects are fixating at stimulus images which are displayed in isolation on a gray background. In our daily life, however, visual objects are embedded in complex background and their emergence is typically preceded by a fast change of the background due to saccadic eye movement. Given these differences, it is elusive whether the observations from standard experimental conditions can be extended to natural viewing conditions.\nWe studied whether and how complex background and its sudden change affect the object-selective neuronal activities in the macaque IT cortex. We presented visual objects either (A) on a gray background, (B) on complex backgrounds during prolonged presentations of the backgrounds, or (C) on complex backgrounds that appear simultaneously with the onset of the object presentation, to analgesized and immobilized macaque monkeys. We recorded LFP responses in the IT cortex simultaneously from multiple depths and reconstructed the current source density (CSD), which reflects local synaptic processes.\nWe found that the CSDs showed object selective responses. Their object preference was considerably modified when objects were embedded in complex (condition B) instead of gray backgrounds (condition A). On the other hand, when a sudden change of the background is provided at the onset of the object presentation (condition C), object selectivity became similar to that in condition A, suggesting a cancellation of the background effect observed in condition B. In addition, we observed the enhancement of response magnitude in condition C compared to conditions A and B. We will discuss the implications of these results to the visual processing in natural conditions, in particular active visual search of complex objects embedded in natural scenes.\n", "acknowledgements": "Partly financed by Helmholtz Alliance on Systems Biology and German-Japanese Joint Computational Neuroscience Program (grant 01GQ1114)", "id": 131159, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Junji Ito"}, {"epithet": "2", "name": "Masamitsu Mukai"}, {"epithet": "2", "name": "Hiroshi Tamura"}, {"epithet": "1", "name": "Sonja Gr\u00fcn"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Tanaka K (1996) Inferotemporal cortex and object vision. Annual review of neuroscience 19:109\u2013139.\n[2] Kreiman G, Hung CP, Kraskov A, Quiroga RQ, Poggio T, DiCarlo JJ (2006) Object selectivity of local field potentials and spikes in the macaque inferior temporal cortex. Neuron 49:433\u2013445.\n"}, {"correspondence": ["s.strokov@fz-juelich.de"], "doi": "10.12751/nncn.bc2013.0090", "affiliations": [{"index": "1", "address": "Institute of Neuroscience and Medicine (INM-6) and Institute for Advanced Simulation (IAS-6), J\u00fclich Research Centre and JARA, J\u00fclich, Germany"}, {"index": "2", "address": "Graduate School of Frontier Biosciences, Osaka University, Japan"}, {"index": "3", "address": "Theoretical Systems Neurobiology, RWTH Aachen Univ, Aachen, Germany"}], "title": "Spatio-temporal modulations of object selectivity in the inferior temporal cortex", "abstract": "The inferior temporal (IT) cortex is known for object recognition since IT neurons selectively respond to specific, complex visual objects [1]. It has been shown that not only spiking activity but also local field potentials (LFPs), which are considered to reflect the synaptic input to the local area, show selective responses in IT [2]. As other cortical areas, IT has a layered structure. Middle layer, called granular, primarily receives feed forward projections from other cortical areas, and is therefore considered as an input layer. While supra-granular and infra-granular layers mainly send projections to other areas, and are considered as output layers [3].\nHere we aim to test the hypothesis that object selectivity of the LFP response is processed across the cortical layers. Therefore we recorded in analgesized and immobilized macaque monkeys LFPs simultaneously from multiple depths of IT cortex using a linear electrode array. Recording was done at 5 sites in 3 hemispheres of 2 animals. The monkeys were presented with a set of 128 visual stimuli consisting of geometric shapes and natural objects. Each of the objects was shown separately on a gray background for 0.5 sec. From the amplitudes of the LFPs (bandpass filtered 1.5-300Hz) during the stimulus presentations we computed the selectivity index (SI) defined as across-stimulus response variance divided by within-stimulus variance [2].\nAbout 100ms after stimulus onset we observed a negative deflection in the LFP amplitude in the granular layer which is typically not associated with a high SI value (see Figure). Later, at 230ms after stimulus onset there was a second, strong negative deflection of LFP amplitude spanning all layers which is associated with strong selectivity in all layers. This suggests a transformation of non-specific input activity in the middle layer to object-selective output in the upper layers, and can be interpreted as a reflection of computational processes across layers.", "acknowledgements": "Acknowledgements: Partly financed by Helmholtz Alliance on Systems Biology and German-Japanese Joint Computational Neuroscience Program (grant 01GQ1114)         ", "id": 131160, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Serge Strokov"}, {"epithet": "1", "name": "Junji Ito"}, {"epithet": "2", "name": "Hiroshi Tamura"}, {"epithet": "1,3", "name": "Sonja Gr\u00fcn"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Figure caption: Time course of LFP selectivity index (SI) (top) and trial averaged LFP amplitude (bottom). The horizontal axis indicates the time (stimulus onset at 0ms), while the recording channels span the vertical axis (top: superficial layers, bottom:  deep layers). Vertical dashed lines indicate on- and offset of stimulus presentation. Horizontal dashed lines mark the boundary of the region where an initial current sink was detected by CSD analysis, interpreted as the input layer.", "figpath": "090.png", "refs": "1. Tanaka, 1993, Science, 262:685-688\n2. Kreiman et al., 2006, Neuron, 49:433-445\n3. Felleman & Van Essen, 1991, Cerebral Cortex, 1: 1\u201347."}, {"correspondence": ["guetig@em.mpg.de"], "doi": "10.12751/nncn.bc2013.0091", "affiliations": [{"index": "1", "address": "Max Planck Institute of Experimental Medicine, Germany"}], "title": "Self-supervised neuronal processing of sensory streams", "abstract": "During behavior, a continuous stream of sensory information reaches the central nervous system in the form of a high-dimensional spatio-temporal pattern of action potentials. When processing such activity, many sensory neurons respond with exquisite tuning and high specificity to temporally local stimulus features, such as sounds within a communication call or shapes within a movie. Often the temporal extent of such embedded features is orders of magnitude shorter than the duration of the encompassing, behaviorally meaningful sensory episode. It is commonly hypothesized that the emergence of neuronal feature detectors requires temporal segmentation of the training data, to allow neurons to adjust the strength of their responses to isolated target features. It is unclear, how such temporal supervision is implemented in neuronal circuits, in particular before sensory representations have formed.\n\nHere we show that only the number of feature occurrences without any temporal information is sufficient to train biologically plausible model neurons to detect spatio-temporal patterns of spikes that arrive embedded in long streams of background activity. Intriguingly, neurons can even learn complex continuous tuning functions from aggregate training labels, i.e. the sum of the desired response strengths over multiple features occurring within a given trial. Neither individual counts nor the times of features are needed in this segmentation free learning scheme.\n\nWe discovered that the simplicity of such supervisory signaling allows neuronal networks to self-supervise: A single supervisor neuron that feeds back the mean population activity as training label enables neuronal populations to reliably detect reoccurring spike patterns in their input activity without any external supervision. By successfully applying these findings to bird song and human speech recognition tasks we establish a novel network mechanism for self-supervised learning in populations of spiking neurons.", "acknowledgements": "Very helpful discussion with Peter Dayan, Winfried Denk, Ahmed El Hady and David Hansel are gratefully acknowledged.", "id": 131161, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Robert G\u00fctig"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Segmentation free neuronal learning. Voltage trace of an Intergrate & Fire neuron that was simultaneously trained to respond to five out of ten \"sensory\" features (color patches) with different output spike numbers (blue: 1 spike, light blue: 2 spikes, green: 3 spikes, yellow: 4 spikes, red: 5 spikes). Each feature corresponds to a distinct 50ms input spike pattern. During training feature spike patterns are randomly embedded within a stream of Poisson background firing of the same statistics. The neuron only receives the aggregate number of desired output spikes as a supervisory signal, but neither the number of target features, nor their individual occurrence times or counts.", "figpath": "091.png", "refs": ""}, {"correspondence": ["hillmann@em.mpg.de"], "doi": "10.12751/nncn.bc2013.0092", "affiliations": [{"index": "1", "address": "Max Planck Institute of Experimental Medicine, G\u00f6ttingen, Germany"}], "title": "Specialization of sensory neuronal target detectors", "abstract": "Many neurons in sensory pathways respond selectively to a narrow class of stimuli such as faces or specific communication calls. At the same time neuronal processing is robust to a large degree of natural variability within such complex stimulus classes. For instance, face detection must be robust with respect to a particular hair or eye color and speech processing must tolerate large differences between female and male vocalizations. It is hypothesized that such difficult perceptual invariances might be subserved by populations of neurons that specialize on different substructures within a sensory object category. However, it is unclear what neuronal mechanisms of learning could underly such symmetry breaking within a populations of sensory neurons.\n\nOne important state of the art ensemble method for neuronal populations is the mixture of experts model[1] that induces specialization of expert neurons via gating neurons that route inputs to individual experts. However, because this model relies on complex neuronal interactions, its biologically plausible implementation has remained challenging.\n\nHere we show that symmetry breaking and specialization within populations of sensory neurons can emerge through a simpler instantiation of a competitive population learning rule, the tagging algorithm. To mimic a sensory classification task we simulate a population of spiking neurons and require the number of responding neurons to discriminate between predefined target and null stimuli. Upon erroneous trials, the tagging algorithm uses different properties of the neuronal responses, eg spike-times or depolarization, to select ('tag') only a subset of neurons to undergo learning while the others remain unchanged. We implement this algorithm with populations of tempotron[2] integrate & fire neurons and demonstrate its ability to induce specialized neuronal feature detectors for synthetic spike patterns as well as for auditory objects in a neuronal model of speech recognition.", "acknowledgements": "Financial support of the NEUROSENSES PhD training in Integrative Neurosensory Sciences is gratefully acknowledged.", "id": 131162, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Julia Hillmann"}, {"epithet": "1", "name": "Robert G\u00fctig"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Specialization of neuronal feature detectors. Left: Learning curves\nof a population of 20 neurons discriminating a target class of 20 fixed spike\npatterns (at least one neuron has to fire) versus random spike patterns of the\nsame statistics (all neurons have to remain silent). In each trial noise is induced by\nrandom deletion of spikes and Gaussian spike time jitter. Due to the\nspecialization of each neuron to one of the target spike patterns, the\npopulation trained with tagging algorithm (blue) substantially outperforms a\nsingle neuron (green) as well as a population of 20 independently trained\ncells with majority voting (red). Right:\nIndividual response probabilities of the \"tagging\" population (colorbar). Each\nneurons specializes on a single template.", "figpath": "092.jpeg", "refs": "[1] Jacobs, R. A., Jordan, M. I., Nowlan, S. J., Hinton, G. E. (1991). Adaptive Mixtures of Local Experts. Neural Computation 3: 79-87\n[2] G\u00fctig, R. and Sompolinsky, H. (2006). The tempotron: a neuron that learns spike timing-based decisions. Nature Neuroscience 9: 420-428"}, {"correspondence": ["arash_kermani@yahoo.com"], "figid": 94, "doi": "10.12751/nncn.bc2013.0094", "affiliations": [{"index": "1", "address": "TU-Chemnitz, Germany"}], "title": "Unsupervised neural learning improves image classification under occlussion", "abstract": "In recent years several different learning approaches have been developed to model the early vision, particularly at the level of V1 [1]. The major criterion for evaluation of those models is the ability to develop oriented, bandpass receptive fields and if the distribution of receptive field types mimics the distribution of observed ones from the macaque. Although the match to biological data can be considered as one important criterion, further criteria are required to evaluate the different approaches. We here investigate the robustness with respect to loss of information in the form of occlusions, that is, partial absence of information in the input. We use two classical generative models of vision; non-negative matrix factorization with sparseness constraints (NMFSC) [2] and an ICA algorithm, here fastICA [3] and compare them to a Hebbian learning model [1]. We used a Linear Discriminant Analysis (LDA) classifier to measure the performance of classification after the data was preprocessed with each of the three mentioned methods. The LDA classifier used on output of the neural network, fastICA and NFMSC is a benchmark for observing how much each of the methods can compensate the loss of information. The neural network showed more robustness under occlusion than the other two preprocessors. This would imply that the prior knowledge our Hebbian network has learnt, is accurate enough to make right decisions about the input even if a part if the data is lost. The input images were taken from MNIST handwritten digit images and natural images from the set provided by Patrik Hoyer (http://www.cs.helsinki.fi/u/phoyer/code/nnscpack.tar.gz).", "acknowledgements": "This work has been supported by the German Academic Exchange Service(DAAD).", "id": 131163, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Arash Kermani Kolankeh"}, {"epithet": "1", "name": "Michael Teichman"}, {"epithet": "1", "name": "Fred Hamker"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Teichmann, M., Wiltschut, J., Hamker, F.H. (2012). Learning invariance from natural images inspired by observations in the primary visual cortex. Neural Computation., 24(5):1271\u20131296.\n[2] Hoyer P.O., E. (2004). Non-negative Matrix Factorization with Sparseness Constraints. Journal of Machine Learning Research, 5:1457\u20131469.\n[3] Hyvrinen A. and Oja E. (2004). A Fast Fixed-Point Algorithm for Independent Component Analysis. Neural Computation, 9(7):1483\u20131492."}, {"correspondence": ["michael.teichmann@informatik.tu-chemnitz.de"], "figid": 95, "doi": "10.12751/nncn.bc2013.0095", "affiliations": [{"index": "1", "address": "Chemnitz University of Technology, Germany"}, {"index": "2", "address": "University of Minnesota, United States"}], "title": "What are the Benefits of Structural Plasticity in a Model of the Primary Visual Cortex?", "abstract": "In many neuronal network models, the connectivity must be predefined by the modeler. Depending on her expertise, the modeler has to find an appropriate setup for her model with respect to neuroscientific knowledge and the network's function. Inappropriate connectivity could lead to strong fluctuation in learning or induce a strong bias. This problem can be overcome using structural plasticity. Structural plasticity encompasses the formation and pruning of synapses, the growth and degradation of dendritic spines, and the outgrowth and retraction of axons and dendritic arbors (Butz et al., 2009b). \nWe have thus modeled as an activity-dependent stochastic process (Butz et al., 2009a). Neuronal activity govern the dendritic outgrowth and the probability of synapse removal, whereas the formation of synapses at the dendritic sides has a fixed probability. These mechanisms are applied in a network for learning V1 receptive fields (Teichmann et al., 2012). The synaptic plasticity in this model is based on calcium dependent Hebbian learning rules with homeostatic regulations (Teichmann et al., 2012).\nWe address two major topics. First, we present an additional (structural) plasticity rule to enhance the stability of a network, particularly the stability of receptive fields. Second, we develop the ability to create an appropriate connection structure in a model learning V1 receptive fields trained on natural scenes. We show that the resulting connection patterns are comparable to physiological data, and that the stability of the receptive fields is increased. Additionally, we show that the retinotopic topology of V1 is preserved, despite the continuous changes in connectivity.", "acknowledgements": "This work has been supported by the German Science Foundation (DFG GRK1780/1) and the DAAD RISE program.", "id": 131164, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Michael Teichmann"}, {"epithet": "2", "name": "Maxwell Shinn"}, {"epithet": "1", "name": "Fred Hamker"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Butz, Van Ooyen, W\u00f6rg\u00f6tter (2009a). A model for cortical rewiring following deafferentation and focal stroke. Frontiers in computational neuroscience, 3(August), 10.\nButz, W\u00f6rg\u00f6tter, Van Ooyen (2009b). Activity-dependent structural plasticity. Brain research reviews, 60(2), 287\u2013305.\nTeichmann, Wiltschut, Hamker (2012). Learning invariance from natural images inspired by observations in the primary visual cortex. Neural computation, 24(5), 1271\u201396."}, {"correspondence": ["logo@hrz.tu-chemnitz.de"], "figid": 96, "doi": "10.12751/nncn.bc2013.0096", "affiliations": [{"index": "1", "address": "TU Chemnitz, Artificial Intelligence, Germany"}, {"index": "2", "address": "BCCN Berlin, Germany"}], "title": "The Dentate gyrus, more than just pattern separation?", "abstract": "In theories of hippocampal function, a main question of interest concerns the differential roles of hippocampal formation subregions. According to the auto-associative model [1,2], CA3 activity will converge towards one of several previously stored patterns of activity whenever a partial or noisy cue is presented. The dentate gyrus, in turn, is assigned a role as a \u201cteacher\u201d during storage but not recall, imposing discrete, minimally overlapping activity patterns on CA3.\nAmong several other proposals for the role of the dentate gyrus, such as storing autoassociations [3], we suggest that the concept of contextual modulation of CA3 activity by the dentate gyrus [4] deserves further investigation. We have developed a computational model of the interaction between CA3 and DG, modeled as populations of spiking neurons, and learning using STDP rules. \nExperimental support for this view comes from recent studies of the influence of dentate activity on sharp-wave ripples, which have found that the DG may bias hippocampal sharp waves [5,6]. Computational models have viewed replay during sharp waves as a recall process [7,8] in a similar sense as in auto-associative models. \nOur model suggests that specific DG activity during memory recall can improve recall performance, especially in the case of overlapping memory items or sequences. Specifically, we discuss the computational role of the mossy fiber \u201cen-passant\u201d projections from the dentate gyrus to interneurons of the CA3 region [9] which are often neglected in hippocampal modelling.", "acknowledgements": "This work has been funded by DFG grant HA2630/4-2 \u201cThe cognitive control of visual selection and action perception\u201d and EU FP7-ICT grant 600785 \u201cSpaceCog\u201d.", "id": 131165, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Lorenz Goenner"}, {"epithet": "1", "name": "Julien Vitay"}, {"epithet": "1,2", "name": "Fred H. Hamker"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Treves A and Rolls ET. Hippocampus 2(2): 189-199 (1992).\n[2] Becker S. Hippocampus 15:722\u2013738 (2005).\n[3] Lisman JE. Neuron 22: 233\u2013242 (1999).\n[4] Doboli S et al. Neural Computation 12, 1009-1043 (2000).\n[5] Rex CS et al. PLoS One 4(11): e7761 (2009).\n[6] Sullivan D et al. J Neurosci 31(23): 8605\u20138616 (2011).\n[7] Molter C et al. Hippocampus 17(3): 201\u2013209 (2007).\n[8] Bush D et al. PLoS Comput Biol 6(7): e1000839 (2010).\n[9] Acs\u00e1dy L, et al. J Neurosci 18(9):3386\u20133403 (1998)"}, {"correspondence": ["fernando.ramirez@bccn-berlin.de"], "figid": 97, "doi": "10.12751/nncn.bc2013.0097", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Charit\u00e9 - Universit\u00e4tsmedizin Berlin, Germany"}], "title": "Probing the representation of face orientation in human ventral visual cortex", "abstract": "The increased sensitivity provided by the application of multivariate pattern analysis methods to functional magnetic resonance imaging (fMRI) data has led to the application of such methods to a growing number of neuroscientific questions. A critical issue that requires special attention is the interpretation of classification results in any brain region of interest. Thus, if diagnostic information regarding a dimension of interest is detected, say, face orientation, next the question arises concerning how information is encoded in the measured signals, and the relationship between such signals and underlying neural populations. Recent studies suggest the representation of face orientation in ventral visual cortex may be mirror-symmetric (e.g. responses to right- and left-profile views are similar). However, abundant data suggest that neural representations of faces are tuned to a single preferred view, suggesting a monotonic angle code. Here, we first present simulations showing how signal-to-noise-ratio (SNR) effects may have been mistaken as evidence of mirror-symmetry. Then, we propose a solution to this problem based on a modeling approach that simulates, given a small number of biologically plausible parameters, the expectancy of a family of model similarity matrices associated with a set of experimental conditions, each defined by a concrete model parameter combination. Model parameters include the tuning width of assumed neural populations, their level of clustering according to tuning properties, and the strength of the representation of various views covering a full rotation of the head. We use this approach to show in the fusiform face area (FFA) (1) the dominance of a monotonic angle code, and (2) an overrepresentation of frontal face-views. Finally, we show our method can distinguish univariate and SNR effects from the underlying multivariate representational structure, presumably reflecting the inhomogeneous sampling of view-tuned neural populations.", "acknowledgements": "We thank Jakob Heinzle, Robert Martin and Yi Chen for helpful comments. This research was partially funded by a DAAD-CONICYT doctoral scholarship.", "id": 131166, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Fernando Ram\u00edrez"}, {"epithet": "1", "name": "Carsten Allefeld"}, {"epithet": "1", "name": "John-Dylan Haynes"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["d.grytskyy@fz-juelich.de"], "figid": 98, "doi": "10.12751/nncn.bc2013.0098", "affiliations": [{"index": "1", "address": "INM-6 & IAS-6, Research Center J\u00fclich, Germany"}, {"index": "2", "address": "Medical Faculty, RWTH Aachen, Germany"}], "title": "Connectivity reconstruction from complete or partially known covariances in the asynchronous irregular regime", "abstract": "The question about synaptic connectivity reconstruction from the measurement of neuronal activity is studied since [1]. Some of since then developed approaches treat correlated activity per se as a measure of functional connectivity [2], others apply Shannon entropy [3]. A stochastic framework [4] distinguishes between direct connections and common input for the repeated presentation of an external stimulus. Timme [5] investigated networks exhibiting regular spiking due to external stimulation and obtained exact expressions for the connectivities from the perturbation of inter-spike-intervals. The linear approximation of the dynamic response provides expressions for the cross covariances [6] and was recently applied to reconstruct sparse network connectivities [7]. Within this framework, we here propose methods valid in the asynchronous irregular regime that enable the reconstruction of arbitrary connectivities from averaged rates and covariances measured in absence of external stimuli. The first method requires the covariance matrix between spike trains in the Fourier domain, known as the cross-spectrum. The cross-spectrum at two distinct frequencies uniquely determines the connectivity matrix by a decomposition of the inverted covariance matrix into real and imaginary parts, leading to the symmetric and antisymmetric parts of the connectivity, respectively. If the cross-spectrum is given for several frequencies, the neuronal response kernel can be obtained for them. The main disadvantage of this method is the requirement of the full covariance matrix, which is often not available. We therefore propose a second method based on the expansion of the covariance in powers of the connectivity multiplied by the kernel function. Reconstruction is here performed by a projection of the measured covariances on powers of the kernel function. This method is less accurate than the previous one and has more constraints, but is applicable to each known pair of neurons separately.", "acknowledgements": "Partially supported by the Helmholtz Association: HASB and portfolio theme SMHB, the J\u00fclich Aachen Research Alliance (JARA), the Next-Generation Supercomputer Project of MEXT, and EU Grant 269921 (BrainScaleS). ", "id": 131167, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Dmytro Grytskyy"}, {"epithet": "1,2", "name": "Markus Diesmann"}, {"epithet": "1", "name": "Moritz Helias"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Aertsen AMHJ et al (1989) J Neurophysiol 61(5): 900-917 \n[2] Stevenson IH et al (2008) Curr Opin Neurobiol 18(6): 582-588 \n[3] Singh A, Lesica, NA (2010) PLoS Comput Biol 6(12): e1001035 \n[4] Nykamp DQ (2009) J Math Biol 59(2): 147-173 \n[5] Van Bussel F et al (2011) Front. Comput. Neurosci. 5: 3 \n[6] Tetzlaff T et al (2012) PLoS Comp Biol 8(8):e1002596 \n[7] Pernice V, Rotter S (2012). Front. Comput. Neurosci. Conference Abstract: Bernstein Conference "}, {"correspondence": ["kunkel@fz-juelich.de"], "figid": 99, "doi": "10.12751/nncn.bc2013.0099", "affiliations": [{"index": "1", "address": "Simulation Laboratory Neuroscience \u2013 Bernstein Facility Simulation and Database Technology, Institute for Advanced Simulation, J\u00fclich Aachen Research Alliance, J\u00fclich Research Centre, Germany"}, {"index": "2", "address": "Institute of Neuroscience and Medicine (INM-6) and Institute for Advanced Simulation (IAS-6), J\u00fclich Research Centre and JARA, Germany"}, {"index": "3", "address": "Department of Mathematical Sciences and Technology, Norwegian University of Life Sciences, Aas, Norway"}, {"index": "4", "address": "Laboratory for Neural Circuit Theory, RIKEN Brain Science Institute, Wako, Japan"}, {"index": "5", "address": "High-Performance Computing Team, RIKEN Computational Science Research Program, Kobe, Japan"}, {"index": "6", "address": "Integrated Systems Biology Laboratory, Department of Systems Science, Graduate School of Informatics, Kyoto University, Japan"}], "title": "NEST: Highly scalable simulation technology from laptops to supercomputers", "abstract": "Over the last couple of years, supercomputers such as the Blue Gene/Q system JUQUEEN in J\u00fclich and the K computer in Kobe have become available for neuroscience research. These massively parallel systems open the field for a new class of scientific questions as they provide the resources to represent and simulate brain-scale networks, but they also confront the developers of simulation software with a new class of problems. Initial tests with our neuronal network simulator NEST [1] on JUGENE (the predecessor of JUQUEEN) revealed that in order to exploit the memory capacities of such machines, we needed to improve the parallelization of the fundamental data structures. To address this, we developed an analytical framework [2], which serves as a guideline for a systematic and iterative restructuring of the simulation kernel. In December 2012, the 3rd generation technology was released with NEST 2.2, which enables simulations of 10^8 neurons and 10,000 synapses per neuron on the K computer [3].\n\nEven though the redesign of the fundamental data structures of NEST is driven by the demand for simulations of interacting brain areas, we do not aim at solutions tailored to a specific brain-scale model or computing architecture. Our goal is to maintain a single highly scalable code base that meets the requirements of such simulations whilst still performing well on modestly dimensioned lab clusters and even laptops.\n\nHere, we introduce the 4th generation simulation kernel, which does not compromise on the general usability of NEST and will be be released with NEST 2.4. We show that with the 4g technology it will be possible to simulate networks of 10^9 neurons and 10,000 synapses per neuron on the K computer.", "acknowledgements": "Early access to K computer at RIKEN AICS, VSR grant JINB33, Alliance on Systems Biology, Initiative and Networking Fund and Portfolio theme SMHB of the Helmholtz Association, MEXT Next-Generation Supercomputer Project, EU Grant 269921(BrainScaleS), Research Council of Norway grant 178892/V30(eNeuro)", "id": 131168, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Susanne Kunkel"}, {"epithet": "2", "name": "Maximilian Schmidt"}, {"epithet": "2", "name": "Jochen Martin Eppler"}, {"epithet": "3", "name": "Hans Ekkehard Plesser"}, {"epithet": "4", "name": "Jun Igarashi"}, {"epithet": "5", "name": "Gen Masumoto"}, {"epithet": "4", "name": "Tomoki Fukai"}, {"epithet": "6", "name": "Shin Ishii"}, {"epithet": "1", "name": "Abigail Morrison"}, {"epithet": "2", "name": "Markus Diesmann"}, {"epithet": "2", "name": "Moritz Helias"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Gewaltig MO, Diesmann M: NEST (NEural Simulation Tool). Scholarpedia 2007, 2(4):1430.\n2. Kunkel  S, Potjans TC, Eppler JE, Plesser HE, Morrison A, Diesmann M: Meeting the memory challenges of brain-scale simulation.  Front. Neuroinform. 2012, 5:35.\n3. Helias M, Kunkel S, Masumoto G, Igarashi J, Eppler JE, Ishii S, Fukai T, Morrison A, Diesmann M: Supercomputers ready for use as discovery machines for neuroscience. Front. Neuroinform. 2012, 6:26."}, {"correspondence": ["thomas.fucke@zi-mannheim.de"], "figid": 100, "doi": "10.12751/nncn.bc2013.0100", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Psychiatry, Central Institute of Mental Health, Medical Faculty Mannheim, Heidelberg University, Germany"}, {"index": "2", "address": "Cortical Plasticity Laboratory, Dept. of Physiopathology of Neuronal Plasticity, Neurocentre Magendie, Bordeaux, France"}, {"index": "3", "address": "Laboratory of Neural Circuit Dynamics, Brain Research Institute, University of Zurich, Switzerland"}], "title": "Towards a Model of Postnatal Development in Cortical Layer 2/3: Single Cell Properties", "abstract": "Many psychotic disorders, such as schizophrenia, can be led back to problems during postnatal development (for a good overview, see David, Kapur & McGuffin, 2011). Here, we examine the changes in intrinsic cell parameters during postnatal maturation and the underlying mechanisms in principal cells of layer 2/3 (L2/3) of the rat somatosensory cortex.\nWhole cell recordings where obtained from neurons in acute brain slices from one- to four-week old rats (P8-P28). Developmental changes in morphology were assessed from biocytin-filled neurons. Based on the cells\u2019 responses upon somatic injection of rectangular current pulses, over the age range resting membrane potential on average dropped from -63 to -78 mV, input resistance dropped from ~200 MOhm to ~40 MOhm, with an accompanying decrease of the cell time constant from 30 ms to 12 ms, while anomalous rectification in these cells (AR; Waters & Helmchen, 2006) dropped from 130 MOhm/nA to 20 MOhm/nA. From these parameters, we conclude that L2/3 pyramidal cells show a marked decrease in excitability during the first weeks of postnatal development, suggesting that more synaptic drive is required for suprathreshold activation as age increases.\nTo further explore these findings, we constructed a sub-threshold, conductance-based single compartment models using the NEURON simulation environment (Carnevale & Hines, 2006). Parameters were optimized by utilizing a simulated annealing algorithm (Press et al., 1992). Variability in parameters was estimated by generating a series of models by fitting to several separate single in vitro experiments for each age group. Following the findings of pharmacological experiments, the model comprises leak, inward-rectifier K+ (KIR-) and Ih conductances. Currently, we employ this model to reproduce membrane potential measurements in vivo at different ages in order to estimate changes in synaptic input to L2/3 pyramidal cells during postnatal development.", "acknowledgements": "This work is funded through a grant from the German Ministry of Education and Research (BMBF, 01GQ1003B).", "id": 131169, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Thomas Fucke"}, {"epithet": "1", "name": "Thomas Hahn"}, {"epithet": "2", "name": "Andreas Frick"}, {"epithet": "3", "name": "Fritjof Helmchen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "David AS, Kapur S & McGuffin P (Editors): Schizophrenia \u2013 The Last Frontier (A Festschrift for Robin M. Murray). Psychology Pr.: The Maudsley Series (2011)\n\nWaters J, Helmchen F: Background Synaptic Activity is Sparse in Neocortex. J Neurosc 26(32):8267-8277 (2006)\n\nCarnevale NT, Hines ML: The NEURON Book. Cambridge, UK: Cambridge University Press (2006)\n\nPress WH, Flannery BP, Teukolsky SA, Vetterling WT: Numerical Recipes in C (Second Edition). Cambridge, UK: Cambridge University Press (1992)"}, {"correspondence": ["marek.rudnicki@tum.de"], "figid": 101, "doi": "10.12751/nncn.bc2013.0101", "affiliations": [{"index": "1", "address": "Technische Universit\u00e4t M\u00fcnchen, Germany"}], "title": "Influence of pulse shape and electrode position on cochlear implant stimulation", "abstract": "Cochlear implants (CIs) stimulate the auditory nerve with charge-balanced biphasic pulses. However, in animal experiments, monophasic or asymmetric pulses result in higher efficiency (Wiler et al. 1989). Pulse polarity has only small effects for biphasic stimuli, larger effects are expected for triphasic pulses. The influence of pulse polarity could depend on several factors: pulse shape, electrode position or species.\n\nWe tested 7 CI patients (MED-EL-PulsarCI100) using standard biphasic pulses and compared sensations with triphasic pulses. All leading-phase polarity combinations were investigated on the 1st (most apical) and the 6th (middle) electrode. The task was to adjust the loudness (2-AFC, 2-down/1-up) of the triphasic pulses to the biphasic reference at a near-threshold level (threshold+25\u00b5A).\n\nOur results show that triphasic pulses are less efficient than biphasic pulses in agreement with Coste and Pfingst (1996). We found a strong and significant threshold difference when we switched pulse polarity for triphasic pulses, but only at the most apical electrode. At the middle electrode, changes were smaller and not statistically significant.\n\nIn addition, we simulated the experiment with with a multi-compartment Hodgkin-Huxley type neuron model. Biphasic pulses were more efficient than triphasic. As in the experiment, the position of the electrode relative to the neuron influenced the threshold difference between polarities. When the electrode was moved to the end of the neuron and beyond (position of apical electrode), the sign of the difference changed.\n\nThe model predicts that the apical electrode lies beyond the neurons, whereas the middle electrode is close to the end or even alongside the neurons.", "acknowledgements": "Support provided by the Munich Bernstein Center for Computational Neuroscience by the German Federal Ministry of Education and Research (reference numbers 01GQ0441 and 01GQ1004B), MED-EL Innsbruck and Universit\u00e4t Innsbruck.", "id": 131170, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Sonja Karg"}, {"epithet": "1", "name": "Marek Rudnicki"}, {"epithet": "1", "name": "Christina Lackner"}, {"epithet": "1", "name": "Werner Hemmert"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Wiler, J. A., Clopton, B. M., & Mikhail, M. A. (1989). Effect of electrical pulse shape on AVCN unit responses to cochlear stimulation. Hearing research, 39(3), 251-261.\n\nCoste, R. L., & Pfingst, B. E. (1996). Stimulus features affecting psychophysical detection thresholds for electrical stimulation of the cochlea. III. Pulse polarity. Journal of the Acoustical Society of America, 99(5), 3099-3108.\n"}, {"correspondence": ["stefanie.keller@tum.de"], "figid": 102, "doi": "10.12751/nncn.bc2013.0102", "affiliations": [{"index": "1", "address": "Technische Universit\u00e4t M\u00fcnchen, IMETUM, Bio-Inspired Information processing, Germany"}, {"index": "2", "address": "MED-EL Deutschland GmbH, Germany"}, {"index": "3", "address": "Hochschule f\u00fcr angewandte Wissenschaften, FH M\u00fcnchen, Germany"}], "title": "Influence on Speech reception threshold (SRT) due to phase inversion and time shifting of background noise", "abstract": "Determination of the speech reception threshold (SRT) with background noise is a common tool to measure the speech intelligibility of CI-patients in an everyday listening situation. \nThis study analyses the influence on speech reception threshold of normal hearing subjects due to phase inversion (S0Npi) and interaural time differences (ITDs) of the background noise. 12 normal hearing subjects listened to Sentences of a german speech intelligibility test (OLSA) via headphones in a hearing booth. The background noise (olnoise) was shifted in time (0 and 0.625 ms) according to the speech signal. Levels at each ear were always the same. \nThe results show a better SRT for the ITD condition (0.625 ms) compared to the frontal condition (0 ms): (SRTfrontal = -5.75\u00b10.59 dB S/N gg. SRTITD(left) =-11.85\u00b11.55 dB S/N, SV SITD(right) = -11.95\u00b11.84 dB S/N). This is valid for natural ITDs. If the phase of the noise is inverted the results show further significant improvement compared to ITD of 0.625 ms (SRTS0Npi = -13.23\u00b11.56 dB S/N). This is interesting because the phase inversion of the background noise is an unnatural condition and the ITD condition is comparable to the situation where the noise is coming from the side and the signal from the front. \nThe current data are planned to act as reference for CI data. Thereby it can be seen if the patients can also profit from the phase inversion and the ITD of the background noise.  \n", "acknowledgements": "This work was supported by MED-EL and the Bernstein Centre of Computational Neuroscience (01GQ1004B, 01GQ1004D).", "id": 131171, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Stefanie Keller"}, {"epithet": "2", "name": "Christian Wirtz"}, {"epithet": "3", "name": "Hanna Beike"}, {"epithet": "3", "name": "Armin Giebel"}, {"epithet": "1", "name": "Werner Hemmert"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["werner.hemmert@tum.de"], "figid": 103, "doi": "10.12751/nncn.bc2013.0103", "affiliations": [{"index": "1", "address": "Technische Universit\u00e4t M\u00fcnchen, Germany"}, {"index": "2", "address": "MED-EL Starnberg, Germany"}], "title": "Analysis of Localization Cues Shaped by Globular Bushy Cells with a Sound Localization Model", "abstract": "Globular Bushy Cells (GBCs) are one of the principal cells in cochlear nucleus (CN). They receive major excitatory inputs from auditory nerve fibers (ANFs) and project their axons to the contralateral medial nucleus of the trapezoid body. GBCs are directly involved in the sound localization pathway to the lateral superior olive. We investigated how GBCs improve temporal cues encoded in neural spike trains.\nWe simulated auditory nerve responses with an auditory periphery model (Zilany et al. 2009). The GBC model was a single compartment representing a soma with Hodgkin-Huxley-like channels (Rothman and Manis 2003). It received purely excitatory inputs from ANFs. Synaptic weights were fitted to reproduce firing patterns of high-sync neurons in CN. Simulated responses from both ears were fed to a binaural cross-correlation model (Lindemann 1986). It consisted of delay lines inspired by Jeffress (1948) and additional inhibitory elements. The model is both ITD and ILD sensitive.\nWe simulated two types of sounds: pure tones and speech. The sound source was moving around the listener (1 rotation/s). Our results show that GBCs enhance localization cues over ANFs. GBCs are known to enhance the temporal precision of their spike trains by coincidence detection. They lock on low-frequency pure tones and enhance amplitude modulations, which are present in speech sounds. The internal representation of the sound source location in the Lindemann model is much sharper with GBCs compared with ANFs. With speech sounds this sharpening effect is particularly pronounced.\nThe analysis of spike trains derived from GBCs and ANFs using a sound localization model provided a quantitative analysis of the processing capabilities of GBCs. We observed how GBCs sharpen neuronal responses for simple and complex sounds in the time domain. Our analysis sheds new light on how ultraprecise temporal information is processed in the localization pathway to achieve pristine sound localization cues.", "acknowledgements": "This work was supported by the German Research Foundation (SPP 1608), the Bernstein Center for Computational Neuroscience Munich (BMBF 01GQ1004B and 01GQ1004D) and MED-EL.\n", "id": 131172, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Marek Rudnicki"}, {"epithet": "2", "name": "Christian Wirtz"}, {"epithet": "1", "name": "Werner Hemmert"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Jeffress, L. A. (1948). J. Comp. Physiol. Psychol, 41(1), 35-39.\nLindemann, W. (1986). JASA (80), 1608.\nRothman, J. S., & Manis, P. B. (2003). J. Neurophysiology, 89(6), 3083-30\nZilany, M. S., Bruce, I. C., Nelson, P. C., & Carney, L. H. (2009). JASA (126), 2390."}, {"correspondence": ["christian.wirtz@medel.de"], "figid": 104, "doi": "10.12751/nncn.bc2013.0104", "affiliations": [{"index": "1", "address": "MED-EL Deutschland GmbH, Germany"}, {"index": "2", "address": "Technische Universit\u00e4t M\u00fcnchen, Germany"}, {"index": "3", "address": "MED-EL, Austria"}], "title": "Model-based Prediction of Source Localization abilities in challenging listening situations for normal hearing and CI Listeners", "abstract": "Although modern cochlear implants (CI) provide good speech intelligibility, their performance lags behind normal hearing subjects in adverse listening conditions. Such scenarios are for example cocktail party situations with multiple simultaneous sound sources, noisy environments, music background or reverberations. It is well known that sound localization provides important cues to separate sources which enhance speech intelligibility in those environments.\n\nSince CIs were initially designed for monaural implantation only, there is room to optimize coding of binaural information. Within a simulated listening setup, binaural models, such as the Lindemann model, can provide a metric to predict source localization abilities. The metric was extended to work with action potentials, which are generated by physiologically inspired models of sound coding provided by an intact inner ear model and a model of electric hearing with different CI coding strategies.\n\nFor the evaluation we used realistic signals: our test scenario was a spoken sentence and we moved the virtual speaker around the virtual head of a cochlear implant patient. With a HD CIS strategy, the analysis indicated that the precision of the ITD coding was not sufficient for sound localization. However, the evaluation of a fine-structure coding strategy (FS4, MED-EL) revealed that, this strategy should be able to provide ITD cues with sufficient precision at least suitable for daily use: the temporal precision of the strategy is sufficient to separate seven spatial positions in the horizontal plane. In summary, the model framework introduced here is a valuable tool for the pre-evaluation and optimization of bilateral cochlear implant coding strategies. It provides quantitative values for the strength of the correlation between left and right ear auditory spike trains. The final evaluation, whether these cues can actually be exploited by cochlear implant users has yet to be determined by listening test.\n", "acknowledgements": "This work was funded by a grant from MED-EL Innsbruck and within the Munich Bernstein Center for Computational Neuroscience by the German Federal Ministry of Education and Research (reference number 01GQ1004B and 01GQ1004D).", "id": 131173, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Christia Wirtz"}, {"epithet": "2", "name": "Michele Nicoletti"}, {"epithet": "3", "name": "Peter Schleich"}, {"epithet": "3", "name": "Peter Nopp"}, {"epithet": "2", "name": "Werner Hemmert"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Lindemann, W. (1986), 'Extension of a binaural cross-correlation model by contralateral inhibition. I. Simulation of lateralization for stationary signals.', J Acoust Soc Am 80(6), 1608--1622.\nLindemann, W. (1986), 'Extension of a binaural cross-correlation model by contralateral inhibition. II. The law of the first wave front. ',  J Acoust Soc Am 80(6), 1623--1630.\nNicoletti, M.; Isik, M. & Hemmert, W. (2011), 'Model-based validation framework for coding strategies in cochlear implants' (CIAP)."}, {"correspondence": ["david@nld.ds.mpg.de"], "figid": 105, "doi": "10.12751/nncn.bc2013.0105", "affiliations": [{"index": "1", "address": "Max Planck Institute for Dynamics and Self-Organization, Germany"}, {"index": "2", "address": "Georg-August University, Goettingen, Germany"}, {"index": "3", "address": "Edinburgh University, United Kingdom"}], "title": "Bayesian filtering for classification enhancement of myoelectric signals", "abstract": "In pattern recognition methods for myoelectric prosthesis muscle activity is recorded from electrodes placed on the skin surface while a certain set of static contractions is performed. A widely used feature for myoelectric signal classification is root mean square (RMS) of a time window of the recorded signals. Within this time window the signal should be stationary which can be assumed only during static, constant force contractions. For dynamic contractions and changing force levels the estimation based on such a time window can be too slow to follow the change of the signal's standard deviation (SD) properly. An additional drawback is the time-delay due to windowing. In this study we apply an alternative estimation procedure of the SD based on a Bayesian method and a model for the temporal propagation of the probability distribution of the SD [1]. We compare the two methods in terms of classification performance. For this we investigate 6 different subjects who perform 8 static constant force hand contractions for 3 different force levels (20%, 40% and 60% maximum value contraction). Each contraction is repeated 10 times and held for 4 seconds. The signals are collected with two high density electrode arrays at the upper forearm yielding 126 monopolar signals. We use linear discriminant analysis (LDA) and sequential forward selection (SFS) to select the best (according to this heuristic search procedure) subset out of the 126 signals. We show that classification in the SD space yields slightly worse results for Bayesian method as compared to RMS with a time window of 200ms in the static signal regime, whereas if the dynamic regime is included results are comparable in performance. However, it is worth noting that the drawback of delay due to windowing is not present in the Bayesian approach. Additionally, we show that the Bayesian method is robust against noise. We reach a performance level robust to noise that is relevant for application in myoprosthetics.", "acknowledgements": "This work was funded by the BMBF in the framework of the Bernstein Focus for Neurotechnology Goettingen project 3b, grant number 01GQ0811.", "id": 131174, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "David Hofmann"}, {"epithet": "1", "name": "Benjamin Willenberg"}, {"epithet": "2", "name": "Dario Farina"}, {"epithet": "3", "name": "Michael Herrmann"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Sanger, T. D. (2007). Bayesian filtering of myoelectric signals. Journal of neurophysiology, 97(2), 1839\u201345. doi:10.1152/jn.00936.2006"}, {"correspondence": ["dominika@nld.ds.mpg.de"], "figid": 106, "doi": "10.12751/nncn.bc2013.0106", "affiliations": [{"index": "1", "address": "MPI DS, G\u00f6ttingen, Germany"}, {"index": "2", "address": "IPAB, University Edinburgh, United Kingdom"}], "title": "Representation of complex sounds in the mammalian inferior colliculus", "abstract": "Spectro-temporal neural properties along two different spatial axes within the inferior colliculus in response to complex sound are studied. Vocalizations, being natural stimuli and showing a variety of spectral and temporal modulations are particularly interesting and can elicit responses which are not triggered by artificial simplified sounds.\nWe study responses from guinea pigs to acoustically presented species-specific vocalizations. Multi-units were simultaneously recorded from 32 positions in the central nucleus of the inferior colliculus (ICC) of Dunkin Hartley guinea pigs using a double shank electrode. \nThe vocalizations differ in spectral content and envelope shape, ranging from low to broad spectral distributions and from a highly periodic to complex envelopes, and can be ordered accordingly.\nResponse preferences to features of the complex sounds depend largely on the characteristic frequency of the neural population, showing e.g. enhanced response for low frequency content and periodic envelopes at low characteristic frequencies. \nPooling responses from recording sites with fairly different response properties leads to improved discrimination compared to single site-based discrimination, and is not decreased when removing temporal correlations by shuffling across trials, which indicates independent encoding schemes.  \nOnly directly neighboring (100 \u03bcm) neural populations respond in a similar manner and have highly correlated PSTHs. This suggests that complex sounds are encoded efficiently across the tonotopic gradient and that the information from several best frequency laminae is taken into account for complex sound representation. \n", "acknowledgements": "This work was supported by the BMBF in the National Network for Computational Neuro-science, grant number #01GQ0811 to BFNT G\u00f6ttingen. We would like to thank Thilo Rode, Tanja Hartmann, and Hugh H. Lim for the guinea pig recordings and vocalizations.", "id": 131175, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Dominika Lyzwa"}, {"epithet": "2", "name": "Michael Herrmann"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["mathis@bio.lmu.de"], "doi": "10.12751/nncn.bc2013.0107", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience & Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Germany"}], "title": "Noise correlations of grid cells and the coding of space in medial entorhinal cortex", "abstract": "Grid cells in the entorhinal cortex (EC) exhibit hexagonal firing maps that represent the spatial environment of an animal [1,2]. Across cells, the grids have different length scales and spatial phases. The discharge of a single grid cell, however, is highly variable every time the rat crosses the same location. Together with the ambiguity introduced by the spatially periodic firing of grid cells, this neuronal variability raises the question of how precisely space can be represented by the population of grid cells. If the neurons were independent, a grid code with nested spatial scales would resolve space with exquisite precision, outperforming standard population codes [3,4].  Yet in sensorimotor areas of cortex, neurons display correlated response fluctuations,  which could be deleterious to coding [5], so we asked whether the grid cells in entorhinal cortex have such correlations.\n\nWe estimated the noise correlations for pairs of grid cells recorded from rats  shuttling back and forth on a linear track (experimental recordings from Hafting et al. 2008 [2]) and assessed the impact of such correlations on the spatial resolution of nested grid codes. When the spatial grids of two cells have the same scale and align in spatial phase, the noise correlations reach values of up to 0.8, which is, for instance, much higher than the noise correlations in neurons from visual cortex with the same orientation tuning [6]. As the relative phase difference between two grid cells increases, the noise correlations fall rapidly, as shown in the figure. Incorporating such correlations into a population coding model reveals that the correlations lessen the resolution, but the resolution still scales exponentially in the number of neurons [7]. Therefore, even in the presence of noise correlations,  the population activity in grid cells encodes position more precisely than the same number of place cells would.", "acknowledgements": "", "id": 131176, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Alexander Mathis"}, {"epithet": "1", "name": "Martin Stemmler"}, {"epithet": "1", "name": "Andreas Herz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Noise correlation vs. relative phase difference for of 87 pairs of grid cells. The relative phase is determined by computing the phase difference of two grid cells with similar spatial scale and dividing it by this scale. Gray dots indicate pairs from different tetrodes and gray crosses from the same tetrode, respectively. Black continuous line is a least-mean-square \ufb01t of the function a exp(- phase difference / b) with values a = 0.32 and b = 0.18. For more details on the methods, please consult [7].", "figpath": "107.jpeg", "refs": "[1] Hafting et al. Nature, 436(7052): 2005. doi: 10.1038/nature03721\n[2] Hafting et al. 2008, Nature, 305(5688):  2008. doi: 10.1038/nature06957\n[3] Mathis et al. Phys.Rev.Lett. 109, 018103: 2012. doi: 10.1103/PhysRevLett.109.018103 \n[4] Mathis et al. Neural Comput. 24(9): 2012. doi: 10.1162/NECO_a_00319\n[5] Averbeck et al. Nat. Rev. Neurosci. 7(5): 2006. doi: 10.1038/nrn1888\n[6] Ecker et al Science 327: 2010. doi: 10.1126/science.1179867\n[7] Mathis, et al. arXiv:1305.1573: 2013."}, {"correspondence": ["mathis@bio.lmu.de"], "figid": 108, "doi": "10.12751/nncn.bc2013.0108", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience & Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Germany"}], "title": "Optimal Coding for 3D Space: Grid Cells of Bats Should Spike on a Face Centered Cubic Lattice", "abstract": "'Grid cells' are neurons that are active when an animal is in any one of multiple\nlocations in its environment that correspond to the vertices of  a planar hexagonal\nlattice. These cells have been found in mice, rats, and (crawling) bats [1,2,3]. A number of\nauthors demonstrated that hexagonal lattices are optimal for representing the plane [4,5,6].\n\nWe study Fisher-optimal lattices for representing space in higher dimensions. We find \nthat the Fisher information of a population of neurons with tuning curves having compact \nsupport and periodified on any lattice L is related to the packing ratio of this lattice. \nThus, we conclude that for 3D the optimal lattice for representing space is the \nface centered cubic lattice. We will also discuss equally optimal, \nyet non-lattice packings.", "acknowledgements": "", "id": 131177, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Alexander Mathis"}, {"epithet": "1", "name": "Martin Stemmler"}, {"epithet": "1", "name": "Andreas Herz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Hafting et al. Nature, 436(7052), 2005. doi:10.1038/nature03721.\n[2] Fyhn et al. Hippocampus, 18(12), 2008. doi:10.1002/hipo.20472.\n[3] Yartsev et al. Nature, 479(7371), 2011. doi:10.1038/nature10583.\n[4] Guanella and Verschure, J. of Integrative Neuroscience, 6(3), 2007. doi:10.1142/S0219635207001556\n[5] Mathis, PhD thesis LMU, 2012. urn:nbn:de:bvb:19-150029\n[6] Wei et al.  arXiv preprint arXiv:1304.0031, 2013.\n\n"}, {"correspondence": ["nagele@bio.lmu.de"], "figid": 109, "doi": "10.12751/nncn.bc2013.0109", "affiliations": [{"index": "1", "address": "Division of Neurobiology, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen and Bernstein Center for Computational Neuroscience Munich, University, 82152 Martinsried, Germany"}], "title": "The variability of grid and place cell firing", "abstract": "Neuronal variability limits computation and coding, both at the circuit as well as the single cell level. This is particularly true when firing rates are low.  Grid cells in medial entorhinal cortex in rodents have elaborate spatial firing rate maps, but the average firing rates are typically less than 4.63Hz (2.03Hz \u00b11.29Hz (std)). By reanalyzing data from Sargolini et al (2006) [1], we model the variability of grid cell firing as an inhomogeneous Poisson process whose rate was given by the rodent's trajectory through the spatial firing map. For a Poisson process, the rates r_ij (= spikes on pass j / duration of pass j) in bin i should have a Fano factor (F_i=Var(r_ij)/mean(r_ij)) of unity. The majority (88.9%) of such Fano factors, however, are greater than unity. The average Fano factor for rates r_i on passes through bins of size 3cm x 3cm is 6.25 (std = 7.00, sem = 0.05). In hippocampus, the spatial firing maps of place cells are more spatially restricted, yet the discharge is even more variable [2,3,4]. For both types of cells, the hypothesis of an inhomogeneous Poisson process can be rejected. We consider the possible sources of excess variability and its implications for the spatial precision of population codes.", "acknowledgements": "", "id": 131178, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Johannes Nagele"}, {"epithet": "1", "name": "Alexander Mathis"}, {"epithet": "1", "name": "Martin Stemmler"}, {"epithet": "1", "name": "Andreas V.M. Herz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Sargolini et al., Science, 312.5774: 2006. doi: 10.1126/science.1125572\n[2] Fenton and Muller, PNAS, 95(6): 1998.\n[3] Jackson and Redish, Hippocampus, 17(12): 2007. doi: 10.1002/hipo.20359\n[4] Fenton et al., Journal of Neuroscience, 30(13): 2010. doi: 10.1523/JNEUROSCI.5576-09.2010\n"}, {"correspondence": ["michele.fiscella@bsse.ethz.ch"], "doi": "10.12751/nncn.bc2013.0110", "affiliations": [{"index": "1", "address": "ETH Zurich, Switzerland"}, {"index": "2", "address": "Friedrich Miescher Institute, Basel, Switzerland"}], "title": "Decoding the Activity of ON-OFF Direction Selective Retinal Ganglion Cells", "abstract": "ON-OFF Direction Selective Retinal Ganglion Cells (oo-DSGCs) encode the direction of a moving object (Barlow and Hill, 1963). oo-DSGCs respond strongly to motion along the \u201cpreferred direction\u201d and weakly to motion along the \u201cnull direction\u201d. Four types of oo-DSGCs were consistently found in different species (Oyster and Barlow, 1967; Weng et al., 2005) and their tuning curves are bell-shaped. In addition, oo-DSGCs preferred directions are distributed orthogonally and are aligned to the eye muscles. The axons of oo-DSGCs project to the lateral geniculate nucleus and their activity is likely to be combined to decode the direction of a moving object (Kay et al., 2011; Marshel et al., 2012).\nIn order to understand how oo-DSGCs combined activity could be used by the brain for decoding the direction of a moving object, we used a high-density microelectrode array (HDMEA) to record simultaneously the activity of all the four types of oo-DSGCs (Fiscella et al., 2012). We decoded the direction of movement using a Bayesian decoder based on the oo-DSGCs tuning curves.\nWe found that orthogonal combinations of oo-DSGCs decode significantly better the direction of a moving object compared to single oo-DSGCs or combinations of oo-DSGCs with the same preferred directions. Furthermore, decoding performance seems to be invariant to motion speed. Finally, we found that orthogonal combinations of oo-DSGCs decode the direction of a moving object with highest precision ~ 45 degrees away from their preferred directions, i.e., where their tuning curves overlap.\n", "acknowledgements": "This work was supported by the European Community through the ERC Advanced Grant 267351 \u201cNeuroCMOS\u201d. Michele Fiscella acknowledges individual support through a Swiss SystemsX interdisciplinary PhD grant No. 2009_031.", "id": 131179, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Michele Fiscella"}, {"epithet": "1", "name": "Felix Franke"}, {"epithet": "2", "name": "Karl Farrow"}, {"epithet": "1", "name": "Ian L. Jones"}, {"epithet": "1", "name": "Jan M\u00fcller"}, {"epithet": "2", "name": "Botond Roska"}, {"epithet": "1", "name": "Andreas Hierlemann"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "(a)    Rabbit retinal ganglion cell extracellular action potential landscape.\n(b)    Top, oo-DSGCs tuning curves; Bottom, oo-DSGCs preferred directions.\n(c)    Decoding performance of orthogonal combinations of oo-DSGCs. RMS (root mean square).\n", "figpath": "110.jpeg", "refs": "Barlow HB, Hill RM (1963). Science 139:412-414.\nFiscella M, Farrow K, Jones IL, Jackel D, Muller J, Frey U, Bakkum DJ, Hantz P, Roska B, Hierlemann A (2012). J Neurosci Methods 211:103-113.\nKay JN, De la Huerta I, Kim IJ, Zhang Y, Yamagata M, Chu MW, Meister M, Sanes JR (2011). J Neurosci 31:7753-7762.\nMarshel JH, Kaye AP, Nauhaus I, Callaway EM (2012). Neuron 76:713-720.\nOyster CW, Barlow HB (1967). Science 155:841-842.\nWeng S, Sun W, He S (2005). J Physiol 562:915-923."}, {"correspondence": ["phoevel@physik.tu-berlin.de"], "figid": 111, "doi": "10.12751/nncn.bc2013.0111", "affiliations": [{"index": "1", "address": "BCCN Berlin, TU Berlin, Germany"}], "title": "Modelling functional network of the human cortex from fMRI data", "abstract": "Complex, but highly structured, dynamic phenomena have been reported in resting brain activity revealing so called resting-state functional networks. However, the question, how these well-organised patterns of activity emerge from intrinsic brain dynamics, remains essentially unexplored. Here, we use large-scale neural model as a tool to explore a non-trivial question of correlated behaviour of distant cortical regions i.e. functional connections in resting-state brain dynamics. We choose to model neural network dynamics by biophysically realistic FitzHugh-Nagumo neurons, subject to uncorrelated white Gaussian noise and time-delayed interactions. We then use resulting time-series of the neural activity to infer low-frequency (< 0.1 Hz) fluctuations in fMRI data. We investigate how correlated behaviour of distant regions emerges from different topologies of empirically derived resting-state networks [1]. We discuss optimal values of the correlation threshold and the coupling strength for which the simulated networks have graph-theoretical measures very similar to those of experimentally derived networks.", "acknowledgements": "This work was supported by BMBF (grant no. 01Q1001B) in the framework of BCCN Berlin (Project B7).", "id": 131180, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Vesna Vuksanovi\u0107"}, {"epithet": "1", "name": "Philipp H\u00f6vel"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] V. Vuksanovi\u0107 and P H\u00f6vel, Large-scale neural network model for functional networks of the human cortex, International Symposium Self-Organization in Complex Systems: The Past, Present, and Future of Synergetics, Springer, (2013), available as: http://arxiv.org/abs/1302.3651.\n"}, {"correspondence": ["simonsunimail@gmail.com"], "figid": 112, "doi": "10.12751/nncn.bc2013.0112", "affiliations": [{"index": "1", "address": "Neuroelectronic Systems, University Medical Centre, Freiburg, Germany"}], "title": "Biasing robust STDP in noisy environments", "abstract": "When trying to shape the outcome of spike timing dependent plasticity (STDP) towards some reinforcement signal, the common path of action is to add a third factor to the standard two-factor STDP rule that scales the projective weight change by the supposed amount of reinforcement. Although this describes the lasting influence of neuromodulators on synaptic weight change that has been shown in experiments, another common experimental observation that is not captured through three-factor STDP rules is the instant effect that some neuromodulators seem to have on postsynaptic responses to given presynaptic inputs. \nIn order to answer the question whether this observed instant change in gain or signal to noise ratio may be able to also explain final learning outcomes though some indirect effect, we looked at the specific differences between STDP and traditional rate-based Hebbian methods, and examined standard STDP's strengths and weaknesses under a range of structured, informative and constant-expected-rate inputs. We present repeated spike wave fronts within high-noise background spike activity that are shifted according to some encoded continuous range of values, and show how a typical negative-integral STDP rule is then able to reliably form sparse receptive fields that are robust to long periods of non-structured, information-less stochastic input spiking. For equiprobable pattern occurrences and diverse learning onset times, this leads to a uniformly distributed receptive map without the need for mutual inhibition. The developing map can be biased towards or against responding to specific value subranges by controlling postsynaptic response reliability, e.g. through neuromodulator-dependent changes in noise levels during dendritic or synaptic signal transmission.", "acknowledgements": "", "id": 131181, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Simon M. Vogt"}, {"epithet": "1", "name": "Ulrich G. Hofmann"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Vogt, S.M., Hofmann, U.G. (2012).  doi: 10.1007/s11571-012-9202-4 \nThurley, K., Senn, W., L\u00fcscher, H.-R. (2008).  doi:10.1152/jn.01098.2007 \nKroener S, Chandler LJ, Phillips PEM, Seamans JK (2009).  doi: 10.1371/journal.pone.0006507\nMorrison, A., Diesmann, M., Gerstner, W. (2008).  doi:10.1007/s00422-008-0233-1\nShen, W., Flajolet, M., Greengard, P., Surmeier, D. J. (2008).  doi:10.1126/science.1160575\nMasquelier, T., Guyonneau, R., Thorpe, S. J. (2008).  doi:10.1371/journal.pone.0001377 "}, {"correspondence": ["pedroernesto.garcia@gmail.com"], "doi": "10.12751/nncn.bc2013.0113", "affiliations": [{"index": "1", "address": "NRIA CR Nancy - Grand Est, France"}], "title": "Slow oscillations of  'up' and 'down' states during general anesthesia: bi-stability in a non-linear model", "abstract": "The presence of sequences of alternating quiescent ('down') and bursting ('up') states in NREM sleep neuronal recordings is well established across mammalian species [1]. A striking related pattern of activity can also be observed in LFP and EEG recordings of anesthetized animals [2]. However, the dynamical principles underlying such phenomenon are unclear. Some of the previous theoretical attempts to understand the neural basis of anesthesia effects have shown to be successful in replicating other remarkable characteristics of the associated EEG signals, e.g., the initial increase of the power spectrum and its subsequent decrease (in several frequency bands) during the process of the anesthesia induction [3-4]. Interestingly, such models predict the existence of notable non-linearities in the behavior of the neuronal membrane potential, with more than two stable branches through which the dynamics may evolve as the concentration of the anesthetic agent (AA) increases. Noise-induced transitions between two attractors might then occur, a theoretical framework that could explain the observed alternating sequences of 'up' and 'down' states. An example of this scenario is shown in Fig. 1, where 'p' stands for the AA level, and the oblique line is the separatrix between the two basins of attraction. Nevertheless, the mathematical tractability of these non-linear scenarios is limited by the 2D phase space defined by the describing variables: the excitatory (Ve) and inhibitory (Vi) PSPs at excitatory cells. Exact solutions to these problems are only known for 1D systems and, consequently, the analysis of the existing non-linear models is typically avoided. In this work we undertake a first attempt to solve this task, by applying known techniques on stochastic phenomena theory [5] to the model proposed in [4]. We consider the time the system spends in the 'up' or 'down' states as being similar to the mean exit-time needed to escape from the corresponding attractor.", "acknowledgements": "", "id": 131182, "topic": "Neural encoding and decoding", "figid": 113, "authors": [{"epithet": "1", "name": "Pedro Garcia Rodriguez"}, {"epithet": "1", "name": "Axel Hutt"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Destexhe A. et al., Trends in Neurosciences 30: 334-342, 2007.\n[2] Hutt A. (ed.), Sleep and anesthesia: neural correlates in theory and experiment, Springer-Verlag, 2011.\n[3] Steyn-Ross M. et al., Physical Review E 60(6): 7299-7311, 1999.\n[4] Hutt A. and Longtin A., Cognitive Neurodynamics 4(1): 37-59, 2009.\n[5] Gardiner C.W., Handbook of Stochastic Methods (3rd edition), Springer-Verlag, 2004."}, {"correspondence": ["ziad.m.hafed@cin.uni-tuebingen.de"], "doi": "10.12751/nncn.bc2013.0114", "affiliations": [{"index": "1", "address": "CIN, Germany"}], "title": "On the dissociation between time and space in microsaccade generation: \u2018microsaccadic inhibition\u2019 revisited", "abstract": "Microsaccades play important roles in perceptual and oculomotor performance. Given that gaze fixation is used almost-universally in neuroscience experiments, understanding the conditions under which microsaccades are more likely to occur or not, and in which direction, is essential for neuroscience research. Here we used a combined modeling/experimental approach to investigate a ubiquitous, yet paradoxical, microsaccade phenomenon. On the one hand, after peripheral stimulus onset, microsaccade rate drops within <100 ms (\u2018microsaccadic inhibition\u2019) and then rises again (\u2018microsaccadic rebound\u2019). On the other, microsaccade direction is modulated, but with a different time course, such that movements with extremely short latencies (and during the \u2018inhibition\u2019 phase) are surprisingly the most highly correlated with the stimulus. We show that these apparently dichotomous observations can simply result from a single mechanism that \u2018resets\u2019 the phase of ongoing microsaccadic oscillatory rhythms. In this framework, stimulus onsets act as \u2018countermanding\u2019 stimuli exactly like in large \u2018saccadic countermanding\u2019: they cancel an upcoming movement and start a competing one, thus implementing \u2018phase resetting\u2019. Moreover, the \u2018rare\u2019 microsaccades during \u2018microsaccadic inhibition\u2019 are simply \u2018non-canceled escapes\u2019, and they reflect the instantaneous state of visual representations expected in visuo-spatial maps. Remarkably, a dynamic interaction between the efficacy of the \u2018countermanding\u2019 process and the metrics of the microsaccade being \u2018countermanded\u2019 not only explains microsaccade rate changes, but it also predicts the time courses of microsaccade directions and amplitudes. Our parsimonious framework for understanding microsaccadic modulations after stimulus onsets allows analyzing microsaccades (and larger saccades) using the extensive toolkit of oscillatory dynamical systems often used for modeling spiking neurons, and it constrains neural models of microsaccade triggering.", "acknowledgements": "This work was funded by a grant from the Werner Reichardt Centre for Integrative Neuroscience (CIN) at the Eberhard Karls University of T\u00fcbingen. The CIN is an Excellence Cluster funded by the Deutsche Forschungsgemeinschaft (DFG) within the framework of the Excellence Initiative (EXC 307).", "id": 131183, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Ziad Hafed"}, {"epithet": "1", "name": "Alla Ignashchenkova"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Dissociation between time and space in microsaccade generation. (A) Microsaccade frequency histogram from one monkey fixating while a peripheral stimulus appeared. Microsaccade rate dropped sharply soon after stimulus onset (\u2018microsaccadic inhibition\u2019) and then rebounded (\u2018microsaccadic rebound\u2019) before returning to baseline. (B) Time course of microsaccade directions in the same trials (black curve). Shortly after stimulus onset, microsaccades were strongly biased in the direction of the stimulus (top arrow), and this bias happened when microsaccades were near maximal inhibition (compare to the gray curve, which replicates A for easy comparison between the two time courses). Later, microsaccades were biased opposite the stimulus (lower arrow). Note that the time course of direction was dissociated from the time course of rate (compare black and gray curves). (C) Normalized angular histograms of microsaccade direction relative to stimulus location. During a 50-ms window before stimulus onset, microsaccade directions were uniformly distributed (gray curve). However, immediately after the onset, microsaccades were strongly biased toward the stimulus location (black curve). Note that the latencies of these strongly biased movements are much shorter than normal saccade latencies. Our model replicates these apparently dichotomous observations, with a single \u2018phase resetting\u2019 framework.", "figpath": "114.jpeg", "refs": ""}, {"correspondence": ["dane.corneil@epfl.ch"], "figid": 115, "doi": "10.12751/nncn.bc2013.0115", "affiliations": [{"index": "1", "address": "Ecole Polytechnique Federale de Lausanne, Switzerland"}, {"index": "2", "address": "University of Zurich and ETH Zurich, Switzerland"}, {"index": "3", "address": "University of California San Diego, United States"}], "title": "Learning Nondeterministic Temporal Patterns in Stochastic Winner\u2013Take\u2013All Networks", "abstract": "To make sense of noisy, incomplete sensory data, the brain must be able to learn and model latent temporal patterns. This ability is necessary to predict future events and explain ambiguous observations by integrating past evidence.\n\nHere, we describe how temporal patterns can be learned by stochastic spiking neural populations and recalled during real\u2013time inference. This model is based on the existing Spike\u2013based Expectation Maximization (SEM) framework [1], in which a population of spiking neurons with shared lateral inhibition can learn the hidden causes of input data using a Spike-Timing-Dependent Plasticity (STDP) learning rule. Each neuron learns to represent a different hidden cause, and fires stochastically with a rate proportional to its current posterior probability. The log conditional probabilities of the input variables are encoded in feedforward synapse weights. An extension to the SEM framework has been suggested to represent Hidden Markov Models [2].\n\nHere, we present a model where state transition probabilities are represented using recurrent connections. We show that the feedforward and recurrent connection weights can be learned simultaneously, and that the recurrent connection weights can converge to the log transition probabilities of a Markov model using a novel STDP learning rule. The resulting Winner\u2013Take\u2013All behavior mimics a single-sample particle filter. \n\nThe model is demonstrated on a nondeterministic spatiotemporal pattern. After training, the network spontaneously generates examples of the training pattern. Using multiple populations, this generative behavior can be used to maintain a probability distribution over the hidden state after the sensory input is removed.\n\nThese results illustrate that probabilistic temporal dynamics in spike train data can be learned online by stochastic Winner\u2013Take\u2013All networks using STDP. As such, they represent a step towards a biologically plausible model of spatio\u2013temporal learning and inference.", "acknowledgements": "", "id": 131184, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Dane Corneil"}, {"epithet": "2", "name": "Michael Pfeiffer"}, {"epithet": "3", "name": "Emre Neftci"}, {"epithet": "2", "name": "Giacomo Indiveri"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] B. Nessler, M. Pfeiffer, L. Buesing, and W. Maass. Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity. PLoS Comp. Biol., 9(4):e1003037, 2013. doi: http://dx.doi.org/10.1371/journal.pcbi.1003037\n\n[2] D. Kappel, B. Nessler, and W. Maass. Emergence of Hidden Markov Models through STDP in networks of spiking neurons. In International Conference on Brain Dynamics and Decision Making, Ascona, 2012."}, {"correspondence": ["lorenz.k.mueller@gmail.com"], "figid": 116, "doi": "10.12751/nncn.bc2013.0116", "affiliations": [{"index": "1", "address": "Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland"}], "title": "Recurrent networks of coupled Winner-Take-All oscillators for solving constraint satisfaction problems", "abstract": "The brain is able to integrate noisy and partial information from both sensory inputs and internal states to construct a consistent interpretation of the actual state of the environment. Consistency among different interpretations of unreliable sensory data is likely to be inferred according to an internal model constructed from prior experience [1]. One possible formulation of such an internal model is as a set of constraints between variables that represent the state of the environment. We present a recurrent neuronal network, modelled as a continuous-time dynamical system, that can solve such constraint satisfaction problems. Discrete variables are represented by coupled Winner-Take-All networks, and their values are encoded in localized patterns of oscillations that are learned by the recurrent weights in these networks.  Constraints over the variables are encoded in the network connectivity.  Although there are no sources of noise, the network can escape from local optima in its search for solutions that satisfy all constraints. If there are no such solutions, the network state changes in a pseudo-random manner and its trajectory approximates a sampling procedure that selects a variable assignment with a probability proportional to the fraction of constraints satisfied by this assignment.  External evidence, or input to the network, can force variables to specific values. When new inputs are applied, the network re-evaluates the entire set of variables in its search for the states that satisfy the maximum number of constraints, while being consistent with the external input. The proposed network architecture can perform a deterministic search for the optimal solution to problems with non-convex cost functions. The network is inspired by canonical microcircuit models of the cortex [2] and suggests possible dynamical mechanisms to solve constraint satisfaction problems that can be implemented in both real neural circuits, and neuromorphic electronic circuits.", "acknowledgements": "This work was supported by the European Community\u2019s Seventh Framework Programme ERC grant # 257219 \u2013 \u201cneuroP\u201d and by the European CHIST-ERA program, via the \u201cPlasticity in NEUral Memristive Architectures\u201d (PNEUMA) project.", "id": 131185, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Lorenz K. M\u00fcller"}, {"epithet": "1", "name": "Hesham Mostafa"}, {"epithet": "1", "name": "Giacomo Indiveri"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1]: Spontaneous cortical activity reveals hallmarks of an optimal internal model of the environment; P. Berkes, G. Orban, M. Lengyel and J. Fiser; Science; 2011;  DOI: 10.1126/science.1195870 \n\n[2]: Neuronal circuits of the neocortex; R.J. Douglas and K.A. Martin; Annual review of neuroscience; 2004; DOI: 10.1146/annurev.neuro.27.070203.144152"}, {"correspondence": ["jorchard@uwaterloo.ca"], "doi": "10.12751/nncn.bc2013.0117", "affiliations": [{"index": "1", "address": "University of Waterloo, Canada"}], "title": "Path Integration using the Fourier Transform", "abstract": "Recent hypotheses have pointed to oscillator interference as a mechanism to explain path integration in the entorhinal cortex [1-4]. Velocity-controlled oscillators (VCOs) [5] are neural oscillators that change their frequencies with the animal\u2019s speed and direction of movement. These frequency changes induce phase differences between oscillators. In this way, the animal\u2019s location is encoded by the phase differences between VCOs.\n   Combining different VCOs into a read-out node generates spatially-fixed interference patterns - spatial activation maps. For example, combining three VCO with preferred directions separated by 120\u00b0 generates a grid cell [6]. Welday et al also illustrated rudimentary place cells and border cells by combining VCOs [5].\n   Can we use VCOs to generate arbitrary spatial maps? Yes, and Fourier theory tells us how. Since VCOs generate Fourier basis functions (sines, cosines), combining them into a read-out node essentially performs an inverse Fourier transform. As such, the connection weights from the VCOs to the read-out nodes reflect the Fourier coefficients of the resulting spatial map.\n   Our model splits the generation of spatial activation maps into two components: (1) the animal\u2019s location in its environment is represented by the VCO phases, and (2) the layout of a spatial map is implemented by the connection weights from the VCOs to the read-out node (see figure). All read-out nodes draw from the same bank of VCOs, so generate different spatial maps that are all in spatial register.\n   We implemented a version of this model using spiking neurons (leaky integrate-and-fire). Neural coding (including dynamic oscillators) was done using the Neural Engineering Framework [7]. Phase-coupling mechanisms were included to prevent inconsistent phase drift. Results from random-walk simulations exhibit grid cells that fire bursts of spikes in a hexagonal grid pattern, as well as theta-phase precession.", "acknowledgements": "The authors thank the Natural Science and Engineering Research Council of Canada (NSERC) for financial support.", "id": 131186, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Jeff Orchard"}, {"epithet": "1", "name": "Hao Yang"}, {"epithet": "1", "name": "Xiang Ji"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "The VCOs encode the animal's location in their phases. The connection weights to the read-out node multiply by the Fourier coefficients that produce the resulting spatial activation map.", "figpath": "117.png", "refs": "1) Blair, Gupta, Zhang, Hippocampus, 18:1239\u201355, 2008.\n2) Burgess, Barry, O'Keefe, Hippocampus, 17:801\u201312, 2007.\n3) McNaughton, Battaglia, Jensen, Moser, Moser, Nat Rev Neurosci, 7:663\u201378, 2006.\n4) Solstad, Moser, Einevoll, Hippocampus, 16:1026\u201331, 2006.\n5) Welday, Shlifer, Bloom, Zhang, Blair, J. Neuroscience, 31:16157\u201376, 2011.\n6) Hafting, Fyhn, Molden, Moser, Moser, Nature, 436:801\u20136, 2005.\n7) Eliasmith, Anderson, Neural engineering, MIT Press, 2003."}, {"correspondence": ["Felix.Effenberger@mis.mpg.de"], "doi": "10.12751/nncn.bc2013.0118", "affiliations": [{"index": "1", "address": "Max-Planck-Institute for Mathematics in the Sciences, Germany"}, {"index": "2", "address": "Bernstein Center for Computational Neuroscience G\u00f6ttingen, Germany"}], "title": "Self-organization in balanced state random networks by STDP and homeostatic plasticity", "abstract": "It is widely believed that the topological structure of cortical networks is inhomogeneous and that inhomogeneities play an important role in their dynamics. However, little is known about how such structures could evolve and how synaptic plasticity influences this evolution [3].\n\nTo assess a possible influence of synaptic plasticity rules on the topology of synaptic connections we consider random networks of LIF neurons in the asynchronous irregular regime of activity\u00a0[1] that is believed to be a good theoretical fit to the activity of a cortical network in vivo. We then introduce excitatory and inhibitory spike-timinig-dependent plasticity (STDP) [4] rules in combination with synaptic scaling and find that in this setting interesting and stable self-organization phenomena can be observed.\n\nAfter a transient phase, both the weight distributions and the firing rate distributions are heavy-tailed and close to log-normal (see Fig. A,B), a property also found in cortical networks and that was previously studied in rate-based models [2]. Furthermore, the plasticity rules allow a fraction of the excitatory cells to become \"driver neurons\" that form strong excitatory synapses to their postsynaptic targets, see Fig. C. The spiking activity of driver neurons can thus propagate to the network level, see Fig. D, where apart from the driver neurons the network receives no input. To get an insight into the possible function of driver neurons we study spike-triggered averages. We found that a correlated firing of several driver neurons has strong influence on the dynamics of the network over a period of the following 20\u00a0ms, see Fig. E.  Furthermore, driver neurons tend to fire in a more coincident way than groups of other cells in the network (data not shown). This is due to subnetworks of driver neurons emerging in which all synapses are strong (data not shown).", "acknowledgements": "The second author acknowledges support by the Federal Ministry of Education and Research (BMBF) Germany under grant number 01GQ1005B.", "id": 131187, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Felix Effenberger"}, {"epithet": "2", "name": "Anna Levina"}, {"epithet": "1", "name": "J\u00fcrgen Jost"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "A,B: Long-tailed distributions of synaptic efficacies and firing rates. C: scatter plot of the mean vs the variance of synaptic efficacies vs the rate for excitatory cells; driver cells havong high mean and low variance are marked with a triangle. Animated version: http://www.youtube.com/watch?v=Y876I9Rk4vI D: Raster plot of network activity subject to constant current stimulation of 16 driver cells for a duration of 50ms with subsequently 10, 20, 30, 40, 50mV. E: Spike-triggered average of coincident firing of driver cells, t=0 denoting the time of firing of one or more driver cells is a 5ms bin.", "figpath": "118.png", "refs": "1 Brunel N:Dyn of sparsely conn networks of exc and inhib spiking neurons.J Comput Neurosci 2000,8:183\u2013208\n2 Koulakov AA,Hromadka T,Zador AM:Correlated Connectivity and the Distrib of Firing Rates in the Neocortex.J Neurosci 2009,29(12):3685\u20133694\n3 Kunkel S,Diesmann M,Morrison A:Limits to the Devel of Feed-Forward Struct in Large Rec Neur Net.Front Comput Neurosci 2010,4:160\n4 Vogels TP et al:Inhib plasticity balances exc and inhib in sensory pathways and mem networks.Science 2011,334:1569\u201373."}, {"correspondence": ["r.memmesheimer@science.ru.nl"], "figid": 119, "doi": "10.12751/nncn.bc2013.0119", "affiliations": [{"index": "1", "address": "Department of Biophysics, Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, Netherlands"}, {"index": "2", "address": "Department of Neuroinformatics, Donders Institute for Brain, Cognition and Behaviour, Radboud University Nijmegen, Netherlands"}], "title": "Recurrent neural network learning as a control problem", "abstract": "In both control and learning of a dynamical system, such as a neural network, the goal is the same, namely to make the system generate some desired dynamics. However, there is a fundamental difference: in a controlled system the control signal is always necessary during performance of the task; in a system that learns, learning is no longer required once it has succeeded. Powerful control methods, such as path integral control, have been designed to deal with complex high dimensional dynamics which suggests to investigate their application to the learning of complicated tasks. To bridge the gap between control and learning we do not control the system parameters directly; we control their changes. As a result, optimizing the control such that it vanishes for sufficiently large times implies that the system parameters converge to stationary (but non-vanishing) values. The system generates the desired dynamics beyond some point in time without any further control. In other words, the system has learned the desired dynamics. We apply this approach to the well-known, difficult problem of learning recurrent, continuous time neural networks. The recurrent network connections are learned by path integral control, such that a readout neuron generates a predefined, desired signal. In the case that the dynamics are stochastic, we demonstrate that the path integral control approach can outperform the recently proposed FORCE method.", "acknowledgements": "", "id": 131188, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Martin Mittag"}, {"epithet": "2", "name": "Raoul-Martin Memmesheimer"}, {"epithet": "1", "name": "Hilbert J. Kappen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["fbauer@fias.uni-frankfurt.de"], "figid": 120, "doi": "10.12751/nncn.bc2013.0120", "affiliations": [{"index": "1", "address": "Frankfurt Institute for Advanced Studies and Faculty of Computer Science and Mathematics, Johann Wolfgang Goethe University, Frankfurt am Main, Germany"}], "title": "Processing textures in a smooth visual map and a salt-and-pepper organization", "abstract": "The functional architecture of the visual cortex displays marked differences across mammalian species: in stark contrast to primates and carnivores, in which the preferred stimulus orientation forms an almost smooth map across the cortical surface, in rodents a \u2018salt-and-pepper\u2019 organization has been observed. At present, it is unclear if these differences in the layout of preferred orientations entail any difference in the processing of visual input. In this work, we study in simple model of the visual cortex the role of map layout in distinguishing different textures in images. Our model is based on biologically inspired object recognition systems [1]. The computations in the model involve as key steps steps (i) multiplying the input images with a set of Gabor filters of varying frequency and orientation, (ii) applying a nonlinearity operation to the filter responses, and (iii) pooling the output of the nonlinearity. We studied two different filter architectures with an identical number of neurons (filters): one was consistent with an orientation-preference map as observed in e.g. primates, the other with a salt-and-pepper organization as observed in rodents. We fed the output of our model into a classifier (linear SVM) that learns to predict a class label. Images were taken from the database of [2] and consisted of grayscale textures from 25 classes, each one containing 40 sample images. We cross-validated over 5 realizations of maps, 7 frequencies and 5 splits of the data into 30 training and 10 test samples. We found that smooth orientation maps yielded a consistently better classification accuracy compared to random layouts. We confirmed these results using three further datasets and varying the complexity of the recognition task. These results suggest that differences in the layout of preferred orientations in the visual cortex could reflect differences in processing visual input.", "acknowledgements": "Bernstein Focus Neurotechnology Frankfurt: BFNT 01GQ0840", "id": 131189, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Felix Bauer"}, {"epithet": "1", "name": "Matthias Kaschube"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Pinto N, Cox DD, DiCarlo JJ. Why is real-world visual object recognition hard? PLoS Computational Biology. 4:e27, 2008.\n[2] Lazebnik S, Schmid C, and Ponce J. A Sparse Texture Representation Using Local Affine Regions. IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 27, no. 8, pp. 1265-1278, 2005."}, {"correspondence": ["tsigankov@fias.uni-frankfurt.de"], "figid": 121, "doi": "10.12751/nncn.bc2013.0121", "affiliations": [{"index": "1", "address": "Frankfurt Institute for Advanced Studies, Germany"}], "title": "Two distinct mechanisms for emergence of direction selectivity coexist in generic random recurrent neural networks.", "abstract": "In the mammalian visual cortex the time-averaged response of many neurons is maximal for stimuli moving in a particular direction. Such a direction selective response is not found in LGN, upstream of the visual processing pathway, suggesting that cortical networks play a strong role in the generation of direction selectivity. Here we investigate the mechanisms for the emergence of direction selectivity in the recurrent networks of nonlinear firing rate neurons in layer 4 of V1 receiving the input from LGN. We propose that two distinct mechanisms result in the neuronal direction selective response in these recurrent networks. The first one is a result of nonlinear feed-forward summation of several time-shifted inputs. The second mechanism is based on the competition between neurons for firing in a winner-take-all regime. Both mechanisms rely on inhibitory interactions in the connectivity matrix of lateral connections, but the second one involves inhibitory loops. Typically, the first mechanism results in lower selectivity values than the second, but the time-course of acquiring direction selective response is faster for the first mechanism. The first mechanism results in a relatively narrow tuning curve around the preferred frequency of the moving grating. In contrast the direction selectivity arising from the second mechanism has a broader tuning curve. These differences allow us to provide the recipe for identifying in experiment which of the two mechanisms is used by a given direction selective neuron. We then analyze how the statistics of the connections in the random recurrent networks affect the relative contributions from these two mechanisms and determine the distributions of the direction selectivity values. Our results may account for the recent observations that direction selectivity is present in dark-reared mice and ferrets[1,2]. It can also explain the emergence of direction selectivity in species lacking a spatially organized direction selectivity map.", "acknowledgements": "This work was supported by the German Federal Ministry of Education and Research (BFNT 01GQ0840).\n", "id": 131190, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Dmitry Tsigankov"}, {"epithet": "1", "name": "Matthias Kaschube"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Van Hooser SD, Li Y, Christensson M, Smith GB, White LE, Fitzpatrick D. \nJ Neurosci. 2012 May 23;32(21):7258-66. doi: 10.1523/JNEUROSCI.0230-12.2012.\n[2] Rochefort NL, Narushima M, Grienberger C, Marandi N, Hill DN, Konnerth A. \nNeuron. 2011 Aug 11;71(3):425-32. doi: 10.1016/j.neuron.2011.06.013."}, {"correspondence": ["steffen.katzner@uni-tuebingen.de"], "figid": 122, "doi": "10.12751/nncn.bc2013.0122", "affiliations": [{"index": "1", "address": "Centre for Integrative Neuroscience, University of Tuebingen, Germany"}], "title": "All-or-none learning of orientation discrimination in mice", "abstract": "In basic learning paradigms the rate of acquisition is typically captured by gradually increasing learning curves. Recent work, however, proposes that such gradual increases artificially arise from averaging across subjects, who individually show a step-like increase from a naive to a well-trained level of performance, albeit at different latencies (Gallistel et al., 2004). \n\nHere, we focused on visual sensory processing in the mouse and asked whether orientation discrimination would also be acquired in a step-like fashion.\n\nIn head-fixed mice, we used a classical conditioning paradigm, in which the presentation of one of two orthogonal grating orientations was immediately followed by a fluid reward. We measured licks occurring before reward delivery, and assessed learning progress by contrasting lick rates during grating presentations to baseline lick rates before grating onset, separately for each orientation.\n\nOver the course of few hundred trials, the cumulative record of differences in lick rates showed three markedly distinct periods. First, lick rates were unaffected by the presentation of either orientation with their cumulative records fluctuating around zero. Second, an unspecific conditioned response appeared abruptly with lick rates during either grating orientation higher than baseline, such that both cumulative records started rising with similar changes in slope. Finally, the conditioned response became specific for the rewarded orientation, such that their cumulative differences diverged.\n\nOur findings indicate that orientation discrimination learning in the mouse is characterized by step-like changes in behavior. We aim to study how such rapid forms of learning affect the robustness of sensory representations in mouse visual cortex, where genetic tools can be used to target underlying neural mechanisms.\n\n", "acknowledgements": "This work is supported by a Starting Independent Researcher Grant from the European Research Council (project acronym: PERCEPT) awarded to SK, and by funds awarded to the Centre for Integrative Neuroscience (DFG Exec 307).", "id": 131191, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Ovidiu Jurjut"}, {"epithet": "1", "name": "Laura Busse"}, {"epithet": "1", "name": "Steffen Katzner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Gallistel, C. R., Fairhurst, S., and Balsam, P. (2004). The learning curve: implications of a quantitative analysis. Proc Natl Acad Sci USA, 101(36):13124\u201331."}, {"correspondence": ["manuel@nld.ds.mpg.de"], "figid": 123, "doi": "10.12751/nncn.bc2013.0123", "affiliations": [{"index": "1", "address": "MPI for Dynamics and Self-Organization, Germany"}], "title": "Inferring retinal ganglion cell mosaics from realistic orientation preference maps in cat V1", "abstract": "It has been argued that the emergence of roughly periodic orientation preference maps (OPMs) in the primary visual cortex (V1) of carnivores and primates can be explained by a so-called statistical connectivity model. In this model input to V1 neurons is dominated by a small set of feed-forward projections from retinal ganglion cells (RGC). The typical spacing between adjacent cortical orientation columns preferring the same orientation arises via Moire-Interference between hexagonal ON/OFF RGC mosaics and critically depends on long-range hexagonal order within these mosaics [1]. However, a recent statistical analysis [2] of RGC receptive field positions found no evidence for such long-range positional order, leaving open whether and how the statistical connectivity framework can explain the formation of roughly periodic cortical OPMs. Here we introduce a method to infer model RGCs mosaics that within the statistical connectivity framework yield experimentally measured OPMs from cat V1. Inferred mosaics exhibit realistic nearest neighbor distributions and lack long-range positional order, yet lead to aperiodic OPMs. In contrast to previously considered model RGCs, they exhibit specific angular correlations between ON/OFF ganglion cell pairs that match the spatial correlation of orientation preferences found in cortical OPMs. By analyzing published beta cell mosaics from cat retina, we find that such angular correlations are virtually absent in the data. Therefore, the positioning of ON/OFF ganglion cell pairs appears to lack the necessary spatial structure to yield the aperiodic OPMs found in experiment. Our results indicate that the typical spacing between adjacent orientation columns preferring the same orientation is likely to originate from cortical mechanisms and not set by the structure of RGC mosaics.", "acknowledgements": "We are grateful to Z. Kisvarday (University of Debrecen, Debrecen, Hungary) for sharing optical imaging data and to Stephen J. Eglen Cambridge University, Cambridge, UK) for providing us with the analysis of spatial statistics of mosaics.", "id": 131192, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Manuel Schottdorf"}, {"epithet": "1", "name": "Fred Wolf"}, {"epithet": "1", "name": "Wolfgang Keil"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] S.-B. Paik and D. L. Ringach. \u201cRetinal Origin of Orientation Maps in Visual Cortex.\u201d Nature Neuroscience 14(7): 919\u2013925. (2011) doi:10.1038/nn.2824.\n\n[2] V. Hore, J. B. Troy and S. J. Eglen. \u201cParasol Cell Mosaics Are Unlikely to Drive the Formation of Structured Orientation Maps in Primary Visual Cortex.\u201d Visual Neuroscience 29(6): 283\u2013299. (2012) doi:10.1017/S0952523812000338.\n"}, {"correspondence": ["hamed.bahmani@tuebingen.mpg.de"], "figid": 124, "doi": "10.12751/nncn.bc2013.0124", "affiliations": [{"index": "1", "address": "Max Planck Institute for Biological Cybernetics, T\u00fcbingen, Germany"}, {"index": "2", "address": "Bernstein Center for Computational Neuroscience, T\u00fcbingen, Germany"}, {"index": "3", "address": "Division of Imaging Science and Biomedical Engineering, University of Manchester, Germany"}], "title": "Effects of binocular flash suppression in awake and anesthetized macaque", "abstract": "The primary visual cortex (V1) was implicated as an important candidate for the site of perceptual suppression in numerous psychophysical and imaging studies (Lehky, 1988; Blake, 1989; Polonsky et al., 2000; Tong and Engel, 2001). However, neurophysiological results in awake monkeys provided evidence for competition mainly between neurons in areas beyond V1 (Leopold and Logothetis, 1996; Sheinberg and Logothetis, 1997). In particular, only a moderate percentage of neurons in V1 was modulated in parallel with perception and the magnitude of their modulation was substantially smaller than the physical preference of these neurons (Keliris et al., 2010). It is yet unclear whether these small modulations are rooted in local circuits in V1 or influenced by higher cognitive states. To address this question we recorded multi-unit spiking activity and local field potentials  in area V1 of awake and anesthetized macaque monkeys during the paradigm of binocular flash suppression. The results showed that the pattern of perceptual modulation of neurons in V1 under the conditions of general anesthesia is almost identical to those recorded from awake monkeys. This suggests a role of local processes in V1 in perceptual suppression. Alternatively, these modulations could be caused by feedback from higher areas independent of conscious state.", "acknowledgements": "This work was supported by Max Planck Society and Bernstein Center for Computational Neuroscience T\u00fcbingen (grant number FKZ 01GQ1002).", "id": 131193, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Hamed Bahmani"}, {"epithet": "1,2,3", "name": "Nikos K. Logothetis"}, {"epithet": "1,2", "name": "Georgios A. Keliris"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Keliris GA, Logothetis NK, Tolias AS (2010), Journal of Neuroscience 30:12353\u201312365.\nLehky SR (1988), Perception 17:215\u2013228.\nLeopold DA, Logothetis NK (1996), Nature 379:549\u2013553.\nPolonsky A, Blake R, Braun J, Heeger DJ (2000), Nat Neurosci 3:1153\u20131159. \nSheinberg DL, Logothetis NK (1997), Proc Natl Acad Sci U S A 94:3408\u20133413.\nTong F, Engel SA (2001), Nature 411:195\u2013199."}, {"correspondence": ["layne510@gmail.com"], "figid": 125, "doi": "10.12751/nncn.bc2013.0125", "affiliations": [{"index": "1", "address": "Max Planck Institute for Biological Cybernetics, Germany"}, {"index": "2", "address": "Bernstein Center for Computational Neuroscience, Germany"}, {"index": "3", "address": "Division of Imaging Science and Biomedical Engineering, University of Manchester, United Kingdom"}], "title": "Parallel processes may underly pattern motion perception ", "abstract": "Local measurements by small receptive fields induce ambiguous and noisy one-dimensional motion estimation. This problem can be overcome by selective integration or pooling over time and space to reconstruct the global pattern (Adelson & Movshon, 1982).\nHowever, it remains unclear if the local signals from intersections could influence the global pattern motion perception. Many studies used multiple apertures in order to investigate motion integration over space (Alais, Van der Smagt, Van den Berg, & Van de Grind, 1998; Maruya, Amano, & Nishida, 2010; Mingolla, Todd, & Norman, 1992; Takahashi, 2004), but none took this issue into consideration.\nHere we developed a novel stimulus and try to answer this question. We used a mask with multiple transparent apertures over a moving plaid. The plaid consisted of two overlapping moving gratings with directions 135\u00b0 apart. The apertures were small (0.4\u00b0) and were placed in locations that allowed either only single contours (AP1) or intersections (AP2) to pass through. We hypothesized that if motion integration takes place only at higher stages with larger receptive fields, the probability of coherent pattern motion perception would not be affected by the relative ratios of the aperture types.  \nOur results indicate that motion perception is largely affected by the ratio of aperture types. We conjecture that parallel processes at different stages are involved in motion integration.\n", "acknowledgements": "This work is supported by Max Planck Society and Bernstein Center for Computational Neuroscience Tuebingen.", "id": 131194, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Qinglin Li"}, {"epithet": "1,2,3", "name": "Nikos K. Logothetis"}, {"epithet": "1,2", "name": "Georgios A. Keliris"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Adelson, E. H., & Movshon, J. a. (1982). Nature, 300(5892), 523\u20135. \nAlais, D., Van der Smagt, M. J., Van den Berg, a V, & Van de Grind, W. a. (1998). Vision research, 38(11), 1581\u201391.  \nMaruya, K., Amano, K., & Nishida, S. (2010). Vision research, 50(11), 1054\u201364.  \nMingolla, E., Todd, J. T., & Norman, J. F. (1992). Vision research, 32(6), 1015\u201331.  \nTakahashi, N. (2004). Swiss Journal of Psychology, 63(3), 173\u2013182.  \n"}, {"correspondence": ["jose.donoso@bccn-berlin.de"], "figid": 126, "doi": "10.12751/nncn.bc2013.0126", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Berlin, Germany"}], "title": "Modeling hippocampal ripples in-vitro", "abstract": "Sharp wave-ripples (SWRs) are highly synchronous, transient network events displayed by the mammalian hippocampus during slow-wave sleep and immobile resting periods. Such events are believed to be involved in memory consolidation. A SWR event is characterized by fast network oscillations (~200 Hz \u201cripples\u201d) superimposed by a slow sharp wave (<50 Hz).  Understanding the mechanisms that give rise to SWRs can help us to gain insights on the computations being implemented during memory consolidation. Despite a large amount of electrophysiological data on SWRs in vivo  and in vitro and many computational models (e.g. [3][4]), the basic mechanisms behind SWR generation remain elusive. Regarding the origin of the high-frequency component, two generative mechanisms have been proposed: First, a rhythmic output of a network of principal cells coupled by gap junctions, presumably between axons of pyramidal cells [4]. Second, an interneuron network coupled by chemical synapses that modulates the firing of pyramidal cells [3]. Modeling studies showed that both mechanisms can give rise to a prominent ripple component in the 200 Hz range. Here we explore the oscillatory behavior of an in-silico model of CA1 in which excitatory synaptic transmission is blocked and SWRs are induced by application of brief potassium puffs, which transiently excite the network [1]. In such a preparation, the two proposed ripple generating mechanisms are decoupled and can be studied in isolation. Focusing on a model of a random interneuron network, we found that the power of ripple oscillations is stable for a wide range of the strength of the recurrent inhibitory coupling. A reduction of inhibitory conductance leads to a slight increase in network frequency, which is in line with [2]. Furthermore, larger reductions of inhibitory coupling leads to an abrupt decay of ripple power (see also [1]). Thus, some of the phenomenology of SWRs in vitro can be described in terms of chemical synaptic inhibition.\n", "acknowledgements": "Supported by BMBF grants no. 01GQ1001A and 01GQ0972 \n", "id": 196609, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Jos\u00e9 R. Donoso"}, {"epithet": "1", "name": "Nikolay Chenkov"}, {"epithet": "1", "name": "Richard Kempter"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Nimmrich V, Maier N, Schmitz D, Draguhn A. J. Physiol. 2005, 563.3:663-670.\n2. Behrens CJ, van den Boom LP, Heinemann U. Europ. J. Neurosci. 2007, 25:2170-2181.\n3. Traub RD, Schmitz D, Jeffreys JG, Draguhn A. Neuroscience 1999, 92:407-426.\n4. Brunel N, Wang XJ. J. Neurophysiol. 2003, 90:415-430.\n\n"}, {"correspondence": ["jojaram6@yahoo.com"], "figid": 127, "doi": "10.12751/nncn.bc2013.0127", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Berlin, Germany"}, {"index": "2", "address": "University of Freiburg, Germany"}], "title": "Inheritance of phase precession in the hippocampal formation", "abstract": "The process of faithfully retrieving episodes from our memory requires a neural mechanism capable of initially encoding ordered and reliable behavioral sequences. These behavioral sequences take place on a timescale of seconds or more whereas the timescale of neural plasticity and learning is in the order of tens of milliseconds. To shed light on this dilemma, we turn to studies of hippocampal place cells in rodents, i.e., cells that selectively increase their firing rate in a location of the environment known as the cell's place field. Within the field, the firing phases of a place cell precess monotonically relative to the ongoing theta rhythm. This phenomenon, termed \u201cphase precession\u201d[1], leads to a temporally compressed representation of the  sequences experienced by the rodent, and the compressed timescale matches the requirements of spike-timing-dependent plasticity[2]. \n\nPhase precession has been observed in several regions of the hippocampus and entorhinal cortex, but it remains a mystery whether phase precession emerges independently in each region, or conversely, whether phase precession can be \u201cinherited\u201d from an upstream neuronal population. To address this question, we employ biophysical modeling and mathematical analysis of the activity of a neuron that receives input from a population of neurons that exhibit phase precession. We show how the simple feed-forward topologies in the hippocampal formation assist in propagating phase precession to different regions of the hippocampus and adjacent structures. Furthermore, we can explain how the place-selective responses of a given cell are influenced by both excitation and inhibition; in particular we can reproduce results from intracellular and extracellular recordings in vivo[3,4,5]. Our results suggest that the presence of phase precession in different stages of the hippocampal circuit is indicative of a common source. This idea can help us better understand sequence coding within the hippocampus.", "acknowledgements": "This work was supported by the Bernstein Center for Computational Neuroscience, Berlin through grant numbers 01GQ1001A and 01GQ1001C.", "id": 196610, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Jorge Jaramillo"}, {"epithet": "2", "name": "Robert Schmidt"}, {"epithet": "1", "name": "Richard Kempter"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] O'Keefe and Recce. Hippocampus 3, 317-330 (1993). 10.1002/hipo.450030307\n[2] Skaggs et al. Hippocampus 6, 149-172, (1996). 10.1002/(SICI)\n[3] Harvey et al. Nature 461, 941-946, (2009). 10.1038/nature08499\n[4] Mizuseki et al. Neuron 64, 267-280, (2009).  10.1016/j.neuron.2009.08.037\n[5] Royer et al. Nat. Neurosci. 15 ,769\u2013775, (2012). 10.1038/nn.3077"}, {"correspondence": ["thomas.mccolgan@gmail.com"], "doi": "10.12751/nncn.bc2013.0128", "affiliations": [{"index": "1", "address": "Institute for Theoretical Biology, Humboldt-Universit\u00e4t zu Berlin, Berlin, Germany"}, {"index": "2", "address": "Department of Biology, University of Maryland, College Park, Maryland, USA, United States"}, {"index": "3", "address": "Institute for Biology II, RWTH Aachen, Aachen, Germany"}], "title": "Simulating the effect of axon geometry on the low-frequency field potential in nucleus laminaris", "abstract": "The barn owl is able to locate sounds in the azimuthal plane with extraordinary precision. The main cue is the interaural time difference, which is estimated with a precision of about 10 microseconds. The neuronal processing of the binaural cues used for this feat begins in nucleus laminaris [1] where the local field potential, called neurophonic, has such a microsecond precision [2]. The origin of the neurophonic potential in the nucleus laminaris, however, is not clear, and therefore main neuronal processing steps are not resolved.  \n\nTo understand how the neurophonic potential in nucleus laminaris is generated, we studied responses to acoustic clicks. This impulse response of the neurophonic contains distinct low- (below 2.5 kHz) and high-frequency (above 2.5 kHz) components. The high-frequency component has been previously studied [2,3], while the low frequency component remains relatively unexplored. Interestingly, the low-frequency component shows a characteristic polarity reversal between dorsal and ventral recording sites (Fig. 1). \n\nWe hypothesized that this polarity reversal is related to the spatial organization of the axons projecting from nucleus magnocellularis into nucleus laminaris. In order to test this hypothesis, we constructed a multi-compartment model of a magnocellular axon [4,5], and simulated the extracellular field caused by membrane currents of an axon bundle. Axonal sources can explain the observed polarity reversal if we assume in-vivo like activity patterns and that axons have staggered end points. This finding further corroborates the hypothesis that the input to nucleus laminaris is the dominant origin of the neurophonic in the barn owl[6].", "acknowledgements": "This work was supported by the Bundesministerium fur Bildung und Forschung, Bernstein Center for Computational Neuroscience Berlin, 01GQ1001A and Bernstein Focus \"Neuronal Foundations of Learning\" 01GQ0972.", "id": 196611, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Thomas McColgan"}, {"epithet": "2", "name": "Catherine Carr"}, {"epithet": "3", "name": "Hermann Wagner"}, {"epithet": "1", "name": "Richard Kempter"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Low-frequency (below 2.5 kHz) field potential responses from two recording sites in nucleus laminaris. The top trace is from a dorsal location and the lower trace from a ventral location. Times are relative to stimulus presentation. Anatomic tracing adapted from [1].", "figpath": "128.png", "refs": "[1] Carr CE and Konishi M, 1990, J Neuroscience\n[2] Wagner H et al, 2005, J Neurophysiol, doi:10.1152/jn.01226.2004\n[3] Wagner H et al, 2009, J Neurophysiol, doi:10.1152/jn.00092.2009\n[4] Grau-Serrat V et al, 2003, Biological Cybernetics, doi:10.1007/s00422-003-0444-4\n[5] Kuba H and Ohmori H, 2009, J Physiology, doi:10.1113/jphysiol.2008.162651\n[6] Kuokkanen P et al, 2010, J Neurophysiol, doi:10.1152/jn.00395.2010"}, {"correspondence": ["apine@kaist.ac.kr"], "figid": 129, "doi": "10.12751/nncn.bc2013.0129", "affiliations": [{"index": "1", "address": "Information and Electronics Research Institute, KAIST, Daejeon, South Korea"}, {"index": "2", "address": "Department of Electrical Engineering, KAIST, Daejeon, South Korea"}], "title": "A Hierarchical Predictive Memory Model of Neocortex for Hierarchical Reinforcement Learning", "abstract": "Hierarchical reinforcement learning algorithm (HRL) is reported to relevant to understand brain\u2019s behavioral learning functions. HRL is a reinforcement learning algorithm that the agents can select not only from the primitive actions but also from the hierarchical sets of multi-action subroutines, which reduces the problems tractable. How brains discover the hierarchical schema from the experiences and how they use the hierarchical schema for recognizing hierarchical structure of ongoing states are important problems in the HRL. In this paper, we will suggest that schema formation can be treated similar to the hierarchical feature learning in perception systems. We hypothesize that the event states sequences in the environment are generated from hierarchical and modular event systems. Experiences for series of events shape the inverse generative model of the event system in a hierarchical predictive memory. This knowledge about the event system is suggested to be used to infer the hierarchical structure of ongoing states in Bayesian manner for HRL. To test this idea, we developed a hierarchical version of temporal difference (TD) learning method using Hierarchical Temporal Memory, an implementation of hierarchical predictive memory system. We test our model for simple and general event systems in simulation environments. We demonstrated that our model can accelerate the reinforcement learning. Moreover, learning the policy for one problem in an event system could help to learn the other problem in the same event system. Finally, we showed that, our method showed adaptable behavior to random series of problems in one event system. Our result shows the origin of hierarchy in the HRL can be explained in the hierarchical predictive memory model of Neocortex which was widely used for the perception problems. ", "acknowledgements": "", "id": 196612, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Hansol Choi"}, {"epithet": "2", "name": "Dae-Shik Kim"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["jaeyoung117@kaist.ac.kr"], "figid": 130, "doi": "10.12751/nncn.bc2013.0130", "affiliations": [{"index": "1", "address": "Korea Advanced Institute of Science and Technology, South Korea"}], "title": "Neuro-robotics model of visual delusions", "abstract": "Most computational models of visual perception are about normal brain functions. However, there is not much study done on computational model of visual perception about dysfunctional brain. Our main objective is mechanistic and algorithmic elucidation of delusional perception in normal and dysfunctional brain. \nVisual delusions are a prevalent symptom for many psychiatric disorders, including schizophrenia. They are characterized by overly distorted perception of external visual stimuli. Delusional perception has been recently proposed to be compatible with theoretical models within hierarchical Bayesian network framework. In the present study, we hypothesized that imbalance between bottom-up and top-down processing in hierarchical Bayesian network framework may constitute one of the intrinsic basis for visual delusions. To this end, we utilized simple and biologically-plausible model such as Hierarchical Predictive Coding Network as the basis for our subsequent computational experiments. We utilize Deep Boltzmann Machines (DBMs) as hierarchical models of cortical processing. We included predictive coding scheme to DBMs to investigate visual delusions. In this expanded model, top-down prior expectations are balanced against bottom-up visual inputs (causes) and prior belief (top-down expectation) is updated by a combined top-down and bottom-up pass. In order to investigate the emergence of visual delusions using this framework, face images were used to train a modified DBM system. In the delusional perception mode, visual delusions can arise from false belief network system. We concluded from the results of our preliminary studies that hierarchical predictive coding networks have the potential to serve an architecture and algorithmic framework for more mechanistic elucidation of delusional perception in normal and dysfunctional brains.", "acknowledgements": "This research was supported by NRF(N01120339,N01120163),IBS(N04120248),GFP(SIRC-N01120753) and KOLON industries (G01120293).", "id": 196613, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Jae Young Jun"}, {"epithet": "1", "name": "Dae-Shik Kim"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] P. C. Fletcher and C. D. Frith (2009) \"Perceiving is believing: a Bayesian approach to explaining the positive symptoms of schizophrenia\". Nature reviews,Neuroscience vol 10,doi:10.1038/nrn2536\n[2] Friston K (2008) \"Hierarchical Models in the Brain\". PLoS Comput Biol 4(11): e1000211. doi:10.1371/journal.pcbi.1000211\n[3] R. Salakhutdinov and G. Hinton (2009) \"Deep Boltzmann Machines\". Proceedings of the International Conference on Artificial Intelligence and Statistics."}, {"correspondence": ["martin.angelhuber@bcf.uni-freiburg.de"], "figid": 131, "doi": "10.12751/nncn.bc2013.0131", "affiliations": [{"index": "1", "address": "Faculty of Biology and Bernstein Center Freiburg, University of Freiburg, Germany"}, {"index": "2", "address": "Friedrich Miescher Institute for Biomedical Research, Basel, Switzerland"}], "title": "Tonic conductance changes in the Central Amygdala influence fear generalization", "abstract": "Recent experimental studies (Ciocchi et al, 2010, Haubensak et al, 2010) have revealed an inhibitory microcircuit in the central amygdala (CEA) which is essential for the acquisition and expression of conditioned fear. Two physiologically distinct, mutually inhibiting neuron subpopulations within the lateral part (termed CEl_on and CEl_off) form inhibitory connections to the medial subdivision of the central amygdala (CEm), which drives conditioned fear responses. These subpopulations undergo plasticity of their phasic and tonic activity during fear conditioning, thereby gating fear expression. Notably, Ciocchi et al. (2010) reported a correlation between changes in tonic activity and the ability of the animal to discriminate between the conditioned stimulus and a neutral control stimulus.\nThese activity changes are associated with synaptic plasticity (of the conditioned stimulus) and  subpopulation-specific changes of tonic inhibitory membrane conductances (Botta et al, in preparation). To understand how these two different types of plasticity affect fear conditioning and generalization we devised a spiking neuronal network model of the central amygdala. Specifically, we investigated the effect of tonic conductance changes on the processing of incoming stimuli in the network. In the model, conductance changes and synaptic plasticity at the afferent connections from the basolateral amygdala to CEl (Li, 2013) reproduce the observed changes in phasic and tonic activity (Ciocchi et al, 2010). Furthermore, our results suggest that, while synaptic plasticity controls the sensitivity of the network to phasic input (CS+/-), plasticity of tonic conductances provides fine-tuning of the network response and in particular regulates fear generalization. ", "acknowledgements": "Supported in parts by BrainLinks-BrainTools Cluster of Excellence funded by the German Research Foundation (DFG, grant number EXC 1086), EU Erasmus Phd program `NeuroTime' ", "id": 196614, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Martin Angelhuber"}, {"epithet": "2", "name": "Paolo Botta"}, {"epithet": "2", "name": "Andreas L\u00fcthi"}, {"epithet": "1", "name": "Ad Aertsen"}, {"epithet": "1", "name": "Arvind Kumar"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Ciocchi, S., et al. (2010). Nature 468, 277-282. doi:10.1038/nature09559\nHaubensak, W., et al. (2010). Nature 468, 270-276. doi:10.1038/nature09553\nLi H., et al. (2013). Nature Neuroscience 16, 332-339. doi:10.1038/nn.3322\nBotta, P., et al. (in preparation)"}, {"correspondence": ["alejandro.bujan@bcf.uni-freiburg.de"], "figid": 132, "doi": "10.12751/nncn.bc2013.0132", "affiliations": [{"index": "1", "address": "Bernstein Center Freiburg, Germany"}, {"index": "2", "address": "CNRS-UNIC, France"}], "title": "Propagation of synchronous activity through network resonance", "abstract": "Experimental evidence suggests that the cortex processes sensory stimuli by routing synchronous neuronal activity across hierarchies of functionally specialized neuronal networks. Previously proposed theoretical models impose strong requirements to ensure a reliable propagation of the synchronous activity. On the one hand, the \"synfire chain\" model implies the existence of strong and dense connectivity (Kumar et al. 2008; Diesmann et al. 1999)\u2060. On the other hand the \"communication through coherence\" model requires a consistent phase relationship between the population oscillations of different neuronal networks (Fries 2005)\u2060. Here we present a novel mechanism that creates a natural link between the two aforementioned models while offering a way to overcome their limitations. The model exploits the intrinsic oscillatory modes of recurrent excitatory-inhibitory (EI) neuronal networks to amplify weak periodic signals within a narrow frequency band. We use numerical simulations to explore the propagation of periodic signals through a layered structure of weakly interconnected recurrent EI networks. Our results indicate that propagation is robust against deviations from periodicity in the input. Using a mean field rate model we show that the EI network has second order linear dynamics that shape the resonance behavior of the system. We also evaluate how the resonance behavior depends on the delays and the connectivity strength between the different populations. In summary our results show that oscillations in the large-scale population activity could be a direct consequence of spiking activity propagating through weakly connected EI networks.", "acknowledgements": "This work was supported by FACETS-ITN, CNRS, BrainScales, ANR Complex-V1, the German Federal Ministry of Education and Research (BMBF 01GQ0420 to BCCN Freiburg and 01GQ0830 to BFNT Freiburg/T\u00fcbingen) and the BrainLinks-BrainTools Cluster of Excellence funded by the German Research Foundation.", "id": 196615, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Alejandro F. Bujan"}, {"epithet": "2", "name": "Gerald Hahn"}, {"epithet": "2", "name": "Yves Fregnac"}, {"epithet": "1", "name": "Ad Aertsen"}, {"epithet": "1", "name": "Arvind Kumar"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Diesmann, M., Gewaltig, M.O. & Aertsen, A., 1999. Stable propagation of synchronous spiking in cortical neural networks. Nature, 402(6761), pp.529\u2013533. \nFries, P., 2005. A mechanism for cognitive dynamics: neuronal communication through neuronal coherence. Trends Cogn Sci, 9(10), pp.474\u201380. \nKumar, A., Rotter, S. & Aertsen, A., 2008. Conditions for propagating synchronous spiking and asynchronous firing rates in a cortical network model. J Neurosc, 28(20), pp.5268\u201380. "}, {"correspondence": ["spreizer@web.de"], "figid": 133, "doi": "10.12751/nncn.bc2013.0133", "affiliations": [{"index": "1", "address": "Bernstein Center Freiburg and Neurobiology & Biophysics, Faculty of Biology, University of Freiburg, Germany"}], "title": "Dynamics of cell assemblies in a spiking network model of the striatum", "abstract": "Despite a wealth of anatomical and electrophysiological data, network mechanisms underlying the role of striatum in cognitive and motor functions have remained obscure. Recent experimental data [1-3] and computational models [5] suggest that purely inhibitory recurrent connectivity of striatal neurons could support transient neuronal assemblies and that striatum operates in a \u2018winner-less-competition\u2019 (WLC) [6] mode.\n\nHere we studied the dynamics of striatum neuronal assemblies in large-scale (10,000 leaky-integrate&fire neurons) spiking neuronal networks with two different types of distance dependent connectivity profiles. In networks where connection probability decreased with distance in a Gaussian fashion, the network activity showed no distinct spatial correlations and, hence, showed no neuronal assemblies, neither in the ongoing nor in stimulus induced states. \n\nIn networks where the connection probability changed as gamma distribution as a function of distance between neurons (small or no connection probability within a close neighborhood [3]), neuronal activity was organized in clusters. In low firing rate states, the neuronal assemblies lasted for ~50ms, creating WLC [6]. By contrast, in high firing rate states, neuronal assemblies were highly stable, indicating the \u2018winner-take-all\u2019 dynamics mode [7]. Next, upon stimulation of a fraction of neurons, the network reorganized the spatial structure of neuronal assemblies. Dopamine depletion in Parkinson\u2019s disease results in high background activity. In high firing rate states, transient stimulation can led to a persistent activity in the network (attractor dynamics). Such activity states could provide an explanation of deficits in voluntary actions and beta-band oscillations in the basal ganglia [4].\n\nIn summary, we argue that the non-monotonic spatial connectivity provides the striatum with a rich dynamical repertoire and that the ongoing activity can switch states between different dynamical modes.", "acknowledgements": "This work was funded in parts by BrainLinks-BrainTools Cluster of Excellence funded by the German Research Foundation (DFG, grant number EXC 1086), EU Erasmus Phd program `EuroSPIN' and NeuroTime. \nAll simulations were carried out with NEST (http://www.nest-initiative.org).", "id": 196616, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Sebastian Spreizer"}, {"epithet": "1", "name": "Jyotika Bahuguna"}, {"epithet": "1", "name": "Ad Aertsen"}, {"epithet": "1", "name": "Arvind Kumar"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1.Adler et al. (2013) doi: 10.1523/jneurosci.4791-12.2013\n2.Carrillo-Reid et al. (2011) doi: 10.1523/jneurosci.3226-11.2011\n3.Lopez-Huerta VG et al. (2013) doi: 10.1523/jneurosci.4721-12.2013\n4.Kumar et al. (2011) doi: 10.3389/fnsys.2011.00086\n5.Ponzi A & Wickens J (2010) doi: 10.1523/jneurosci.5540-09.2010\n6.Rabinovich M (2001) doi: 10.1103/PhysRevLett.87.068102\n7.Wickens J et al. (2007) doi:10.1016/S0079-6123(06)60018-6"}, {"correspondence": ["kammerer@bio.lmu.de"], "figid": 134, "doi": "10.12751/nncn.bc2013.0134", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience Munich; Graduate School of Systemic Neuroscience and Division of Neurobiology, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, 82152 Martinsried, Germany"}], "title": "Implications of Grid Phases on Decoding with Noise", "abstract": "Grid cells in the medial entorhinal cortex encode space with hexagonal firing fields,\nwhere nearby cells have similar grid spacing. Yet it is unknown how the grids should be\nshifted against each other in phase. The phases of the fields may influence the\nresolution of the decoder, and the tolerance to noise. Here, we assess the decoding\naccuracy for two extreme cases. Evenly spaced phases, and clustered phases, i.e.,\nseveral cells share the same grid thereby forming a subpopulation. We show that a uniform\nphase distribution is favorable over clustering to obtain high resolutions, without noise\nas well as for different noise models. However, the advantage progressively disappears\nwith increasing noise level such that under realistic conditions few phases may suffice to\noptimally represent space by a population of grid cells.", "acknowledgements": "", "id": 196617, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Axel Kammerer"}, {"epithet": "1", "name": "Christian Leibold"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["slehnert@bio.lmu.de"], "figid": 135, "doi": "10.12751/nncn.bc2013.0135", "affiliations": [{"index": "1", "address": "Computational Neuroscience, Department Biology II, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Germany"}, {"index": "2", "address": "Division of Neurobiology, Department Biology II, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Germany"}], "title": "Action potential generation in coincidence detector neurons of the medial superior olive", "abstract": "Principal neurons in  the medial superior olive (MSO) encode interaural time differences by their firing rate. We assessed the morphology of the first segments of MSO axons by immunohistochemical labeling and 3D-reconstruction from confocal image stacks and found a short AIS and an overall very thin axon of 0.66 microns in diameter. In accordance with this data a multi-compartmental model of an MSO neuron and its axon was created. We found that even though the soma is extremely leaky the axonal segments were very well-isolated showing a much better exitability than the soma. We investigated the dependence of firing on axonal morphology, stimulus kinetics and frequency using modeled naturalistic conductance inputs as well as simple onset input paradigms. We found that shorter internodes and a larger axonal diameter facilitated firing. Moreover, the firing probability exhibited a strong frequency dependence which was seen for ongoing and onset stimuli. The lowest threshold was observed at an input frequency of 500 Hz. The modeling results concerning the onset type stimuli were verified in in-vitro experiments. For both onset and ongoing spiking the dependence on stimulus amplitude and frequency was similar, however the underlying mechanisms were different. Especially for high frequency ongoing synaptic activity, the site of the spike initiation moved deeper into the axon for a substantial amount of elicited APs. This is because the stronger excitatory activity that is necessary to drive the neuron makes the cell leakier and inactivates sodium channels in proximal regions (soma and AIS), while more distal parts of the axon are less affected.\nWe conclude that, even though MSO principal neurons are hard to excite they maintain much of their excitability by having a thin axon. In cases where the AIS is barely excitable the excitability of the deeper axonal parts still secures the cell's spiking capability and enables the cell to convey information via a rate code.", "acknowledgements": "", "id": 196618, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Simon Lehnert"}, {"epithet": "2", "name": "Marc Ford"}, {"epithet": "2", "name": "Olga Alexandrova"}, {"epithet": "1", "name": "Franziska Hellmundt"}, {"epithet": "2", "name": "Felix Felmy"}, {"epithet": "2", "name": "Benedikt Grothe"}, {"epithet": "1", "name": "Christian Leibold"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["d.medina@gmx.de"], "figid": 136, "doi": "10.12751/nncn.bc2013.0136", "affiliations": [{"index": "1", "address": "Computational Neuroscience, Department Biologie II, Ludwig-Maximilians-Universit\u00e4t, Germany"}], "title": "Inhomogeneity reduces memory capacity for sequences", "abstract": "Theoretical models of associative memory generally assume most of their parameters to be homogeneous across the network. However, biological neural networks exhibit high variability of structural as well as activity parameters. This work extends previous models of sequence memory based on Willshaw's learning rule to inhomogeneous pattern sizes, i.e., patterns of variable sparseness. Our results reveal that inhomogeneity in the sparseness of stored patterns is detrimental to a recurrent network's dynamic stability during sequence retrieval, and effectively reduces memory capacity. Bigger than average patterns tend to lead the network into an all-active epileptic state as a result of an excessively high synaptic drive, whereas smaller than average patterns tend to lead to an all-silent state as a result of an insufficient synaptic drive. In either case, sequence retrieval is terminated prematurely due to dynamic instability. Instantaneous feedback inhibition is able to compensate to a certain degree for too big patterns, but it does nothing to prevent the network from falling silent as a result of too small patterns, which are therefore more detrimental to the network dynamics.", "acknowledgements": "This work was funded by the German Federal Ministry for Education and Research (BMBF) under grant numbers 01GQ0981 (Bernstein Fokus on Neuronal Basis of Learning: Plasticity of Neuronal Dynamics) and 01GQ1004A (Bernstein Center for Computational Neuroscience Munich).", "id": 196619, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Daniel Medina"}, {"epithet": "1", "name": "Christian Leibold"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["leeyinyun@gmail.com"], "figid": 138, "doi": "10.12751/nncn.bc2013.0138", "affiliations": [{"index": "1", "address": "Ohio University, United States"}, {"index": "2", "address": " Georg-August-University G\u00f6ttingen, Germany"}, {"index": "3", "address": "Ohio State University, United States"}], "title": "The formation of axonal caliber and nodes of Ranvier", "abstract": "A remarkable feature of myelinated neurons is that their axons are constricted at the nodes of Ranvier. These are the locations where axons are directly exposed to the extracellular space and where the vast majority of the ion channels are located. These constrictions emerge during development and have been observed to reduce axonal cross sectional area by factors of more than 10. Combining fluorescent imaging methods with computational modeling, we describe how the nervous system regulates the local caliber of its axons through the regulation of the transport kinetics of its most important cytoskeletal elements, the neurofilaments, matching axon caliber and shape to its physiologic function. ", "acknowledgements": "I thank Prof. Anthony Brown, who provides the pulse-escape data in both vivo and vitro nerves; I also thank Prof. Peter Jung and Prof. Anthony Brown for supervising the project. ", "id": 196620, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Yinyun Li"}, {"epithet": "3", "name": "Anthony Brown"}, {"epithet": "1", "name": "Peter Jung"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Nature Cell Biology, Vol 2, 2000.\nPhys. Biol. 6 (2009) 046002 (15pp).\nThe Journal of Neuroscience, January 17, 2007, 27(3):507\u2013516.\nMolecular Biology of the Cell Vol.16, 4243\u20134255, 2005."}, {"correspondence": ["davide.bernardi@bccn-berlin.de"], "figid": 139, "doi": "10.12751/nncn.bc2013.0139", "affiliations": [{"index": "1", "address": "BCCN Berlin, Germany"}], "title": "Frequency-resolved information rate of stochastic integrate-and-fire models", "abstract": "The coherence function of integrate-and-fire neurons shows low-pass properties in the most diverse firing regimes [1]. While the coherence function provides a good approximation to the full information transfer properties in the case of a weak input, for a strong input non-linear encoding could play an important role. The complete information transfer is quantified by Shannon's mutual information rate [2] which has been estimated in certain biological model systems [3]. In general, the exact analytical calculation of the mutual information rate is unfeasible and even the numerical estimation is demanding [4].\n\nNumerical calculation of the mutual information rate is now a commonly adopted practice, but it does not indicate what aspects of the stimulus are best represented by the neuronal response. We developed a numerical procedure to directly calculate a frequency-resolved version of the mutual information rate. This can be used to study how different frequency components of a Gaussian stimulus are encoded in neural models without invoking a weak-signal paradigm.", "acknowledgements": "This work was funded by the BMBF (FKZ: 01GQ1001A).", "id": 196621, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Davide Bernardi"}, {"epithet": "1", "name": "Benjamin Lindner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1.Vilela RD, Lindner B: A comparative study of different integrate fire neurons: spontaneous activity, dynamical response, and stimulus-induced correlation. Phys. Rev. E (2009).\n2.Shannon C: A Mathematical Theory of Communication. The Bell System Technical Journal (1948).\n3.Strong SP et al.: Entropy and Information in Neural Spike Trains. Phys. Rev. Lett. (1998).\n4.Panzeri S, et al.: Correcting for the sampling bias problem in spike train information measures. J Neurophysiol. (2007)."}, {"correspondence": ["jens.doose@bccn-berlin.de"], "figid": 140, "doi": "10.12751/nncn.bc2013.0140", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Berlin, 10115, Germany"}], "title": "Fitting an exponential Integrate and fire neuron to spike trains evoked by juxtacellular stimulation", "abstract": "We used nanostimulation, a technique which allows stimulation of identified single neurons in vivo [1], in order to drive pyramidal cells in anesthetized rat motor cortex with fluctuating stimuli (frozen bandpass-limited white noise). We explore how well the spike train in response to this stimulus can be captured by an exponential integrate-and-fire neuron [2], a simple model that has been successfully applied for reproducing spike times of pyramidal cells under noisy current stimulation in vitro [3]. In contrast to the latter situation, our model also includes an appreciable amount of intrinsic noise, accounting for fluctuating input from the surrounding network.   ", "acknowledgements": "This work was supported by Bundesministerium f\u00fcr Bildung und Forschung grant 01GQ1001A", "id": 196622, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Jens Doose"}, {"epithet": "1", "name": "Guy Doron"}, {"epithet": "1", "name": "Michael Brecht"}, {"epithet": "1", "name": "Benjamin Lindner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] A.R Houweling, G. Doron, B.C. Voigt, L.J. Herfst, and M. Brecht J. Neurophysiol. 103, 1696 (2010)\n\n[2] N. Fourcaud-Trocme, D. Hansel, C. van Vreeswijk and N. Brunel J. Neurosci. 23,  11628 (2003)\n\n[3] L. Badel, S. Lefort, R. Brette, C.C.H. Petersen, W. Gerstner and M.J.E. Richardson J. Neurophysiol. 99, 656 (2008)\n"}, {"correspondence": ["felix.droste@bccn-berlin.de"], "doi": "10.12751/nncn.bc2013.0141", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience Berlin, Germany"}], "title": "Analytical results for integrate-and-fire neurons driven by dichotomous noise", "abstract": "Integrate-and-fire models [1] have been widely used in the study of neural systems; in spite \u2013 and because - of their simplicity, they have allowed for analytical insights into a diverse range of questions, ranging from information transmission [2] or adaptation [3] in single neurons to studies of neural networks [4]. Typically, input to such integrate-and-fire neurons is modeled as a Poisson process, i.e. uncorrelated shot noise. As this is notoriously difficult to treat analytically (but see [5]), many studies have employed the so called diffusion approximation.\nHere, we study a general integrate-and-fire neuron that receives dichotomous noise as its input, i.e. noise that jumps stochastically between two levels (Fig. 1, see [6] for a similar setup). As opposed to the commonly employed diffusion approximation, this input is neither uncorrelated nor Gaussian. It could, for example, model up- and down-states of  an embedding network or input from a bursting cell.  Furthermore, there are interesting limit cases; when switching rates are asymmetric, for example, dichotomous noise converges to excitatory shot noise in the limit of small correlation time. We give analytical expressions for firing rate, CV, and stationary probability distributions and compare them to numerical simulations.", "acknowledgements": "This work was supported by Bundesministerium fuer Bildung und Forschung grant 01GQ1001A and the research training group GRK 1589 \"Sensory Computation in Neural Systems\".", "id": 196623, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Felix Droste"}, {"epithet": "1", "name": "Benjamin Lindner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "A) Sample time course of a two state noise. B) Corresponding voltage dynamics of a leaky integrate-and-fire neuron. C) Stationary distribution of this neurons membrane voltage. Units are arbitrary.", "figpath": "141.png", "refs": "1. Burkitt, A. N.  Biol. Cybern. 95.1 (2006): 1-19.\n2. Lindner, B, and Schimansky-Geier, L.  Phys. Rev. Lett. 86.14 (2001): 2934-2937.\n3. Liu, Ying-Hui, and Xiao-Jing Wang.  J. Comp. Neurosci. 10.1 (2001): 25-45.\n4. Brunel, N.  J. Comp. Neurosci. 8.3 (2000): 183-208.\n5. Richardson, MJE, and Swarbrick, R. Phys. Rev. Lett. 105.17 (2010): 178102.\n6. Salinas, E., and Sejnowski, T. J.  Neural Comput. 14.9 (2002): 2111-2155."}, {"correspondence": ["alexandra.kruscha@gmail.com"], "figid": 142, "doi": "10.12751/nncn.bc2013.0142", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Berlin/ Institute for Physics, Humboldt-Universit\u00e4t zu Berlin, Germany"}], "title": "Generalized synchronous output of neural populations \u2013 does it only encode fast stimulus components? ", "abstract": "Neurons are subject to intrinsic noise, which influences the information transmission of an incoming signal. Which information can we derive from a population of noisy neurons, that are uncoupled, but driven by a common broadband stimulus? Intuitively, one expects that the times where the action potentials of the different neurons coincide (synchronous spikes), contain different information about the common stimulus than the output of a single neuron does. \nIndeed, experiments in a electro-sensory model system [1] revealed that synchronous spikes encode preferentially fast (high-frequency) components of the stimulus, i.e. synchrony acts as an information filter. A recent theoretical study [2]\nconfirmed this finding and uncovered the stochastic mechanism of this filter. \n\nTo simplify the analytical approach, Ref. [2] used a rather strict measure of synchrony: all neurons in the population have to fire within a short time window. Here we generalize this to a measure of the synchronous output, for which only m out of n neurons in the population have to fire in synchrony.  We inspect, how well this measure works for different ratios m/n and present an analytical approach to the spectral coherence function that characterizes the information transfer of the stimulus to the synchronous output. We discuss under which conditions this generalized synchrony acts as a band-pass filter. ", "acknowledgements": "This work was supported by Bundesministerium f\u00fcr Bildung und Forschung grant 01GQ1001A.", "id": 196624, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Alexandra Kruscha"}, {"epithet": "1", "name": "Benjamin Lindner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Middleton JW, Longtin A, Benda J, Maler L: Postsynaptic Receptive Field Size and Spike Threshold Determine Encoding of High-Frequency Information Via Sensitivity to Synchronous Presynaptic Activity. \nJournal of Neurophysiology 2009.\n2. Sharafi N, Benda J,  Lindner B: Information filtering by synchronous spikes in a neural population \nJournal of Computational Neuroscience 2012"}, {"correspondence": ["tilo.schwalger@epfl.ch"], "figid": 143, "doi": "10.12751/nncn.bc2013.0143", "affiliations": [{"index": "1", "address": "EPFL, Switzerland"}, {"index": "2", "address": "BCCN Berlin, Germany"}], "title": "Theory of correlation patterns in neurons with adaptation", "abstract": "Many neurons transiently adapt their firing rate during a step current stimulation -- a phenomenon called spike-frequency adaptation (SFA). In the stationary spiking activity of a neuron, the mechansims underlying SFA are thought to become manifest in negative correlations between interspike intervals (ISIs) as shown by many numerical studies [1,2]. Such negative correlations have a strong effect on the long-term spiking variability of single neurons and profoundly shape the low-frequency power of the population activity of many neurons. However, a theoretical understanding of ISI correlations in adapting neurons is largely missing. Here, we present an analytical theory of ISI correlations for a large class of neuron models with spike-triggered adaptation currents [3]. The theory for tonically firing neurons is based on a weak-noise assumption but is valid for arbitrary adaptation time constants and adaptation strength. We derive an explicit formula for the serial correlation coefficient (SCC) for a given phase-response curve (PRC) of the neuron, thus relating non-renewal properties of the spike train to the nonlinear neural dynamics. The relations yields fundamental insights into the structure of possible correlations: (i) it proves that adjacent ISIs are negatively correlated for any neuron with type I PRC, (ii) it explains monotonic and alternating correlation patterns that have been observed in experiments [4] and (iii) it demonstrates that the sum of ISI correlations over all lags is close to -0.5 for strong adaptation, regardless of the detailed correlation pattern. Finally, our theory predicts positive ISI correlations that are only possible in neurons with type II PRCs. All our result are well confirmed by extensive numerical simulations of the leaky, exponential and generalized integrate-and-fire model with adaptation.   ", "acknowledgements": "", "id": 196625, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Tilo Schwalger"}, {"epithet": "2", "name": "Benjamin Lindner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Y. H. Liu, X. J. Wang. J. Comp. Neurosci. 10:25 (2001)\n[2] O. Avila-Akerberg, M. J. Chacron. Exp. Brain Res. (2011)\n[3] T. Schwalger, B. Lindner. arXiv 2013\n[4] R. Ratnam, M. E. Nelson. J Neurosci 20:6672 (2000)"}, {"correspondence": ["sergej@physik.hu-berlin.de"], "doi": "10.12751/nncn.bc2013.0144", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neursoscience, Berlin, 10115, Germany"}], "title": "Does noise shift or delete spikes?", "abstract": "Stochastic leaky integrate-and-fire neurons are widely used to study properties of neural networks (e.g. [1]) as well as the spontaneous activity and signal transmission [2] of single neurons. They have also been employed in studies of the \u2018common-noise\u2019 problem, i.e. the question of how correlated input to two cells causes output spike train correlations of these neurons [3].\nIn the cortex, input correlations seem to be weak [4], however, in the sensory periphery with a strong time-dependent stimulus the situation can be completely different. The two neurons receive the same strong stimulus (often modeled as a random signal) and each neuron is subject to a small amount of intrinsic noise. Without the intrinsic noise two identical neurons would fire in complete synchrony. How does the weak noise change the spikes?\nTo address this question, we first study two versions of inhomogeneous Poisson processes. In one version the intrinsic noise can shift spike times, in the other the noise leads to deletions and additions of spikes. We construct these processes in such a way that the correlations between the modulated spike trains and the perturbing noise is the same in both versions. In this setup, it is possible to analytically calculate the cross-correlation between two spike trains with independent intrinsic noise. By comparison with extensive simulations of stochastic integrate-and-fire neurons we then inspect, which of the two modulation methods is more appropriate to capture the effect of a weak noise on the spike train of a dynamic neuron model.", "acknowledgements": "This work was funded by the BMBF (FKZ: 01GQ1001A).", "id": 196626, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Sergej Voronenko"}, {"epithet": "1", "name": "Benjamin Lindner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Two neurons receive a common signal and distinct intrinsic noise. c is the correlation parameter that tunes the strength of the input correlation. Weak input correlations correspond to c<<1 and strong input correlations correspond to (1-c)<<1.", "figpath": "144.png", "refs": "1.Brunel N: Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons. J Comput Neurosci 2000\n2. Burkitt A N: A review of the integrate-and-fire neuron model. Biological cybernetics 2006  \n3. De la Rocha J et. al.: Correlation between neural spike trains increases with firing rate. Nature 2007\n4. Zohary et. al.: Correlated neuronal discharge rate and its implications for psychophysical performance. Nature 1994"}, {"correspondence": ["shliu@mail.ndhu.edu.tw"], "figid": 145, "doi": "10.12751/nncn.bc2013.0145", "affiliations": [{"index": "1", "address": "Department of Counseling and Clinical Psychology, National Dong-hwa University, Taiwan, Province China"}], "title": "The effect of spatial cues on the facial features for conveying emotional information", "abstract": "Some previous studies have reported that face recognition was more dependent on holistic processing than local processing. Nevertheless the research of various domains, behavioral study, eye-tracking technique and cognitive neuroscience, have found that specific features of the face play an important role in conveying emotional information (Eisenbarth & Alpers, 2011). Most of these evidences were based on overt attention, less on covert attention. Previous studies of covert attention have reported that the 100\u2013175 ms interval between cue and target onset could maximize the spatial cueing effect (Kristjansson, Mackeben, & Nakayama, 2001). Thus, in the present study we used psychophysical method to investigate whether the maximal effect of covert spatial cueing of attention on the eye and mouth features could be beneficial for conveying facial emotional information, and whether the advantage of conveying either the positive or negative emotional information could be due to the effect of covert attention cueing on the specific facial features. In experiment 1, we found that the responses to the happy face were benefited from the cueing on the mouth features, and the responses to the angry face were benefited from the cueing on the eye features. In experiment 2, the 450 ms interval between cue and target onset subsided the effect of covert spatial cueing in a non-significant way. Our results provide evidence that specific features of the face are importantly relevant for conveying emotional information, also support a relationship of reciprocal modulation between emotional information and perceptual processing.", "acknowledgements": "", "id": 196627, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Kai-lun Hsieh"}, {"epithet": "1", "name": "Shiau-hua Liu"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Eisenbarth, H., & Alpers, G. W. (2011). Happy mouth and sad eyes: scanning emotional facial expressions. Emotion, 11(4), 860\u2013865. doi:10.1037/a0022758.\nMasaki,Y., Maddux,W.W., & Takahiko, M. (2007). Are the windows to the soul the same in the East and West? Cultural differences in using the eyes and mouth as cues to recognize emotions in Japan and the United States. Journal of Experimental Social Psychology, 43(2), 303\u2013311. doi:10.1016/j.jesp.2006.02.004\n"}, {"correspondence": ["Franziska.Greifzu@biologie.uni-goettingen.de"], "figid": 146, "doi": "10.12751/nncn.bc2013.0146", "affiliations": [{"index": "1", "address": "Systems Neuroscience, BFNT, J.F.B. Institut f\u00fcr Zoologie und Anthropologie, Georg-August Universit\u00e4t G\u00f6ttingen, Germany"}, {"index": "2", "address": "Institut f\u00fcr Allgemeine Zoologie und Tierphysiologie, Friedrich-Schiller-Universit\u00e4t Jena, Germany"}, {"index": "3", "address": "European Neuroscience Institute G\u00f6ttingen (ENI), G\u00f6ttingen, Germany"}], "title": "Enriched environment housing preserved a juvenile-like ocular dominance plasticity and a juvenile inhibitory tone into adulthood in mouse primary visual cortex", "abstract": "Ocular dominance (OD) plasticity in the mouse primary visual cortex (V1) is maximal at 4 weeks of age, declines during development and is absent beyond postnatal day (PD) 110 if mice are raised in standard cages (SC). While enriched environment (EE) has been shown to promote OD-plasticity in adult rats it is not clear what the underlying mechanisms are. Here we explored cellular mechanisms of EE in V1 of mice and the therapeutic potential of EE to prevent impairments of plasticity after a cortical stroke. Using in vivo optical imaging of intrinsic signals, we show that monocular deprivation (MD) in enriched but not SC-reared adult mice induced a very strong and juvenile-like OD-shift towards the open eye at least until postnatal day 437. This OD-shift was as strong as previously observed only in 4-week-old animals and mediated by a reduction in deprived eye responses in V1. In addition, we explored the cellular mechanisms underlying this EE-effect by in vitro patch-clamp recordings in slices of adult animals: the ratio of GABA receptor-mediated inhibitory postsynaptic currents to AMPA receptor-mediated excitatory postsynaptic currents was reduced in EE- compared to SC-mice, while the AMPA/NMDA ratio was not different between the groups. Moreover, the GABA/AMPA ratio in adult EE-mice was not significantly different from juvenile SC-mice indicating a juvenile level of inhibition in V1 of adult EE-mice. This observation was corroborated by in vivo imaging showing that diazepam treatment significantly reduced the OD-shift. Finally, EE-rearing preserved OD-plasticity after a stroke in the primary somatosensory cortex. Taken together, EE-raising preserved both a juvenile-like OD-plasticity and a juvenile GABA/AMPA ratio into adulthood indicating that the plasticity promoting effect of EE is mediated by a reduction of intracortical inhibition. This suggests EE as a preventive intervention to both enhance and preserve plasticity in adulthood and after a cortical lesion.", "acknowledgements": "", "id": 196628, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Franziska Greifzu"}, {"epithet": "2", "name": "Katja Krempler"}, {"epithet": "3", "name": "Plinio D. Favaro"}, {"epithet": "3", "name": "Oliver M. Schl\u00fcter"}, {"epithet": "1", "name": "Siegrid L\u00f6wel"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["forster@fias.uni-frankfurt.de"], "figid": 147, "doi": "10.12751/nncn.bc2013.0147", "affiliations": [{"index": "1", "address": "Frankfurt Institute for Advanced Studies, Goethe-University Frankfurt, Germany"}, {"index": "2", "address": "Department of Physics, Goethe-University Frankfurt, Germany"}], "title": "Efficient Classification by a Neural Network Approximation of Hierarchical Poisson Mixtures", "abstract": "In this work we investigate a functional aspect of an elementary feedforward neural network with feed-forward and lateral inhibition. The dual-layer network we study is based on earlier work which investigated a close relation between feed-forward inhibition and synaptic scaling [1]. The study analytically showed that a neural network with neurally plausible activation and learning rules approximates maximum likelihood learning of a generative Poisson mixture model. In [1] a Bayesian classifier for the output layer was defined to investigate the interplay between feed-forward inhibition and synaptic scaling.\n\nHere we extend the earlier work by adding a neurally plausible second layer which complements the neurally plausible first layer. The resulting hierarchical network is based on elementary neural update and learning rules, as it only depends on a small number of free parameters, and relates to a hierarchical Poisson mixture model. The second layer can be trained using small amounts of labeled data for classifying input patterns into basic categories (e.g., handwritten digits into classes from 0-9). We show that the capacity of the network can be scaled-up using a parallel online learning scheme which gradually adapts network weights by operating on batches of input patterns in a parallelized fashion. In this way, we can train networks with several thousands of neurons in the middle layer. In numerical simulations we investigate the functional capabilities of the networks using a standard database of handwritten digits (MNIST). For the setting with only a small fraction of labeled data points, we observe a classification accuracy which is comparable to state-of-the-art approaches such as Deep Belief Networks [2,3] or Restricted Boltzmann Machines [4,5].", "acknowledgements": "We acknowledge support from the German Research Foundation (DFG) in the project LU 1196/4-2 and the German Federal Ministry of Education and Research (BMBF), project 01GQ0840.", "id": 196629, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Dennis Forster"}, {"epithet": "1", "name": "Abdul-Saboor Sheikh"}, {"epithet": "1,2", "name": "J\u00f6rg L\u00fccke"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Keck, C et al. Feedforward Inhibition and Synaptic Scaling\u2013Two Sides of the Same Coin? PLoS Comp Bio 8(3) 2012\n[2] Hinton, GE et al. A fast learning algorithm for deep belief nets. Neural comp 18(7) 2006\n[3] Rifai, S et al. The manifold tangent classifier. NIPS 2011\n[4] Hinton, GE. Training products of experts by minimizing contrastive divergence. Neural comp 14(8) 2002\n[5] Salakhutdinov, R & Hinton, GE. Learning a nonlinear embedding by preserving class neighbourhood structure. AISTATS 2007"}, {"correspondence": ["Jakob.Macke@gmail.com"], "figid": 148, "doi": "10.12751/nncn.bc2013.0148", "affiliations": [{"index": "1", "address": "Gatsby Unit, UCL, London, United Kingdom"}, {"index": "2", "address": "Wolfson Institute for Biomedical Research, UCL, London, United Kingdom"}, {"index": "3", "address": "Department of Neuroscience, Physiology and Pharamcology, UCL, London, United Kingdom"}, {"index": "4", "address": "MPI for Biological Cybernetics and Bernstein Center T\u00fcbingen, Germany"}], "title": "Inferring interactions between cell types from multiple calcium imaging snapshots of the same neural circuit", "abstract": "Understanding the functional connectivity between different cell types and the resulting population dynamics is an important problem. Progress with in-vivo 2-photon population calcium imaging makes it possible to densely sample neural activity in superficial layers of a cortical patch. In principle, such data can be used to infer the functional (statistical) connectivity between classes of neurons by fitting models such as generalized linear models or latent dynamical systems. However, this approach faces 3 major challenges which we address: 1) only small populations of neurons can currently be simultaneously imaged at any given time; 2) the cell types of individual neurons are often unknown; and 3) it is unclear how to pool data across different animals to derive an average model.\n First, while it is not possible to simultaneously image all neurons in a cortical column, it is currently possible to image the activity of ~200 neurons at a time and to repeat this procedure at multiple depths. We present a computational method which allows us to \"stitch\" such non-simultaneously imaged populations into one large virtual population. Importantly - and surprisingly - this approach allows us to predict couplings and noise correlations even for pairs of neurons that were never imaged simultaneously. Second, we automatically cluster neurons based on similarities in their functional connectivity. Under the assumption that such functionally defined clusters can correspond to cell types, this enables us to infer both the cell types and their functional connectivity. Third, while connection profiles of individual cells in one class can be variable, we expect the \u2018average\u2019 influence of one cell class on another to be consistent across animals. We show how our approach can be used to pool measurements across different animals in a principled manner.. We demonstrate the utility of our computational tools by applying them synthetic data and to 2-photon imaging data of mouse cortex.", "acknowledgements": "We gratefully acknowledge support form the Gatsby Charitable Trust, European Research Council,  Wellcome Trust and the German Federal Ministry of Education and the German Federal Ministry of Education and Research (BMBF; FKZ: 01GQ1002).", "id": 196630, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Srinivas Turaga"}, {"epithet": "1", "name": "Lars Buesing"}, {"epithet": "2", "name": "Adam Packer"}, {"epithet": "2,3", "name": "Michael Hausser"}, {"epithet": "4", "name": "Jakob Macke"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["stephan.lancier@uni-tuebingen.de"], "doi": "10.12751/nncn.bc2013.0149", "affiliations": [{"index": "1", "address": "Cognitive Neuroscience, Dept. of Biology, University of T\u00fcbingen, Germany"}], "title": "Size vs Configuration of Visual Cues in Human Place Recognition ", "abstract": "The recognition of places can be based on a large number of visual cues such as raw snapshots [1], contrast edges [2], depth distribution, or recognized landmark objects [3]. In humans, most of these cues play a role but their interaction is poorly understood. Here we present an experiment crossing two possible cues for place recognition, image size (subtended visual angle) and image configuration (angular separation) of recognizable landmark objects. \nSubjects were trained in a virtual plus-maze, i.e. a plus-shaped bridge over a pond. Each navigation task involved a 90 degree turn at the centre of the bridge which was thus learned incidentally. Four coloured balls were placed as landmarks above the four quadrants formed by the bridge. In the test phase the pond and bridge were covered by ground fog. Subjects pressed a button when reaching the crossing point; this judgement had to be based exclusively on the four landmark objects. In a test condition, two adjacent landmarks were enlarged while the other two were downsized. If the judgements are based on the visual size of the landmarks, places further away from the enlarged landmarks and closer to the downsized landmarks should be selected. If, however, the complete snapshot is matched, the perceived angular separations between the landmarks should be more important and judgements should be close to the original location. Our results indicate that the majority (7/10) of subjects search at the shifted location where the image sizes match, whereas a minority (3/10) base their judgement on landmark angular separation (see figure). In addition, we found a systematic bias towards the center of gravity of the landmark configuration which is not predicted by snapshot theory.\n", "acknowledgements": "Supported by the German Federal Ministry of Education and Research (BMBF; FKZ: 01GQ1002).", "id": 196631, "topic": "Neural encoding and decoding", "figid": 149, "authors": [{"epithet": "1", "name": "Stephan Lancier"}, {"epithet": "1", "name": "Marc Halfmann"}, {"epithet": "1", "name": "Hanspeter Mallot"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Gillner S, Wei\u00df AM & Mallot HA (2008). Visual homing in the absence of feature-based landmark information. Cognition, 109(1), 105-122.\n[2] Cartwright BA & Collet TS (1983). Landmark Learning in Bees. Journal of Comparative Physiology, 151:521-543.\n[3] Morris RGM (1981). Spatial localization does not require the presence of local cues. Learning and Motivation, 12(2), 239-260."}, {"correspondence": ["s.shaker.barikhan@physik3.gwdg.de"], "doi": "10.12751/nncn.bc2013.0150", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Georg-August University G\u00f6ttingen, G\u00f6ttingen, Germany"}, {"index": "2", "address": "Department of Mechanical Engineering and Science, Graduate School of Engineering, Kyoto University, Kyoto, Japan"}], "title": "Adaptive multiple CPGs with phase reset and inhibition mechanisms for locomotor adaptation of a hexapod robot on irregular terrains", "abstract": "Central Pattern Generators (CPGs) are considered as one of the main mechanisms of locomotion. A conventional way to generate a gait from CPGs is based on the exploitation of interlimb neural connections and predefined phase relationships between legs. However, this conventional technique might not lead to the most suitable gait for a robot and adaptation. This is because the robot\u2019s body dynamics and interactions between body itself and the environment are often ignored.\n \nTo achieve adaptive locomotion considering body dynamics as well as body and environment interactions, Aoi et al. [1] developed a phase reset mechanism  that try to balance between predefined phase differences between right and left adjacent limbs and phase reset mechanism. Owaki et al. [2] presented a system with multiple CPGs and local sensory feedback exploiting the interactions as well as body dynamics to control a quadruped robot \u2018s locomotion. This system can derive different gaits corresponding to change in body properties, e.g., body weight. However, so far these previous works [1,2] have focused on locomotion only for flat terrain.\n\nIn our studies, we achieve adaptive locomotion by exploiting a combination of body dynamics, the interactions, and adaptive control. The controller consists of multiple adaptive CPGs and a local leg control mechanism which considers the difference between the desired Anterior Extreme Point (AEP) and the actual Leg Contact Point (LCP). The local leg control mechanism basically is used to modify the phase of each CPG by resetting or inhibiting it. In addition we used foot contact sensor signals for shaping motor commands. We applied the proposed technique to a simulated hexapod robot. The preliminary results show that the hexapod robot can adapt its gait in order to deal with irregular terrains (see Fig.1a). Besides, the adaptive gait generated by our controller also outperforms the standard one generated by a single conventional CPG (Fig.1b).", "acknowledgements": "This research was supported by Emmy Noether grant MA4464/3-1 of the Deutsche Forschungsgemeinschaft (DFG) and the Bernstein Center for Computational Neuroscience II G\u00f6ttingen (BCCN grant 01GQ1005A, project D1).\n", "id": 196632, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Subhi Shaker Barikhan"}, {"epithet": "2", "name": "Yuichi Ambe"}, {"epithet": "2", "name": "Fumitoshi Matsuno"}, {"epithet": "1", "name": "Florentin W\u00f6rg\u00f6tter"}, {"epithet": "1", "name": "Poramate Manoonpong"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Figure 1: (a) A simulated hexapod robot on irregular terrain. (b) The body trajectories of  the robot on the same terrain with two different controllers. The red line indicates the position of the robot controlled by a single CPG generating a tetrapod gait. The green line shows the position of the robot controlled by multiple CPGs with phase reset and inhibition mechanisms.  In this case, the controller also generates a tetrapod gait at beginning. It can be seen that using the single CPG controller the robot cannot maintain its body position in a straight line (i.e., body trajectory diverges from an initial position), while using our proposed controller which also considers body dynamics and body-environment interactions allows the robot to almost maintain its body position in a straight line (i.e., body trajectory is close to 1 which is an initial position).", "figpath": "150.png", "refs": "1) Aoi, S., Yamashita, T., & Tsuchiya, K. (2011). Hysteresis in the gait transition of a quadruped investigated using simple body mechanical and oscillator network models. Physical Review E, 83(6), 061909.\n2) Owaki, D., Kano, T., Nagasawa, K., Tero, A., & Ishiguro, A. (2012).  Simple robot suggests physical interlimb communication is essential for quadruped walking. Journal of The Royal Society Interface, 10.1098."}, {"correspondence": ["s.dasgupta@physik3.gwdg.de"], "figid": 151, "doi": "10.12751/nncn.bc2013.0151", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Georg-August-Universit\u00e4t G\u00f6ttingen, Germany"}], "title": " Active Memory in Input Driven Recurrent Neural Networks", "abstract": "Understanding the exact mechanism of learning and memory emerging from complex dynamical systems like neural networks serves as a challenging field of research. Traditionally the neural mechanisms underlying memory and cognition in these systems are described by steady-state or stable fixed point attractor dynamics. However an alternative and refined understanding of the neuronal dynamics can be achieved through the idea of transient dynamics [1] (reservoir computing paradigm) i.e., computation through input specific trajectories in neural space without stable equilibrium. Mathematical analysis of the underlying memory through such transient dynamics is difficult. As such information theory provides tools to quantify the dynamics of memory in such networks.\nOne such popular measure of memory capacity in reservoir networks is the linear memory capacity [2]. It provides an indication of how well the network can reconstruct delayed versions of the input signal. However it assumes a linear retrieval of input signal and deteriorates with neuron non-linearity. Alternatively, active information storage [3] provides a measure of local neuron memory by quantifying the degree of influence of past activity on the next time step activity of a neuron independent of neuronal non-linearity. In this work we further extend this quantity by calculating the mutual information between a neuron past activity and its immediate future activity while conditioning out delayed versions of the input signal. Summing over different delays of input signal it provides a suitable measure of total input driven active memory in the network. Intuitively active memory calculates the actual memory in use i.e. influence of input history on local neuron memory. We compare memory capacity and active memory (AM) with different network parameters for networks driven with statistically different inputs and justify AM as an appropriate means to quantify the dynamics of memory in input driven neural networks.", "acknowledgements": "This research was supported by the Emmy Noether Program (DFG, MA4464/3-1), the Federal Ministry of Education and Research (BMBF) by a grant to the Bernstein Center for Computational Neuroscience II G\u00f6ttingen (01GQ1005A, project D1) and the IMPRS for Physics of Biological and Complex Systems.", "id": 196633, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Sakyasingha Dasgupta"}, {"epithet": "1", "name": "Florentin W\u00f6rg\u00f6tter"}, {"epithet": "1", "name": "Poramate Manoonpong"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] M. Rabinovich, R. Huerta, G. Laurent (2008): Transient Dynamics for Neural Processing. Science, Vol. 321, No. 5885., pp. 48-50.  \n[2] H. Jaeger (2001): Short term memory in echo state networks. GMD Report 152, German National Research Center for Information Technology, 2001 (60 pp.)\n[3] S. Dasgupta, F. W\u00f6rg\u00f6tter, P. Manoonpong (2013): Information Dynamics based Self-Adaptive Reservoir for Delay Temporal Memory Tasks. Evolving Systems,doi:10.1007/s12530-013-9080-y \n "}, {"correspondence": ["degoldschmidt@yahoo.co.uk"], "doi": "10.12751/nncn.bc2013.0152", "affiliations": [{"index": "1", "address": "Georg-August-Universit\u00e4t G\u00f6ttingen, Bernstein Center for Computational Neuroscience, Germany"}], "title": "Adaptive Neural Obstacle Negotiation Control for Hexapod Robots", "abstract": "Neurobiological studies have revealed that insects are able to adapt leg and postural behavior in obstacle negotiation. This adaptability of motor behavior enables insects to respond to novel situations in an efficient way [1]. Optimizing the distance to an obstacle where an insect initiates climbing is shown to be crucial for the effective negotiation of an obstacle [2]. These findings motivated us to develop an adaptive neural controller that generates obstacle negotiation behavior in hexapod robots. Based on an existing CPG-based controller and leg reflex control for walking behavior [3], we extended the control system by an adaptive backbone joint control for efficient obstacle negotiation behavior. Part of the adaptive backbone joint control employs neural learning which enables the robot to adapt its postural behavior for obstacle negotiation with respect to varying obstacle heights and different walking gaits. The neural learning circuit for synapse plasticity is based on input correlation (ICO) learning. Correlations of ICO learning rely on an early, predictive signal and a late, reflex signal, both provided by long and short ranges of ultrasonic (US) sensors at the front of the robot, respectively. The output of the learning circuit controls the backbone joint (BJ) of the robot. As a result, the proposed controller  allows the robot to adapt the BJ motion for negotiate high obstacles like 10 cm (Fig. 1). At the beginning, the robot does not move its BJ and is thus unable to surmount the obstacle. By increasing the plastic synapses of the predictive signals (i.e., long range US sensor signals), the robot leans its front body up at an optimal distance from the obstacle to finally negotiate it. Besides increased robustness for climbing various obstacles, the robot also exhibits stick insect-like climbing behavior. We have developed and tested the controller first on a robot simulator, before successfully transferring it to our physical hexapod robot AMOSII.", "acknowledgements": "This research was supported by Emmy Noether grant MA4464/3-1 of the Deutsche Forschungsgemeinschaft (DFG) and the Bernstein Center for Computational Neuroscience II G\u00f6ttingen (BCCN grant 01GQ1005A, project D1).", "id": 196634, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Dennis Goldschmidt"}, {"epithet": "1", "name": "Florentin W\u00f6rg\u00f6tter"}, {"epithet": "1", "name": "Poramate Manoonpong"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Learning curve of a negotiation of an obstacle with a height of 10 cm. The plastic synapses \u03c11L,1R of the left and right US sensors (cyan and orange lines) change according to the ICO learning rule, i.e. due to correlations of the predictive signals (red lines) and the reflex signals (green lines). At the beginning of the experiment, the backbone joint (BJm, blue line) does not exhibit any behavior because of small weights \u03c11L,1R. During learning, the amplitude as well as the slope of the backbone joint motor output increases proportional to the increase of \u03c11L,1R (see light red colored area). After learning, \u03c11L,1R have converged towards values for which the robot performs an optimal backbone joint motion, i.e., an optimal leaning behavior. The convergence is due to the fact that the reflex signals do not occur after learning (see blue colored area). Raw data (USRaw) coming from the ultrasonic (US) sensors is also shown. The learning rate \u03bc is set to 0.5 for the experiment.", "figpath": "152.png", "refs": "[1] R. E. Ritzmann and A. B\u00fcschges, \u201cAdaptive motor behavior in insects,\u201d Curr Opin Neurobiol 17(6), 2007.\n[2] C. Harley, B. English, and R. Ritzmann, \u201cCharacterization of obstacle negotiation behaviors in the cockroach,\u201d J Exp Biol 212(10), 2009.\n[3] P. Manoonpong, U. Parlitz, and F. W\u00f6rg\u00f6tter, \u201cNeural control and adaptive neural forward models for insect-like, energy-efficient, and adaptable locomotion of walking machines,\u201d Front Neural Circuits 7: 12, 2013."}, {"correspondence": ["poramate@manoonpong.com"], "doi": "10.12751/nncn.bc2013.0153", "affiliations": [{"index": "1", "address": "Beijing University of Aeronautics and Astronautics, China"}, {"index": "2", "address": "Georg-August-Universit\u00e4t G\u00f6ttingen, Bernstein Center for Computational Neuroscience, Germany"}], "title": "Fault tolerant locomotion of a hexapod walking robot under neural control based on multiple chaotic CPGs and learning", "abstract": "Insects can perform various gaits for walking on different terrains. If their legs are damaged, they can adjust the frequencies of remaining legs individually for the damage compensation [1]. Biological and ethological studies reveal that the properties are achieved by their neural systems with multiple central pattern generators (CPGs) and sensory feedback \u200e[2]. In order to realize such properties in our hexapod walking robot AMOS, we extend our neural locomotion control with a single chaotic CPG [3] to multiple chaotic CPGs where each of which controls each leg (Fig. 1a). The CPGs can synchronize or desynchronize to perform uniform or distinguishing behavior. Without leg damage, the CPGs synchronize and their dynamics is identical (similar to a single CPG). Changing their periodic dynamics to different periods, the controller produces various walking patterns, like wave, caterpillar, tetrapod, and tripod gaits [3]. With leg damage, they release their synchronization leading to independent dynamics. In this condition, a simulated annealing-based learning mechanism is applied to adjust the remaining legs\u2019 oscillation frequencies in an online manner for leg damage compensation. The experimental results of real robot walking show that employing the multiple chaotic CPGs with the online learning mechanism allows the robot to perform self adaptation after leg damage (Fig. 1b). As a consequence, it can still move forward; thereby it can reach the end of a desired path (see http://manoonpong.com/BCCN2013/svideo.wmv) or approach a goal at front. In contrast, using a single CPG controller with leg damage, the robot has difficulty to move forward; thereby it fails to the task. This study suggests that biologically-inspired neural control based on multiple CPGs and learning presented here is an effective way to generate complex behaviors particularly when different body parts have to perform independent movements for damage compensation or achieving fault tolerant locomotion.", "acknowledgements": "This research was mainly supported by the Emmy Noether Program (DFG, MA4464/3-1) and BMBF by a grant to BCCN II Goettingen (01GQ1005A, project D1) and in part by National Natural Science Foundation of China under the project 61175108.", "id": 196635, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Guanjiao Ren"}, {"epithet": "1", "name": "Weihai Chen"}, {"epithet": "2", "name": "Sakyasingha Dasgupta"}, {"epithet": "2", "name": "Christoph Kolodziejski"}, {"epithet": "2", "name": "Florentin W\u00f6rg\u00f6tter"}, {"epithet": "2,*", "name": "Poramate Manoonpong"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Figure 1: (a) Six chaotic CPGs. The orange circles indicate the CPG units. The blue circles indicate the motor neurons of our hexapod walking robot AMOSII developed at BCCN G\u00f6ttingen in collaboration with Fraunhofer IAIS. Red lines represent the synchronization mechanism while green lines represent the signal spreading direction. There are one master CPG (CPG0 at the right front leg) and five client CPGs (CPG1,\u2026,5 at the remaining legs). (b) Self-adaptive walking with leg damage. The upper panel shows two snapshots which indicate walking behaviors before and after learning, respectively. Before learning, the robot failed to pass the tunnel while, after learning, the robot adapted it locomotion such that it could simply pass the tunnel (see supplementary video at http://manoonpong.com/BCCN2013/svideo.wmv). The lower panel shows the adapted gait. A blank row indicates a damaged leg. In this experiment, the R1 leg (right front leg) was damaged.", "figpath": "153.png", "refs": "1) M. Schilling, H. Cruse, and P. Arena, Hexapod walking: an expansion to WALKNET dealing with leg amputations and force oscillations, Biol Cybern 96(3), 2007.\n2) U. B\u00e4ssler and A. B\u00fcschges, Pattern generation for stick insect walking movements-multisensory control of a locomotor program, Brain Res Brain Res Rev 27(1), 1998.\n3) S. Steingrube, M. Timme, F. W\u00f6rg\u00f6tter, and P. Manoonpong, Self-organized adaptation of a simple neural circuit enables complex robot behaviour, Nature Physics 6(3), 2010."}, {"correspondence": ["riefsdahl@physik3.gwdg.de"], "doi": "10.12751/nncn.bc2013.0154", "affiliations": [{"index": "1", "address": "Third Institute of Physics - Biophysics, Georg-August-Universit\u00e4t G\u00f6ttingen, Germany"}, {"index": "2", "address": "Bernstein Center for Computational Neuroscience, G\u00f6ttingen, Germany"}], "title": "The effects of complex topologies and topological changes on Echo State Networks", "abstract": "Echo State Networks (ESNs) are recurrent neural networks, which apply rate-coded neuron models for reservoir computing. An input drives a reservoir with fixed recurrent connections, where only the output connections need to be trained. This simple principle has a surprisingly high computational power [1] and even provides a fading memory of the input signal. The performance of the network is influenced by the topology of the reservoir. Although the standard approach relies on random connections, there could be specific topologies that outperform a random network. \nThis work analyses the effects of different complex network topologies, such as scale-free networks and clustered networks [2], on the performance of ESNs on different benchmark tasks and compares them to a random network. The different topologies are evaluated with standard measures like the Normalised Root Mean Square Error (NRMSE), the Memory Capacity (MC) and information theoretic measures such as Transfer Entropy and Average State Entropy. \nPreliminary results suggest that the scale-free property and clustering do not implicate a general improvement for all measures, as the performance in terms of MC and NRMSE actually decreases for the non-random networks. This means that despite popular belief random networks after all still outperform some of the more sophisticated architectures. However, scale-free networks express an extended stability of MC in the regime of high spectral radii (see figure). Inspired by these non-trivial properties, future work will concentrate on introducing structural plasticity in standard ESNs for slow evolution of its network topology and investigate dynamic transition between different topological structures. Beyond that, research will be continued to evaluate which measures are effected by different topologies and which turn out to be robust against topological changes.", "acknowledgements": "This research was supported by the Emmy Noether Program (DFG, MA4464/3-1), the Federal Ministry of Education and Research (BMBF) through the BCCNII G\u00f6ttingen grant (01GQ1005A, project D1) and European Community's Seventh Framework Programme FP7/2007-2013 under grant agreement no. 270273 (Xperience).", "id": 196636, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Kolja Riefsdahl"}, {"epithet": "1,2", "name": "Sakyasingha Dasgupta"}, {"epithet": "1,2", "name": "Florentin W\u00f6rg\u00f6tter"}, {"epithet": "1,2", "name": "Poramate Manoonpong"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Memory capacity (MC) plotted against the spectral radius for three different network topologies: A random network, a clustered network consisting of six clusters and a scale-free network. Unlike for the random and the clustered network, the MC of the scale-free network does not drop for high spectral radii.\nThe experiments were performed with a reservoir of 300 neurons and one input neuron, which provides random input drawn form a uniform distribution from -1 to 1. All weights were chosen randomly from the same distribution. The connections from the input to the reservoir were set with a probability of 0.1 with 20% connectivity in the reservoir. Each data point was averaged over 100 independent runs.", "figpath": "154.png", "refs": "[1] H. Jaeger and H. Haas, \"Harnessing nonlinearity: predicting chaotic systems and saving energy in wireless communication\", Science, vol. 304, no 5667, pp 78-80, 2004, DOI 10.1126/science.1091277\n\n[2] S. Jarvis, S. Rotter, and U. Egert, \"Extending stability through hierarchical clusters in echo state networks\", Frontiers in Neuroinformatics, vol. 4, no. 11, 2010, DOI 10.3389/fninf.2010.00011"}, {"correspondence": ["schuetze@inb.uni-luebeck.de"], "figid": 155, "doi": "10.12751/nncn.bc2013.0155", "affiliations": [{"index": "1", "address": "Institute for Neuro- and Bioinformatics, University of L\u00fcbeck, Germany"}], "title": "Learning orthogonal bases for sparse coding", "abstract": "It is well known that natural images can be sparsely encoded if suitable bases are used [1]. Orthogonal and bi-orthogonal transforms are employed for image compression, e.g. the discrete cosine transform (DCT) for the JPEG standard, and the Cohen-Daubechies-Feauveau 9/7 wavelets (CDF97) for the JPEG2000 standard [2]. These transforms have been shown to be effective in representing an image by its k largest absolute transform coefficients (k-term approximation).\n\nWe here address the question of whether a sparsely encoding orthogonal basis can be learned, such as to provide a good k-term approximation. We present a preliminary version of our orthoSC algorithm, which is evaluated on natural and synthetic data. Our experiments with different natural image data sets show that the learned orthoSC bases are more similar to the PCA than to DCT or wavelet bases, when the orthoSC basis is initialized randomly. For synthetic data, orthoSC reliably learns the underlying orthogonal basis that generated the data.\n\nWe compare the average k-term compression performance for learned orthoSC bases with those for several other transform bases (PCA, DCT, Haar wavelets, CDF97). With an appropriate initialization, k-term compression performance with an orthoSC basis is better than with any alternative basis. Due to convergence issues, which remain to be solved, with a random initialization the performance decays, but is still better than conventional PCA and comparable to Haar wavelets.\n\nInterestingly, the k-term approximations in the PCA basis (k-term-PCA) are quite effective in encoding natural image patches. The k-term-PCA compression performance is not only higher than conventional PCA , but also higher than with Haar wavelets, and comparable to the JPEG standards (DCT and CDF97).", "acknowledgements": "The research is funded by the DFG Priority Programme SPP 1527, grant number MA 2401/2-1.", "id": 196637, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Henry Sch\u00fctze"}, {"epithet": "1", "name": "Erhardt Barth"}, {"epithet": "1", "name": "Thomas Martinetz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] B. A. Olshausen and D. J. Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 381:607--609.\n\n[2] Michael D. Adams. The jpeg-2000 still image compression standard.\nIn ISO/IEC JTC 1/SC 29/WG 1 N 2412, 2001."}, {"correspondence": ["kartheek.medathati@inria.fr"], "figid": 156, "doi": "10.12751/nncn.bc2013.0156", "affiliations": [{"index": "1", "address": "INRIA, Sophia Antipolis, France"}, {"index": "2", "address": "Institute de Neurosciences de la Timone, France"}], "title": "A retinotopic neural fields model of perceptual switching in 2D motion integration ", "abstract": "In perceptual multistability a fixed but ambiguous stimulus can invoke multiple interpretations although only one can be held at a time. Visual motion stimuli are inherently ambiguous, for instance due to the aperture problem, which makes motion perception a complex inference task. The underlying cortical dynamics that select one percept out of multiple competing possibilities are not fully understood. Recent studies by [1], [2] have tried to address this problem using the neural fields formalism. In [1] switching behaviour for a classical psychophysics stimulus, the multistable barberpole, was successfully captured in a feature-only, one-layer model of MT with adaptation and noise. However, without a representation of space, only some very specific stimulus could be considered. The work reported in [2] provides a much more general framework for motion integration in a two layer-model, however, it fails to capture the switching behaviour as the mechanisms of adaptation and noise were not considered. Building on the strengths of both studies, we propose a model that takes into account the spatial domain in a two-layer configuration whilst incorporating both adaptation and noise. Interactions between two layers processing local motion (V1 and MT) occurred through recurrent and lateral connections. The input stimuli are represented using direction of motion signals extracted using Reichardt detectors at corresponding 2D spatial locations. We use stimuli such as drifting bars and barberpoles to constrain the model to a suitable operating regime. In terms of computations, since the model is demanding we implemented it using GPUs, extending the methods of [3]. Based on this implementation, we study dynamics of the model focusing on coherency in plaid motion (plaids and crossed barber pole).", "acknowledgements": "1) This work was partially supported by the EC IP project FP7-ICT-2011-8 no. 318723 (MatheMACS)\n\n2)The research leading to these results has received funding from the European Union Seventh Framework Programme (FP7/2007- 2013) under grant agreement no. 269921 (BrainScaleS)\n", "id": 196638, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "N V Kartheek Medathati"}, {"epithet": "1", "name": "James Rankin"}, {"epithet": "1", "name": "Pierre Kornprobst"}, {"epithet": "2", "name": "Guillaume Masson"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1) J. Rankin, I. M. Andrew, G. S. Masson, O. Faugeras, and P. Kornprobst, Bifurcation study of a neural fields competition model with an application to perceptual switching in motion integration. INRIA Research Report-8220, 2013.\n2) E. Tlapale, G. S. Masson and P. Kornprobst. Modelling the dynamics of motion integration with a new luminance-gated diffusion mechanism. Vision Research, 2010.\n3) Javier Baladron. Exploring the neural codes with parallel hardware. Ph.D. Thesis, Univ. of Nice, 2013.\n"}, {"correspondence": ["jochen.braun@ovgu.de"], "doi": "10.12751/nncn.bc2013.0157", "affiliations": [{"index": "1", "address": "Center for Behavioral Brain Sciences, Magdeburg, Germany"}, {"index": "2", "address": "Istituto Superiore di Sanita`, Rome, Italy"}], "title": "Motion binding: quantitative characterization of energy landscapes", "abstract": "Visual perception exhibits numerous cooperative phenomena suggestive of attractor dynamics (e.g., (Buckthought, Kim, & Wilson, 2008)). Here we examined whether the perception of coherent motion in random-dot kinematograms (RDK) is consistent with the dynamics of a recurrently connected network, specifically, with an input-dependent family of \u2018energy landscapes\u2019 governing the evolution of state trajectories. Six observers viewed RDK in which the fraction of coherent dots followed an unpredictable random walk, reporting their initial and final percepts. Our results show extensive path-dependence (hysteresis) of the final percept as well as a broad bistable regime for intermediate coherence fractions. The first-order dynamical equation of a recurrently connected system (time-constant, non-linear feedback by general logistics function, and noise) was fully constrained by the detailed information from random walk trials. They revealed the \u2018energy landscape\u2019 governing activity dynamics at each coherence level. Our analysis showed that hysteresis in the perception of coherent motion is consistent with bistability (and not with inertia) and, for the first time, quantitatively characterizes the \u2018basin of attraction\u2019 around a cooperative perceptual state. This opens novel perspectives for reverse-engineering the effective recurrent connectivity of perceptual representations from dynamical observations.", "acknowledgements": "The authors were supported by the BMBF Bernstein Network of Computational Neuroscience and the State of Saxony-Anhalt.", "id": 196639, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Jochen Braun"}, {"epithet": "1", "name": "Guillermo Aguilar"}, {"epithet": "1", "name": "Alexander Pastukhov"}, {"epithet": "2", "name": "Maurizio Mattia"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "A) Experimental paradigm. Observers view continuous RDK for 5 s. Fraction F of coherent dots follows an unpredictable random walk. Observers report the initial and final appearance of coherent motion (if any). B,C,D) Path-dependence of motion percept (example). BC Random walk trials with low or high coherence at x=4.25 s (A and B, respectively) and intermediate coherence between 4.75 s and 5.0 s are grouped together, with final appearance indicated by color (red = coherent, blue = incoherent). Evidently, final appearance is strongly dependent on prior path, not merely on final coherence Fend. D Hysteresis loop assembled from many such observations (shaded area indicates significantly different appearance, Fisher\u2019s exact test). Together, hysteresis loops for different values of T0 provide a detailed and quantitative characterization of the path dependence of motion coherence. E,F,G) Input-\u00addependent energy landscape governing motion coherence. The random walk results constrain the first-\u00ad\u2010order dynamical equation of a coupled system, with feedback embodied in a nonlinear gain function (E). Optimal parameter fitting yields a fast activity dynamics (\u03c4 < 0.1 s) governed by an \u2018energy landscape\u2019 (F), which for a wide input range allows the coexistence of two attractor states (wells). This is illustrated in (G) where the probability density (contour shadings) of activity x is depicted for the whole range of F. Superimposed are the fixed points of the dynamics (red solid curve) and the landscape valleys (contour shadings). Coherent and incoherent percepts correspond to high and low levels of activity, respectively. For intermediate coherence levels (0.15 to 0.9), activity clusters around Up and Down states, indicating bistable perception. For lower or higher coherence levels, the system provides only a single attractor state. ", "figpath": "157.png", "refs": "Buckthought, A., Kim, J., & Wilson, H. R. (2008). Hysteresis effects in stereopsis and binocular rivalry. Vision research, 48(6), 819\u201330. doi:10.1016/j.visres.2007.12.013\n"}, {"correspondence": ["rcao.neurophys@gmail.com"], "doi": "10.12751/nncn.bc2013.0158", "affiliations": [{"index": "1", "address": "Department of Technologies and Health, Istituto Superiore di Sanita, Roma, Italy"}, {"index": "2", "address": "Cognitive Biology, Center for Behavioral Brain Sciences, Magdeburg, Germany"}], "title": "Analytical framework for collective dynamics of cortical columns", "abstract": "We propose a novel analytical framework for the collective dynamics of cortical columns. We assume that (i) individual columns transition spontaneously between active and inactive states, (ii) stimulation increases likelihood of active states, (iii) cooperative percepts (e.g., coherent motion) integrate activity over a population of columns, and (iv) perceptual onset occurs when population activity exceeds a fixed threshold. Described framework constitutes a known stochastic process. We have obtained analytically all moments of the distribution (FPTD) of first-passage-times (times between stimulation onset and threshold crossing). Our analysis predicts mean and shape of FPTD as a function of spontaneous, stimulated, and threshold levels of activity. In low-threshold regimes, stimulated levels alter mean, but not shape, of the FPTD. This is because the mean is mainly a \u2018local effect\u2019 (coupling between stimulation and active times), while the shape is a \u2018collective effect\u2019 (spontaneous and threshold levels of activity). Intriguingly, the predicted dissociation is mirrored by the empirical distribution of dominance periods in multi-stable displays, where modified display alters the mean of the distribution ten-fold, while leaving distribution shape unchanged (coefficient of variation ~ 0.6, skewness ~ 1.2). Accordingly, we propose that the stimulus-dependence of dominance periods reflects the collective dynamics of cortical columns.", "acknowledgements": "The authors were supported by the BMBF Bernstein Network of Computational Neuroscience and the State of Saxony-Anhalt.", "id": 196640, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Robin CAO"}, {"epithet": "2", "name": "Alexander PASTUKHOV"}, {"epithet": "2", "name": "Jochen BRAUN"}, {"epithet": "1", "name": "Maurizio MATTIA"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "A,B) Framework for modeling collective dynamics. An individual column (A) transitions spontaneously between inactive and active states. Rates \u03bd+ and \u03bd- change with stimulation. Collective activity of a population of columns (B) evolves stochastically from its spontaneous level x0 towards a threshold level x\u03b8, following onset of stimulation. The stimulated steady-state xss = \u03bd+/(\u03bd++\u03bd-) lies above x\u03b8 and is never reached. The time-constant is \u03c4= 1/(\u03bd++\u03bd-). We consider first-passage times T1,2,3 and their distribution (FPTD). C,D,E) Analytical prediction of FPTD (\u2018collective effects\u2019). Moments of the FPTD vary with the spontane-ous level x0, threshold level x\u03b8, and stimulated steady-state xss of activity. Above we illustrate the first three moments \u03bc1,2,3 in terms of \u03bc1/\u03c4 (C), coefficient of variation Cv=\u03bc21/2/\u03bc1 (D) and skewness \u03b3=\u03bc3/\u03bc23/2 (E). The typical distribution shapes of multi-stable perception (Cv=0.6, \u03b3=1.2) are obtained only in a low-threshold, high-stimulation regime (thick lines converging at lower right). F) Coupling of rates to stimulation (\u2018local effects\u2019). The coupling between time-scale \u03c4 and stimulated level xss reflects \u2018local effects\u2019 and introduces one additional degree of freedom. The rates follow as \u03bd+= xss/\u03c4 and \u03bd-= (1- xss)/\u03c4. G,H) Comparison to empirical FPTD. Together, \u2018local\u2019 and \u2018collective effects\u2019 match the empirical dependence of FPTD on stimulation. Above, theoretical values of \u03bc1, coefficient of variation Cv (G, black lines), and skewness \u03b3 (H, black lines) are compared to empirical values (binocular rivalry, crosses).", "figpath": "158.png", "refs": ""}, {"correspondence": ["konda@informatik.uni-frankfurt.de"], "doi": "10.12751/nncn.bc2013.0160", "affiliations": [{"index": "1", "address": "Goethe-University Frankfurt, Germany"}, {"index": "2", "address": "University of Montreal, Canada"}], "title": "Boltzmann machines with dendritic gating", "abstract": "The gated Boltzmann machine (GBM) is a recent approach to learning representations of motion from frames in a video by encoding prevalent patterns of correlation between the pixels across frames [1]. Since the model needs to account for potential correlations between each pixel pair, and since videos typically contain as many transformations as there are pixels in each frame (and often more), the computational complexity of the GBM is cubic in the number of pixels.\n\nIn this work we present a variation of the GBM, whose complexity is linear in the number of pixels. To this end we learn projections of the frames, such that correlation patterns between only a small number of the projections suffice to learn representations of motion.  Our work is similar to the recently introduced ``factored'' GBM [2], but in contrast to that work, it is a single-layer model that can be trained using local, Hebbian learning rules.\n\nWe also show that, when the number of projections is small and the units encoding the projections are arranged in space, such that nearby units share features from which they receive input, then features self-organize into ``pinwheels'' with similar frequencies and orientations occupying similar regions in space. In contrast to related recent work on the emergence of pinwheels [3], our model relies only on local learning rules in conjunction with spatially constrained ``gating'' interactions.\n\nWe evaluate the model on a variety of motion understanding tasks. We show that the model yields competitive performance and that it can outperform the factored GBM by a large margin.\n", "acknowledgements": "This work was supported in part by the German Federal Ministy of Education and Research (BMBF) in project 01GQ0841 (BFNT Frankfurt)", "id": 196641, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Kishore Konda"}, {"epithet": "2", "name": "Roland Memisevic"}, {"epithet": "1", "name": "Vincent Michalski"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Topography via dendritic gating", "figpath": "160.png", "refs": "[1] Memisevic, Roland, and Geoffrey Hinton. \"Unsupervised learning of image transformations.\" Computer Vision and Pattern Recognition, 2007. CVPR'07. IEEE Conference on. IEEE, 2007.\n[2] Memisevic, Roland, and Geoffrey E. Hinton. \"Learning to represent spatial transformations with factored higher-order boltzmann machines.\" Neural Computation 22.6 (2010)\n[3] Bauer, Felix, and Roland Memisevic. \"Feature grouping from spatially constrained multiplicative interaction.\" arXiv preprint arXiv:1301.3391"}, {"correspondence": ["mlynar@mis.mpg.de"], "figid": 161, "doi": "10.12751/nncn.bc2013.0161", "affiliations": [{"index": "1", "address": "Max Planck Institute for Mathematics in the Sciences, Germany"}], "title": "Intermediate Level Representations Of Natural Auditory Scenes", "abstract": "Natural auditory environment consists of multiple objects varying their spatial configuration while generating complex waveforms. The auditory system manages to reconstruct the auditory scene based on information present in two one-dimensional sound waveforms perceived via the left and the right ear. Spatial information is provided by between-ear disparities - binaural phase (IPD) and level (ILD) differences in addition to position-specific modulation of sound spectra. Under natural stimulation, spatial cues reveal correlations along the cochleotopic axis reflecting the structure of natural sounds, as well as temporal correlations due to the motion of sound sources.\nThis work attempts to model the rich structure of natural auditory scenes. It proposes a hierarchical generative model of binaural sounds recorded in a fully natural setting. The model consists of two layers of latent coefficients learned separately. The first layer forms a sparse, complex valued representation of waveforms in both ears using a dictionary of parametric basis functions adapted to the data. This allows for extraction and separation of phase and amplitude information. The second layer learns interaural phase and amplitude dependencies via sparse coding on the first layer outputs. Higher-level components represent structure present in the signal due to the sound waveform variability as well as spatial aspects of the environment. The processing hierarchy can be interpreted as a statistical  analogy of binaural processing by midbrain nuclei in mammals. \n", "acknowledgements": "", "id": 196642, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Wiktor Mlynarski"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["c.bachmann@fz-juelich.de"], "doi": "10.12751/nncn.bc2013.0162", "affiliations": [{"index": "1", "address": "Inst. of Neuroscience and Medicine (INM-6) and Inst. for Advanced Simulation (IAS-6), J\u00fclich Research Centre and JARA, Germany"}, {"index": "2", "address": "Simulation Laboratory Neuroscience \u2013 Bernstein Facility Simulation and Database Technology, Institute for Advanced Simulation, J\u00fclich Aachen Research Alliance, J\u00fclich Research Centre, Germany, Germany"}, {"index": "3", "address": "Bernstein Center Freiburg, Albert-Ludwigs University, Freiburg, Germany"}], "title": "Impact of Alzheimer's Disease on the computational and dynamical properties of recurrent neural circuits. ", "abstract": "Cognitive functions such as perception, memory, association, classification or prediction of dynamical systems can be realized by recurrent networks of simple model neurons [1,2,3]. In Alzheimer's Disease, there is a clear positive correlation between synapse loss and cognitive impairment [4]. However, the mechanisms underlying this correlation are so far poorly understood. Here, we investigate how the loss of excitatory synapses in sparsely connected random networks of spiking excitatory and inhibitory neurons [5] affects their dynamical and computational properties. By means of simulations, we study the network response to noisy realizations of multidimensional input spike-train templates.  We observe that a loss of excitatory synapses on excitatory neurons (decrease in excitatory-excitatory indegree; vertical arrow in the figure) reduces the network's sensitivity to perturbations of time-varying input streams, improves its ability to generalize and impairs its discrimination capability [6]. Homeostasis, implemented as an up-scaling of the remaining excitatory-excitatory synapses to preserve the average firing rate, recovers the network performance (horizontal arrow in the figure). This provides a potential explanation for the delayed onset of clinical symptoms with respect to the onset of cortical damage: the performance of cortical networks only starts to drop when the homeostatic mechanisms are exhausted.", "acknowledgements": "Supported by the Helmholtz Alliance on Systems Biology, the Helmholtz Association in the Portfolio theme \"Supercomputing and Modeling for the Human Brain\", the J\u00fclich Aachen Research Alliance (JARA), the Next-Generation Supercomputer Project of MEXT, EU Grant 269921 (BrainScaleS), the Junior Professor Program of Baden-W\u00fcrttemberg and the Initiative and Networking Fund of the Helmholtz Association.", "id": 196643, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Claudia Bachmann"}, {"epithet": "1", "name": "Tom Tetzlaff"}, {"epithet": "2", "name": "Susanne Kunkel"}, {"epithet": "3", "name": "Philipp Bamberger"}, {"epithet": "1", "name": "Abigail Morrison"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Loss of excitatory-excitatory synapses (vertical arrow) impairs discrimination capability (gray coded). Recovery of discrimination capability by firing-rate homeostasis (scaling up remaining excitatory-excitatory synapses; horizontal arrow).", "figpath": "162.png", "refs": "1. JJ Hopfield PNAS 1982, 79(8):2554-2558. \n2. H Jaeger, H Haas. Science 2004, 304:78-80. \n3. W Maass, T Natschlaegel, H Markram  Neural Comput 2002, 14(11):2531-2560.\n4. RD Terry, E Masliah, DP Salmon, N Butters, R DeTeresa, R Hill, LA Hansen, R Katzman Ann Neurol 1991, 30(4):572-80. \n5. N Brunel J Comput Neurosci 2000, 8(3):183-208.\n6. R Legenstein, W Maass Neural Netw 2007, 20(3):323-334."}, {"correspondence": ["y.chua@fz-juelich.de"], "figid": 163, "doi": "10.12751/nncn.bc2013.0163", "affiliations": [{"index": "1", "address": "Institute of Neuroscience and Medicine (INM-6), Juelich Forschungszentrum, Juelich, Germany"}, {"index": "2", "address": "Bernstein Centre Freiburg, Albert-Ludwigs University, Freiburg im Breisgau, Germany"}, {"index": "3", "address": "Institute for Cognitive Neuroscience, Psychology faculty, Ruhr University of Bochum, Germany"}], "title": "Calcium current makes LIF neuron with conductance synapses a better coincidence detector", "abstract": "Dendritic spikes are known to improve efficacy of synaptic inputs in causing action potentials [1]. The Calcium spike at distal apical dendrites of layer 5 pyramidal neuron has been observed in-vitro and argued to help forward propagation of synaptic inputs at distal tufts [2]. When combined with a backpropagating action potential, a smaller distal current is required to trigger the Calcium spike [3]. \nSuch a calcium spike has been modeled before in multi-compartment point neuron models using first order kinetics [4]. In our work, we show that such a spike, under the fluctuation driven regime can be approximated by a threshold triggered alpha function current. The exact contribution of the Calcium spike to somatic membrane potential can be analytically derived. We also improved on the analysis by taking into account correlation between membrane potential and conductances.\nWe next show in numerical simulations carried out with NEST [5] that the Calcium spike greatly improves the efficacy of distal coincident inputs in causing high frequency action potentials or burst, while the improvement becomes significantly less for the same amount of coincident inputs but shared by the somatic and distal compartments.", "acknowledgements": "Supported by Helmholtz Alliance on Systems Biology, Helmholtz Association in the Portfolio theme \"Supercomputing and Modeling for the Human Brain\", J\u00fclich Aachen Research Alliance (JARA), Junior Professor Program of Baden-W\u00fcrttemberg and Initiative and Networking Fund of the Helmholtz Association.", "id": 196644, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Yansong Chua"}, {"epithet": "1", "name": "Moritz Helias"}, {"epithet": "1,2,3", "name": "Abigail Morrison"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Williams, S.R., et al. Science, March 2002.\n[2] Larkum, M.E., et al. Journal of Physiology, 2001.\n[3] Larkum, M.E., et al. Nature, March 1999.\n[4] Larkum, M.E., et al. Cerebral Cortex, October 2004.\n[5] Gewaltig, M., et al. (2007) NEST (Neural Simulation Tool), Scholarpedia, 2(4):1430.\n"}, {"correspondence": ["j.jitsev@fz-juelich.de"], "doi": "10.12751/nncn.bc2013.0164", "affiliations": [{"index": "1", "address": "Institute for Neuroscience and Medicine (INM-6), Computational and Systems Neuroscience & Institute of Advanced Simulation (IAS-6), Theoretical Neuroscience, Research Center J\u00fclich, J\u00fclich, Germany"}, {"index": "2", "address": "Max-Planck-Institute for Neurological Research, Cortical Networks Group, Cologne, Germany"}], "title": "Functional role of opponent, dopamine modulated D1/D2 plasticity in prediction error-driven reinforcement learning in the basal ganglia", "abstract": "Here, we introduce a spiking actor-critic network model of learning from both reward and punishment in the basal ganglia. Both the dorsal (actor) and ventral (critic) striatum are assumed to contain populations of D1 and D2 medium spiny neurons (MSNs). In the ventral striatum, this allows separate representation of both positive and negative expected outcomes by respective D1/D2 MSN populations, which we hypothesize to reside in the shell part of the Nucleus Accumbens. The positive and negative outcome expectations are fed to dopamine (DA) neurons in VTA region, which compute and signal total prediction error by DA release. Based on recent experimental work [1], DA level is assumed to modulate plasticity of D1 and D2 synapses in opposing way, inducing LTP on D1 and LTD on D2 synapses if being high and vice versa if being low. Crucially, this form of opponent plasticity implements temporal-difference (TD)-like update of both positive and negative outcome expectations and performs appropriate adaptation of action preferences.\n\nWe implemented the network in the NEST simulator [2] using leaky integrate-and-fire spiking neurons, and designed a battery of experiments in various grid world tasks. Across the tasks the network can learn both to approach the delayed rewards while consequently avoiding punishments, which posed severe difficulties for the previous model without D1/D2 segregation [3]. The model highlights thus the functional role of D1/D2 MSN segregation within the striatum in implementing appropriate TD-like learning from both reward and punishment and explains necessity for opponent direction of DA-dependent plasticity found at synapses converging on distinct striatal MSN types. The approach can be further extended to study how abnormal D1/D2 plasticity may lead to a reorganization of the basal ganglia network towards pathological, dysfunctional states, like for instance those observed in Parkinson disease under condition of progressive dopamine depletion.", "acknowledgements": "Supported by the Helmholtz Alliance on Systems Biology, the Helmholtz Association \"Supercomputing and Modeling for the Human Brain\", the German Research Foundation (DFG, clinical research unit KFO 219), the J\u00fclich Aachen Research Alliance (JARA) and the Junior Professor Program of Baden-W\u00fcrttemberg.", "id": 196645, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Jenia Jitsev"}, {"epithet": "2", "name": "Nobi Abraham"}, {"epithet": "2", "name": "Marc Tittgemeyer"}, {"epithet": "1", "name": "Abigail Morrison"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "A spiking neural network model of basal ganglia circuit for prediction error-driven reinforcement learning with opponent, DA-modulated D1/D2 MSN plasticity ", "figpath": "164.png", "refs": "[1] Shen, W., Flajolet, M., Greengard, P. and Surmeier, D. J. Dichotomous dopaminergic control of striatal synaptic plasticity. Science, 2008, 321, 848-851\n[2] Gewaltig M-O and Diesmann M (2007). NEST, Scholarpedia 2(4):1430\n[3] Potjans, W., Diesmann, M. and Morrison, A. An imperfect dopaminergic error signal can drive temporal-difference learning. PLoS Comput. Biol., 2011, 7\n"}, {"correspondence": ["thomas.muench@cin.uni-tuebingen.de"], "figid": 165, "doi": "10.12751/nncn.bc2013.0165", "affiliations": [{"index": "1", "address": "Center for Integrative Neurosciences, Bernstein Center, University T\u00fcbingen, Germany"}], "title": "Automated Behavioral Testing Procedure of Visual Performance Based on the Optokinetic Reflex", "abstract": "Testing the optokinetic reflex (OKR) is an established method to evaluate visual performance in a simple and rapid way. The OKR manifests itself in an involuntary head and eye movement, triggered for example by a moving regular stripe pattern. We set up an enhanced virtual optokinetic drum, consisting of 4 computer monitors, onto which visual stimuli can be presented with high flexibility, making it easy to modulate the stimulus parameters (contrast, spatial resolution). By online monitoring the position of a moving animal, we adapt the stimulus to the current head position. This enables us to keep the spatial frequency of the presented stimulus constant despite of varying head-screen-distances. We also implemented an automated tracking system to monitor the animals head movements. Furthermore we combined this with an automated analysis and thus objective algorithm to score animal behaviour. \nTo evaluate the algorithm of our analysis we compared manual assessment of the animal\u2019s behavior with the result of our automated scoring procedure. There was a high degree of correlation, verifying the reliability of our method. As a proof of concept we reproduced the known contrast sensitivity function of mice. We tested the visual performance of wild type (C57Bl/6) as well as the influence of age in retinal degenerated mice (rd10). Here we compared rd10 mice (n=7) of 2 different age groups (P24-P32 vs. P86 to P91). As expected young rd10 mice had significantly better spatial resolution than old rd10 mice and were able to see even low contrasts. \n", "acknowledgements": "", "id": 196646, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Boris Benkner"}, {"epithet": "1", "name": "Thomas A. M\u00fcnch"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["thomas.muench@cin.uni-tuebingen.de"], "figid": 166, "doi": "10.12751/nncn.bc2013.0166", "affiliations": [{"index": "1", "address": "Center for Integrative Neurosciences, Bernstein Center, University T\u00fcbingen, Germany"}], "title": "Culturing of post-mortem Human Retina for Optogenetic Treatments", "abstract": "Loss of vision means a substantial impairment in the quality of life. Optogenetics is a promising tool for restoring vision after retinal degeneration. So far, most optogenetic approaches are developed and tested in animal models. Towards clinical translation, one should test cell type specific expression and functional restoration in human retina. This would allow better assessing the efficacy of novel treatments in restoring the diversity of human visual processing, and ruling out some side-effects before clinical trials. \nWe tested if human retinal tissue, obtained from enucleations (ex-vivo) and cornea donations (post mortem), is suitable for in vitro approaches, can be kept alive in culture and can be used to evaluate the benefits and risks of different treatment strategies.\nIt is assumed that retinal ganglion cell (RGC) death begins after 2 hours, and is completed after 6 hours. Here we first investigated the influence of ischemia on retina and evaluated whether post-mortem tissue can be used for our studies. We set up and optimized tissue culture conditions with the goal to assess optogenetic approaches in the human retina in-vitro. We used electrophysiological recordings and trypan blue stainings to evaluate the condition of the tissue. Finally, lentiviral techniques have been established for visual restoration approaches.\nWe could record spontaneous activity from human RGCs from tissue donated up to 25 hours post mortem. Retinal tissue that was brought into culture immediately after enucleation stayed light responsive for at least 48 (mouse), 72 (pig), and 24 (human) hours. Post mortem human retina showed spontaneous ganglion cell activity for at least 96h in culture.  \nWe established tissue culture conditions to maintain the retina in healthy physiological state for several days. This time period should be sufficient for lentivirus-mediated plasmid expression so that first optogenetic approaches can be assessed in this human in-vitro system.", "acknowledgements": "", "id": 196647, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Marion Mutter"}, {"epithet": "1", "name": "Katja Reinhard"}, {"epithet": "1", "name": "Natalia \u015awi\u0119tek"}, {"epithet": "1", "name": "Thomas A. M\u00fcnch"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["thomas.muench@cin.uni-tuebingen.de"], "figid": 167, "doi": "10.12751/nncn.bc2013.0167", "affiliations": [{"index": "1", "address": "Center for Integrative Neurosciences, Bernstein Center, University T\u00fcbingen, Germany"}], "title": "Studying circuit-level function of human retina in vitro", "abstract": "Retinal information processing has been characterized in many animal models. Specialized circuits for color vision, movement direction detection, approach sensitivity etc. have been described. However, except for a short communication by Weinstein and colleagues in 1971 [1], no physiological in-vitro data from human retina has been published. It is often alleged that sophisticated image processing is a hallmark of lower mammalian retina and might be absent in human retina. We thus aimed at studying human retina function on cell and system levels in-vitro. \nHuman retinal tissue was donated by patients who had to undergo enucleation at the University Hospital T\u00fcbingen. We placed retinal pieces ganglion cell side-down on a 60-electrode multi-electrode array (MEA), and stimulated the retina with various light stimuli such as steps of different contrast, white-noise-flicker, bars moving in eight directions, drifting sine wave gratings, chirp, and natural movies. During stimulation, we recorded from ganglion cells, and in 7 out of 12 donated retinas we could measure light responses. The recorded cells showed various properties such as different polarity (ON, OFF, ON-OFF), and distinct spatial and temporal tuning. The measured responses from the 60-electrode MEAs provide a glimpse into the diversity of the information processing in the human retina, but do not yet allow clear identification of cell types. Thus, in order to record from every ganglion cell within a small retinal patch, we recently implemented a high-density MEA with 11011 electrodes [2], and performed a first successful measurement with human retina. \nWe showed that different functional types of ganglion cells can be recorded in-vitro in human retinas obtained from patients. In the future, acquired expertise, improved collaboration with the eye clinic, and the use of high-density MEAs will allow further comprehensive characterization of human retinal ganglion cell types.", "acknowledgements": "We would like to thank Prof. K. U. Bartz-Schmidt and the operating team of the University Eye Hospital T\u00fcbingen for the great collaboration for the donation process, and Prof. A Hierlemann (D-BSSE, ETH Z\u00fcrich, Basel) for providing the high-density MEA system.", "id": 196648, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Katja Reinhard"}, {"epithet": "1", "name": "Thomas A. M\u00fcnch"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Weinstein GW, Hobson RR, Baker FH. Extracellular recordings form human retinal ganglion cells. Science 1971; 171(975): 1021\u20132.\n[2] Frey U, Eger U, Heer F, Hafizovic S, Hierlemann A. Microelectronic system for highresolution mapping of extracellular electric fields applied to brain slices. Biosens Bioelectron 2009; 24: 2191\u20138."}, {"correspondence": ["thomas.muench@cin.uni-tuebingen.de"], "figid": 169, "doi": "10.12751/nncn.bc2013.0169", "affiliations": [{"index": "1", "address": "Center for Integrative Neurosciences, Bernstein Center, University T\u00fcbingen, Germany"}], "title": "Expanding the operational range of channelrhodopsin", "abstract": "Optogenetics is mostly applied in neuroscience where optogenetically targeted neurons are activated (or inhibited) with exogenous light sources. These experimental conditions determine to a large extent which properties of ChR are considered \"ideal\", and efforts of engineering ChR have been guided by these assumptions.\nOptogenetics is also used for vision restoration. There, neurons in the retina are targeted to restore light sensitivity after the photoreceptors have died. Animal experiments have shown that this is a valid and highly promising strategy to treat blindness. However, the properties of existing variants of ChR are not ideal to support vision restoration: The properties of the target neurons (retinal neurons are mostly non-spiking) and of the light stimulus (gradual brightness changes over many log units in the environment) are fundamentally different from the common situation in laboratory optogenetic experiments.\nHere, we use a computational model of ChR's photocycle to explore its properties that would support \"optogenetic vision\" better than currently existing variants. We pay particular attention to expanding the operational range of optogenetic vision, i.e. the environmental brightness range over which appropriately treated retina might be functional. We suggest several strategies that may lead to a more than 2-fold expansion of the operational range compared to current approaches. We found that \"ideal\" properties of ChR for optogenetic vision can be the opposite of the \"ideal\" properties for basic science application. Our results can therefore serve as a basis to designing new variants of ChR that better support vision restoration. At the same time, our model also casts a spotlight on the biophysical limitations of what is possible with ChR alone. To overcome these limitations in the future, we will either need to make use of technological aids like image intensifiers, or develop substantially different optogenetic tools.", "acknowledgements": "", "id": 196650, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Thomas A. M\u00fcnch"}, {"epithet": "1", "name": "Marion Mutter"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["alex.susemihl@bccn-berlin.de"], "figid": 170, "doi": "10.12751/nncn.bc2013.0170", "affiliations": [{"index": "1", "address": "Fu Berlin, BCCN Berlin, Germany"}, {"index": "2", "address": "TU Berlin, BCCN Berlin, Germany"}, {"index": "3", "address": "FU Berlin, BCCN Berlin, Germany"}], "title": "Learning dynamic receptive fields from natural image sequences with autoencoded Temporal Restricted Boltzmann Machines", "abstract": "In their natural environment, animals experience a complex and dynamic visual scenery. Under such natural stimulus conditions, neurons in the visual cortex employ a spatially and temporally sparse code (Dan et al., 1996; Vinje and Gallant, 2000; Reinagel and Reid, 2002; Haider et al., 2010; Martin and Schr\u00f6der, 2013). For the input scenario of natural still images, previous work demonstrated that unsupervised feature learning combined with the constraint of sparse coding can predict physiologically measured re- ceptive fields of simple cells in the primary visual cortex (Olshausen et al., 1996). This convincingly indicated that the mammalian visual system is adapted to the natural spatial input statistics. Here, we extend this approach to the time domain in order to predict dynamic receptive fields that can account for both, spatial and temporal sparse activation in biological neurons. We rely on temporal restricted Boltzmann machines (Sutskever and Hinton, 2007) and suggest a novel temporal autoencoding training procedure. When tested on a dynamic multivariate benchmark data set (Taylor et al., 2007) this method outper- formed existing models of this class. Learning features on a large dataset of natural movies allowed us to model spatio-temporal receptive fields for single neurons. They resemble temporally smooth transformations of previously obtained static receptive fields and are thus consistent with existing theories. A neuronal spike response model demonstrates how the dynamic receptive field facilitates temporal and population sparseness. We discuss the potential mechanisms and benefit of a spatially and temporally sparse representation of natural visual input.", "acknowledgements": "We thank Bj\u00f6rn Kampa and Manfred Opper for comments. The work of CH and AS was supported by the DFG research training group GRK 1589/1", "id": 196651, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Chris H\u00e4usler"}, {"epithet": "2", "name": "Alex Susemihl"}, {"epithet": "3", "name": "Martin Nawrot"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Dan, Y., et al. (1996). The Journal of Neuroscience, 16(10):3351\u2013 3362.\nHaider, et al. (2010). Neuron, 65(1):107.\nMartin, K. A. and Schr\u00f6der, S. (2013). The Journal of Neuroscience, 33(17):7325\u20137344.\nOlshausen, B. et al. (1996). Nature, 381(6583):607\u2013609.\nReinagel, P. and Reid, R. (2002). The Journal of neuroscience, 22(16):6837\u20136841.\nSutskever, I. and Hinton, G. (2007). AISTATS\nTaylor, G., et al. (2007). NIPS\nVinje, W. and Gallant, J. (2000). Science, 287(5456):1273\u20131276."}, {"correspondence": ["rinaldo.betkiewicz@bccn-berlin.de"], "figid": 171, "doi": "10.12751/nncn.bc2013.0171", "affiliations": [{"index": "1", "address": "Neuroinformatics & Theoretical Neuroscience, Institute of Biology, Freie Universit\u00e4t Berlin. Bernstein Center for Computational Neuroscience Berlin, Germany"}], "title": "Inhibitory Structure Promotes Winnerless Competition In a Spiking Model of the Antennal Lobe", "abstract": "The insect olfactory system is a suitable model for studying general principles of sensory processing. Odors evoke complex spatio-temporal responses in the first processing stage, the Antennal Lobe (AL). The AL is characterized by projection neurons (PN) receiving lateral input from inhibitory interneurons [1]. When these inhibitory neurons exhibit winnerless competition (WLC) the evoked population activity in the AL can be described as a heteroclinic phase space orbit, a saddle attractor sequence that corresponds to a spatiotemporal pattern of activation [2]. However, understanding the relation between a heteroclinic orbit and the structure of a complex, realistic network is a challenge in current research [3]. We base our approach on a reduced model of the AL in the theoretical framework of dynamical system to describe how odors are encoded in spatio-temporal spiking activity.  \n\nHere we investigate spiking neural networks following robust heteroclinic orbits. We show how WLC dynamics is caused by either structure in the lateral connections, or structure in the input clusters and investigate the emergence and stability of a heteroclinic orbit in a constrained inhibitory network. In our description, clusters in the input are reflected in the functional connectivity between competing neuronal ensembles. We show that the number of input clusters determines the number of possible heteroclinic orbits.\n\nWe choose the insect olfactory system because it system shares suitable and accessible characteristic features across species, implementing key principles on different scales (brain size). We use homologies of the inhibitory AL Network, to discuss the stimulus encoding and capacity dependence on the network size N. Linking function to structure in a realistic spiking model, opens a perspective on a new class of paradigms in structure-dynamics interaction in neuronal systems.", "acknowledgements": "German Ministry of Education and Research (BMBF) through grant 01GQ0941 to the project Insect Inspired Robots within the BFNL program. R.B. is supported through the Research Training Group Sensory Computation in Neural Systems (GRK 1589) funded by the German Research Foundation (DFG)", "id": 196652, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Rinaldo Betkiewicz"}, {"epithet": "1", "name": "Farzad Farkhooi"}, {"epithet": "1", "name": "Martin Paul Nawrot"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Nawrot, M. P. (2012). Dynamics of sensory processing in the dual olfactory pathway of the honeybee. Apidologie.\n[2] Rabinovich et al. (2001). Dynamical Encoding by Networks of Competing Neuron Groups: Winnerless Competition. PRL 87(6)\n[3] Assisi, C., Stopfer, M., & Bazhenov, M. (2011). Using the structure of inhibitory networks to unravel mechanisms of spatiotemporal patterning. Neuron, 69(2)"}, {"correspondence": ["lazarov@nld.ds.mpg.de"], "figid": 172, "doi": "10.12751/nncn.bc2013.0172", "affiliations": [{"index": "1", "address": "Max Planck Instiute for Dynamics and Self-Organization, G\u00f6ttingen, Germany"}, {"index": "2", "address": "The Hebrew University of Jerusalem, Rehovot, Israel"}, {"index": "3", "address": "Bernstein Center for Computational Neuroscience, G\u00f6ttingen, Germany"}, {"index": "4", "address": "Georg-August-University G\u00f6ttingen, Third Institute for Physics, G\u00f6ttingen, Germany"}], "title": "Action potential shape and neuronal encoding properties maturate in parallel in cultured hippocampal neurons", "abstract": "Action potential (AP) generation begins with the activation of Na channels in the axon initial segment (AIS). The Na currents that flow during the first hundred microseconds in the proximal axon shape the onset of the somatic AP waveform, while the second phase of the AP upstroke is shaped by local, somatic Na currents. Na channel voltage dependence and activation kinetics in the AIS control the initial phase of the AP, as well as the exact timing of the AP in relation to the input current waveform. The latter can be characterized by the spike-triggered average of the input (STA). To which degree the early AP shape at the soma is also related to the STA is currently debated; multi-compartment models do not provide unambiguous answers as the actual values of key parameters, e.g. somatic and axonal Na channel density and voltage dependence are controversially discussed in the community.\nWe studied the maturation of the AIS function in cultured hippocampal neurons, as revealed by developmental changes in the AP waveform, and the relationship of these changes to maturation of neuronal encoding properties, as revealed by the STA and the dynamic gain. The measures of the AP shape changed quickly within the first week of AP firing: Vthresh dropped by 4mV, the onset rapidness, peak rate of rise and Vpeak increased. After 20 DIV the shape of APs was largely stable. Consistent with the increase in onset rapidness, Na channel fluorescence intensity in the AIS increased as well during the first 20 DIV. In parallel with the changes in AP waveform, the STA became narrower and the slope of the dynamic gain curve increased. For both fast and slow input fluctuations, the membrane time constant is a strong predictor of the slope of the gain. In the regime of slow input fluctuations we also obtained a positive correlation between the onset rapidness and the slope of the gain. This relation is expected from theory if onset rapidness was a proxy for axonal Na channel voltage dependence.", "acknowledgements": "This study was supported by the DFG (SFB 889), BCCN II (01GQ1005B), BFNT (01GQ0811), BMBF Bernstein Focus Lernen (01GQ0922), VW-Stiftung (ZN2632), and GIF (No.I-906-17.1/2006).", "id": 196653, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2,3", "name": "Elinor Lazarov"}, {"epithet": "4", "name": "Anja Huss"}, {"epithet": "2", "name": "Michael Gutnick"}, {"epithet": "1", "name": "Fred Wolf"}, {"epithet": "1,3", "name": "Andreas Neef"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["olmaov@neuron.appl.sci-nnov.ru"], "figid": 173, "doi": "10.12751/nncn.bc2013.0173", "affiliations": [{"index": "1", "address": "Institute of Applied Physics of RAS, Nizhny Novgorod, Russia"}, {"index": "2", "address": "Institute for Nonlinear Science, University of California at San Diego, USA, United States"}], "title": "Anti-phase bursting in two groups of randomly spiking neurons: generation and control", "abstract": "Animal locomotion activity relies on generation and control of coordinated periodic actions in a Central Pattern Generator (CPG). A core element of many CPGs responsible for the rhythm generation is a pair of reciprocally coupled neuron populations. A relatively recent development in studies of various CPG models is motivated by potential applications of neurobiological principles for control of motor activity in biomimetic robots [1, 2]. A very important element of such modeling is the design of very simple and computationally efficient models of neuronal behavior that sophisticated enough to capture important dynamical mechanisms of real neurons and neural networks and can be simulated in real-time within a compact, low-power computer implemented with FPGA or DSP chip [3, 4]. This work considers the use of a reduced model in form of discrete time system [5] to study the emergence of anti-phase bursting activity in two reciprocally coupled populations. We focus on the case of intrinsically not bursting neurons where the onset of switching anti-phase oscillations is supported by the effect of Post Inhibitory Rebound (PIR) bursts. The neurons within each group do not interact with each other, however each neuron in one group inhibits all neurons in the other group. Each isolated element (neuron) exhibits occasional spikes at random moments of time, however the interaction between two groups of such elements leads to formation of the mean group activities in anti-phase, burst-like oscillations.", "acknowledgements": "Supported by MESRF (8497, 14.132.21.1354, 8205) and by RFBR (12-02-31252, 12-02-00526, 12-02-31825, 12-04-31963, 13-02-00858).", "id": 196654, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Oleg V. Maslennikov"}, {"epithet": "1", "name": "Dmitry V. Kasatkin"}, {"epithet": "2", "name": "Nikolai F. Rulkov"}, {"epithet": "1", "name": "Vladimir I. Nekorkin"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] AJ Ijspeert, Neural Networks 21 4 642-653 (2008)\n[2] J Ayers, N Rulkov, D Knudsen, Y-B. Kim, A. Volkovskii, and A. Selverston, Applied Bionics and Biomechanics, 7, 57-67 (2010)\n[3] J Ayers and N Rulkov. In: Bio-mechanisms of Animals in Swimming and Flying. N Kato and S Kamimura. Tokyo, Springer-Verlag. (2007) Pp. 295-306\n[4] A Westphal, NF Rulkov, J Ayers, D Brady and M Hunt, Smart Structures and Systems, 8, 1, 39-52 (2011)\n[5] M Courbage, VI Nekorkin and LV Vdovin, Chaos, 17, 043109 (2007)"}, {"correspondence": ["remi.gau@tuebingen.mpg.de"], "figid": 174, "doi": "10.12751/nncn.bc2013.0174", "affiliations": [{"index": "1", "address": "Max Planck institute for biological cybernetics, Germany"}, {"index": "2", "address": "University of Birmingham, United Kingdom"}], "title": "The left prefrontal cortex controls information integration by combining bottom-up inputs and top-down predictions", "abstract": "In the natural environment our senses are bombarded with many different signals. To form a coherent percept, the brain should integrate signals originating from a common source and segregate signals from different sources. This fMRI study investigated how humans combine bottom-up inputs (i.e. congruent VS incongruent signals) and top-down predictions (i.e. common source prior) to infer if sensory signals should be integrated.\nSixteen participants were shown movies of congruent (e.g. visual Ti with auditory Ti), incongruent (e.g. visual Ti with auditory Pi) and McGurk syllables (e.g. visual Ki with auditory Pi, which can be fused into the illusionary percept Ti). We manipulated participants\u2019 top-down predictions by presenting the McGurk stimuli in a series of congruent or incongruent syllables. Participants reported their syllable percept in forced choice procedure with 6 response options.\nAt the behavioural level, participants were more likely to fuse auditory and visual signals of a McGurk trial into an illusionary percept in congruent relative to incongruent contexts. This indicates that participant\u2019s top-down predictions influence whether or not they integrate sensory signals.\nAt the neural level, incongruent relative to congruent bottom-up inputs increased activations in a left fronto-parietal network. The left prefrontal activations also increased for McGurk trials, when participants selectively reported their auditory percept and did not fuse auditory and visual signals.  This effect was enhanced for incongruent contexts when participants expected that sensory signals  needed to be segregated.\nOur results show that the left inferior frontal sulcus determines whether sensory signals should be integrated by combining top-down predictions generated from prior trials with bottom-up information about sensory conflict in the incoming signals. Furthermore, it exerts top-down control  enabling independent sensory processing and report of only one sensory modality.\n", "acknowledgements": "", "id": 196655, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Remi Gau"}, {"epithet": "2", "name": "Uta Noppeney"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["tim.rohe@tuebingen.mpg.de"], "figid": 176, "doi": "10.12751/nncn.bc2013.0176", "affiliations": [{"index": "1", "address": "Department of Human Perception, Cognition and Action, Max Planck Institute for Biological Cybernetics, Tuebingen, Germany"}, {"index": "2", "address": "Computational Neuroscience and Cognitive Robotics Centre,University of Birmingham, Birmingham, United Kingdom"}], "title": "Causal inference conditions reliability-weighted integration of audiovisual spatial signals", "abstract": "To form coherent and reliable multisensory percepts of the environment, human observers have to segregate multisensory signals caused by independent sources but integrate those from a common source. Models of causal inferences (Kording et al., 2007) predict the inference of a common cause if the signals are close in space and time. Further, models of optimal reliability-weighted integration predict that multisensory signals are weighed proportional to their relative reliability in order to maximize the reliability of the integrated percept (Ernst & Banks, 2002). To probe models of causal inference and reliability-weighted integration, we presented subjects (N = 26) with audiovisual spatial cues and manipulated spatial disparity and visual reliability. Subjects were required to selectively localize the auditory cues and to judge the spatial unity of the cues. Indices of audiovisual spatial integration showed that audiovisual spatial cues were weighted proportional to visual reliability, but only if a common cause was inferred. Likewise, localization reliability increased with visual reliability in case of a common-cause inference. Computational models incorporating causal inferences and reliability-weighted integration provided superior fit to auditory-localization data compared to models implementing only reliability-weighted integration. The results suggest that reliability-weighed integration is conditioned on the outcome of the causal inference.", "acknowledgements": "The study was funded by the Max Planck Society.", "id": 196656, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Tim Rohe"}, {"epithet": "2", "name": "Uta Noppeney"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Ernst, M. O., & Banks, M. S. (2002). Humans integrate visual and haptic information in a statistically optimal fashion. Nature, 415(6870), 429-433.\nKording, K. P., Beierholm, U., Ma, W. J., Quartz, S., Tenenbaum, J. B., & Shams, L. (2007). Causal inference in multisensory perception. PLoS One, 2(9), e943.\n"}, {"correspondence": ["j.krupic@ucl.ac.uk"], "figid": 177, "doi": "10.12751/nncn.bc2013.0177", "affiliations": [{"index": "1", "address": "Cell and Developmental Biology, University College London, United Kingdom"}, {"index": "2", "address": "Institute of Behavioral Neuroscience, University College London, United Kingdom"}], "title": "How geometry of the environment affects grid cell symmetry: experimental observations and theoretical predictions", "abstract": "The mammalian hippocampal formation provides neuronal representations of environmental location, but the underlying mechanisms are unclear. The majority of cells recorded in parasubicular and medial entorhinal cortices of freely moving rats showed spatially periodic firing patterns composed of plane waves (or bands) drawn from a discrete set of orientations and wavelengths(1, 2). Grids cells form an important subset of this more general class, corresponding to hexagonal configurations of bands, and having the most stable firing. Occasional changes between hexagonal and non-hexagonal firing patterns imply a common mechanism underlying the various spatial patterns. Here we show how the geometry of the environment can affect the symmetry of spatially periodic cells and propose a descriptive model based on boundary-grid cell interactions that can capture our current experimental observations.", "acknowledgements": "This work was supported by the European Union Framework 7 (SPACEBRAIN) grant, the UK Medical Research Council, the Gatsby Charitable Foundation, and the Wellcome Trust. J.K. received support from a CoMPLEX studentship.", "id": 196657, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Julija Krupic"}, {"epithet": "2", "name": "Marius Bauza"}, {"epithet": "1", "name": "Stephen Burton"}, {"epithet": "1", "name": "John O'Keefe"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Krupic J, Burgess N, O\u2019Keefe J. Neural representations of location composed of spatially periodic bands. Science. 2012 Aug 17;337(6096):853\u20137. \n2. Zhang S-J, Ye J, Miao C, Tsao A, Cerniauskas I, Ledergerber D, et al. Optogenetic Dissection of Entorhinal-Hippocampal Functional Connectivity. Science. 2013 April 5; 340(6128)."}, {"correspondence": ["robert.egger@mpfi.org"], "figid": 178, "doi": "10.12751/nncn.bc2013.0178", "affiliations": [{"index": "1", "address": "Computational Neuroanatomy Group, Max Planck Institute for Biological Cybernetics, Tuebingen, Germany"}, {"index": "2", "address": "Network Imaging Group, Max Planck Institute for Biological Cybernetics, Tuebingen, Germany"}, {"index": "3", "address": "Department of Visualization and Data Analysis, Zuse Institute Berlin, Berlin, Germany"}, {"index": "4", "address": "Center for Neurogenomics and Cognitive Research, VU University Amsterdam, Amsterdam, Netherlands"}], "title": "Reverse-engineering sensory-evoked signal flow in rat barrel cortex", "abstract": "We present a novel reverse-engineering approach that allows investigating sensory-evoked signal flow through individual neurons within the context of their surrounding neural networks.\nTo do so, spontaneous and sensory-evoked activity is recorded from individual neurons in vivo. In addition, the complete 3D dendrite and axon projection patterns of these neurons are reconstructed and registered into an anatomically realistic model of rat barrel cortex. This model allows estimating the number and cell type-specific subcellular distribution of synapses on these neurons. Next, the neurons are \u201cwired\u201d into the network by connecting the synapses to presynaptic neurons based on cell type-specific connection probabilities. The number of functional synapses on this neuron is determined by including measurements of cell type-specific ongoing and sensory-evoked spiking probabilities for all presynaptic cell types. Finally, this neuron is turned into a compartmental model and constrained by comparing model responses to ongoing and sensory-evoked synaptic inputs to in vivo measured responses.\nFor the first time, this allows investigating in vivo measured sensory-evoked responses of single neurons in anatomically realistic computer models, complementing previous biophysically detailed models of single neurons based on in vitro experiments.\nTo investigate the mechanistic principles underlying sensory responses in different cell types, we use a Monte Carlo method for sampling the parameter space of the network-embedded neuron model. For example, by varying the functional connectivity or timing of sensory input, we identify model configurations that match the in vivo observed responses of these neurons.\nAs a first demonstration of the feasibility of this approach, we investigate sensory-evoked responses in two different pathways in rat barrel cortex.", "acknowledgements": "", "id": 196658, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Robert Egger"}, {"epithet": "2", "name": "Arno C. Schmitt"}, {"epithet": "3", "name": "Vincent J. Dercksen"}, {"epithet": "4", "name": "Christiaan P.J. de Kock"}, {"epithet": "2", "name": "Jason Kerr"}, {"epithet": "1", "name": "Marcel Oberlaender"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["rtnarayanan@gmail.com"], "figid": 179, "doi": "10.12751/nncn.bc2013.0179", "affiliations": [{"index": "1", "address": "Computat. Neuroanatomy, Max Planck Inst. For Biol. Cybernetics, Tuebingen, Germany"}, {"index": "2", "address": "Center for Neurogenomics and Cognitive Res., VU Univ. Amsterdam, Amsterdam, Netherlands"}, {"index": "3", "address": "Digital Neuroanatomy, Max Planck Florida Inst., Jupiter, FL, United States"}], "title": "Cell type-specific 3D structure and in vivo function of rat vibrissal sensory and motor cortex", "abstract": "Despite a long tradition in reconstructing neurons, the tracing of complete 3D axon morphologies still represents one major challenge in neuroscience research. In the present study, we labelled individual neurons throughout all layers of rat somatosensory and motor cortex with biocytin using an in vivo juxtasomal labelling approach. These neurons were reconstructed for their axon and dendrite morphologies by a semi-automated tracing pipeline and then positioned in a standard cortex reference frame to determine potential dendrite-axon overlap between neurons to create anatomically realistic model of the cortical circuitry. Previously we showed that the dendritic length and the number of thalamocortical synapses are key to predict the spiking behaviour of individual neurons in vivo. Here, additionally we show that all cell types in the rat vibrissal cortex have very specific local and long range innervation profiles. For e.g. we found that spiny stellate in the main input layer 4 are presynaptic to all cortical layers, whereas thick tufted neurons in the main output layer 5 are postsynaptic to all layers. Secondly, we found that axons of individual neurons show location and cell type-specific bouton density profiles. Thirdly, we found that all sensory neurons project axons beyond their principal column. Hence, most cell types receive more than 50% of their intracortical input from surrounding columns. Thus, for the first time, we provide clear evidence of multi-columnar processing. However, it remains open, whether some of these principles may be generalizable to other cortical areas as well. Consequently, we determined in vivo spiking frequencies, dendritic and axon projection patterns for cell types located within the vibrissal part of the primary motor cortex. We will demonstrate similarities, but also substantial organizational differences between the sensory and motor areas involved in processing whisker-evoked excitation. \n", "acknowledgements": "", "id": 196659, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Rajeevan Narayanan"}, {"epithet": "2", "name": "Christiaan De Kock"}, {"epithet": "3", "name": "Lothar Baltruschat"}, {"epithet": "2", "name": "Hemanth Mohan"}, {"epithet": "1", "name": "Robert Egger"}, {"epithet": "3", "name": "Bert Sakmann"}, {"epithet": "1", "name": "Marcel Oberlaender"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["rp@ni.tu-berlin.de"], "figid": 180, "doi": "10.12751/nncn.bc2013.0180", "affiliations": [{"index": "1", "address": "Neural Information Processing Group, Technische Universit\u00e4t Berlin; Bernstein Center for Computational Neuroscience Berlin, Germany"}, {"index": "2", "address": "Max Planck Institute for Biological Cybernetics, Berlin, Germany"}], "title": "Memory load modulates spiking activity in prefrontal cortex", "abstract": "While short-term memory is an essential requirement for behavior, knowledge about its neural code remains limited. In particular, how the brain organizes maintenance of multiple items at the same time has received little attention in this context. We trained two macaque monkeys to perform well in a memory task with load 1 and then, without further training had them memorize one to four visual sample stimuli presented sequentially over a period of 900 ms. Behavioral performance was above chance for all load conditions from the first session on. After a 3 second delay, the monkeys had to decide whether a newly presented test stimulus was part of the memorized set or not. During all subsequent sessions in which the monkey performed with load > 1, we recorded multi-unit activity and LFPs in prefrontal cortex using up to 16 micro-tetrodes.\nWe performed spike sorting with a new algorithm (bayes optimal template matching) and analyzed rate modulations across task time: preliminary results show the firing rate of most sorted single units is significantly modulated during stimulus presentations and delay, compared to the level of baseline activity. Separating units from the compound tetrode multi-unit signal provides additional information: many multi-units exhibit no significant (Friedman test, p<0.05) rate modulation for different memory loads, while we find multiple load-selective single units after sorting the respective spikes.\nMost selective sorted units modulate their firing rate during the first second of the delay period. For the majority of these units, the rate during this period is increased compared to the baseline activity. Later in the delay period, the selective units exhibit no preference towards an increase in firing rate. These results suggest an active memory encoding phase shortly after the stimulus presentation. We are now starting to assess single trial classification performance and include analyses of LFP oscillations and correlations between units.", "acknowledgements": "This work was funded by BMBF (01GQ0742, 01GQ0743), the Max-Planck-Society and the Deutsche Forschungsgemeinschaft (GRK1589/1).", "id": 196660, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Robert Pr\u00f6pper"}, {"epithet": "2", "name": "Matthias H.J. Munk"}, {"epithet": "1", "name": "Klaus Obermayer"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["maziar@ni.tu-berlin.de"], "figid": 181, "doi": "10.12751/nncn.bc2013.0181", "affiliations": [{"index": "1", "address": "Technische Universit\u00e4t Berlin; Bernstein Center for Computational Neuroscience Humboldt-Universitaet zu Berlin, Germany"}, {"index": "2", "address": "Technische Universit\u00e4t Berlin, Germany"}, {"index": "3", "address": "University of California, Irvine, United States"}], "title": "V1 neural responses to 1D and 2D moving patterns: a computational study", "abstract": "The classical receptive field (CRF) of many neurons in the primary visual cortex (area 17, V1) is tuned for the orientation and direction of 1-dimensional (1D) stimuli (i.e. edges, gratings). Further downstream, previous studies have reported sensitivity to more complex properties such as the global direction of 2-dimensional (2D) stimuli (i.e. plaids) only for neurons in higher visual areas (i.e., MT in monkey (Movshon etal, 1986), or PLS-complex in cat (Li et al, 2001).  Recently, however, extra-cellular recordings from both cat (Hashemi-Nezhad et at, 2011) and monkey (Guo et al, 2004) V1 cells have shown that a sub-population (<10%) of neurons are also tuned to 2D stimuli. \n\nIn order to investigate under which conditions V1 cells can show 2D tuning, we expanded the Energy Model (EM) (Adelson and Bergen, 1985) to construct receptive fields accounting for the rich selectivity of V1 responses. Within a range of biologically plausible values, we fixed the spatial structure of the EM\u2019s receptive field parameters and systemically varied the stimulus spatial frequency, speed, and orientation, and measured the model\u2019s energy responses to both 1D and 2D moving stimuli. \n\nOur results suggest that EM-neurons with high aspect ratios (multiple receptive field subunits) show no responses to plaid stimuli moving along their preferred 1D direction. For receptive field subunits with a low aspect ratio, we observe that the resulting broadening of the orientation and speed tuning produces plaid responses to the preferred 1D direction. Our modeling results demonstrate how V1 pattern selectivity can emerge from an Energy Model. \n", "acknowledgements": "M H-N would like to acknowledge funding support from Bernstein Center for Computational Neuroscience\nHumboldt-Universit\u00e4t zu Berlin and Sensory Computation in Neural Systems\nTechnische Universit\u00e4t Berlin.", "id": 196661, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Maziar Hashemi-Nezhad"}, {"epithet": "2", "name": "Timm Lochmann"}, {"epithet": "3", "name": "David C Lyon"}, {"epithet": "1", "name": "klaus Obermayer"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Adelson EH, Bergen JR. J Opt Soc Am A. 2:284-99. 1985\n\nGuo K, Benson PJ, Blakemore C. Eur J Neurosci. 19:1055-66. 2004 \nDoi:10.1111/j.1460-9568.2004.03212.x\n\nHashemi-Nezhad M, Liu Y-J , Lyon DC. Proceedings of the Society for Neuroscience. 41\u2019th Annual Meeting. Prog No. 270.05. 2011\n\nLi B, Chen Y, Li BW, Wang LH, Diao YC. Eur J Neurosci. 14:690-700. 2001\n\nMovshon JA, Adelson EH, Gizzi MS, Newsome WT. Exp Brain Res, Supplementum 11:117-151. 1986\n"}, {"correspondence": ["alex.susemihl@bccn-berlin.de"], "figid": 182, "doi": "10.12751/nncn.bc2013.0182", "affiliations": [{"index": "1", "address": "TU Berlin, BCCN Berlin, Germany"}], "title": "Optimal Control with Spike Train Information", "abstract": "We consider the problem of controlling a partially-observed linear stochastic system, where the observations come from Poisson spikes of a dense Gaussian-tuned population of neurons. This provides an alternative to the classical case of optimal neural coding, where the tuning functions and receptive fields of neurons are selected to maximize mutual information (Atick, 1992, Laughlin, 1982) or to minimize the mean squared error (Berens et al., 2011, Susemihl et al., 2013). Here we consider a full control problem, and after solving for the value function through a belief state formulation, seek the optimal tuning functions for the Poisson neurons that minimize the cost over the time window of the control problem. Similarly to (Susemihl et al., 2013), the Hamilton-Jacobi-Bellman equation for the value function results in a delayed partial-differential equation, which can be solved with similar methods. We discuss the applicability of the Certainty Equivalence Principle in this case and the extension to non-Gaussian tuning functions.", "acknowledgements": "AS's work was supported by the DFG research training group GRK 1589/1", "id": 196662, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Alex Susemihl"}, {"epithet": "1", "name": "Manfred Opper"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Atick, J. J. (1992). Could information theory provide an ecological theory of sensory processing? Network, 3(2):213\u2013251.\nLaughlin, S. (1981). A simple coding procedure enhances a neuron\u2019s information capacity. Z. Naturforsch, 36(c):910\u2013912.\nBerens P. et al., (2011) Reassessing optimal neural population codes with neurometric functions, PNAS 108 4423\nSusemihl, A. et al., (2013), Dynamic State Estimation based on Poisson Spike Trains: Towards a Theory of Optimal Encoding, JSTAT 2013(3):"}, {"correspondence": ["rmcichy@mit.edu"], "doi": "10.12751/nncn.bc2013.0183", "affiliations": [{"index": "1", "address": "CSAIL, MIT, United States"}, {"index": "2", "address": "BCS, MIT, United States"}], "title": "Decoding orientation of visual stimuli from human magnetoencephalography data", "abstract": "Local orientation is a fundamental feature extracted by visual perception. Recent advances in multivariate analysis methods in fMRI have allowed the direct and non-invasive localization of orientation encoding in the human brain [1], but have left its temporal aspects unclear. Here, using magnetoencephalography (MEG) we resolve with high temporal resolution the time course of orientation encoding in the human brain.\n\nIn experiment 1, participants observed sinusoidal gratings tilted 45\u00b0 to the right or left from vertical.  In experiment 2, sinusoidal gratings were oriented from 0 to 150\u00b0 in 30\u00b0 steps; and in experiment 3, they were radially balanced exponential spirals oriented 45\u00b0 to the right or left. All stimuli were shown in two different phases (phase and anti-phase) to allow dissociation of orientation from local luminance differences.\n\nWe used time-resolved multivariate pattern classification (support-vector machines) to decode the observed orientation from MEG data. In all three experiments and for all orientations, we find robust and significant decoding starting at ~65-70ms after stimulus onset. In addition, experiment 2 shows that orientation decoding is not merely due to a radial bias in the representation of orientation [2]. Comparing decoding for oblique vs. cardinal orientations (experiment 3), we also find no evidence for a cardinal bias [3] as a factor in orientation decoding in MEG. Importantly, results were independent of the local luminance of the stimuli, i.e. they generalized across phase. \n\nOur results demonstrate that multivariate analysis of MEG signals allows content-sensitive and direct read-out of local visual orientation information, and inform about the factors enabling orientation decoding.\n\n", "acknowledgements": "Thanks to Aude Oliva for providing additional support for this work; Humboldt Foundation scholarship to R.C.; Volkswagen Foundation grant to R.C.; Data recorded at the Athinoula A. Martinos Imaging Center at McGovern Institute for Brain Research, MIT.", "id": 196663, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Radoslaw Martin Cichy"}, {"epithet": "2", "name": "Dimitrios Pantazis"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Panels show stimulus material (top) and results (bottom) of three experiments investigating the time course of orientation encoding in the human brain. The lower part shows the results of time-resolved multivariate pattern classification (support vector machines) on MEG data distinguishing between brain responses to stimuli of different orientation. Analysis controlled for the influence of phase and thus local luminance differences between stimuli. Pattern classification was conducted pair-wise between conditions, resulting in a baseline chance-level of 50% decoding accuracy. Before stimulus onset and until ~60ms decoding accuracy fluctuates around baseline, then rises sharply and is followed by sustained and significant signal (p<0.05, Bonferroni-corrected for multiple time points by bootstrap). Significance is indicated by colored stars above the data curve, color-coded for decoding between different steps in orientation difference in experiment 2.", "figpath": "183.png", "refs": "1) Furmanski CS, Engel SA (2000) An oblique effect in human primary visual cortex. Nat. Neurosci. 3:535\u2013536.\n2) Mannion DJ et al. (2009) Discrimination of the local orientation structure of spiral Glass patterns early in human visual cortex. Neuroimage 46:511\u2013515.\n3) Sasaki Y et al. (2006) The Radial Bias: A Different Slant on Visual Orientation Sensitivity in Human and Nonhuman Primates. Neuron 51:661\u2013670."}, {"correspondence": ["calbers@neuro.uni-bremen.de"], "figid": 184, "doi": "10.12751/nncn.bc2013.0184", "affiliations": [{"index": "1", "address": "University of Bremen, Germany"}], "title": "Associative learning of spike patterns with spike timing dependent plasticity ", "abstract": "The perceptron is an abstract model for hetero-associative memory and consists of rate-based neurons. The perceptron learning rule has several highly desirable properties also for auto-associative learning, namely close to optimal memory capacity, convergence in finite time if a solution exists, and a stop condition which provides a learning margin that provides robustness against noise. However, it is not known if and how the perceptron learning rule might be realized in real neuronal networks. Here we present new approach that is based on the concerted action of neuronal dynamics, most prominently action potential after-hyperpolarization, and a STDP rule, where pairs of first a pre- and then a postsynaptic spike lead to a decrease of synaptic impact. The role of the teacher signal is taken by postsynaptic spikes, which during learning are part of synchronously induced activity pattern, and after learning, if missing, will be filled back in. We prove mathematically that our approach is equivalent to the perceptron learning rule, and therefore realizes close to optimal auto-associative memory. Furthermore, with the condition of synchrony released, we show that with the same approach a neuron can learn to discriminate also spatio-temporal spike patterns, i.e. become a tempotron. Our results show that the combination of neuronal dynamics and synaptic plasticity rules can give rise to powerful learning principles. ", "acknowledgements": "Support by the BMBF (German Ministry of Education and Science) through \"Bernstein Fokus Lernen - Variable Tunes: Neuronal Models of Sequence Learning\", grant number 01GQ0964 is gratefully acknowledged.\n", "id": 196664, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Christian Albers"}, {"epithet": "1", "name": "Maren Westkott"}, {"epithet": "1", "name": "Klaus Pawelzik"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Hertz, Krogh, Palmer (1991) Introduction to the Theory of Neural Computation. Addison-Wesley.\nWestkott, Albers, Pawelzik (2013) Inhibitory STDP generates inverse models through detailed balance. Oral presentation at CNS 2013 (Paris)\nHaas, Nowotny, Abarbanel, (2006) Spike-Timing-Dependent Plasticity of Inhibitory Synapses in the Entorhinal Cortex. Journal of Neurophysiology 96(6)\nG\u00fctig, Sompolinsky (2006) The tempotron: a neuron that learns spike timing-based decisions.Nature Neuroscience 9(3)"}, {"correspondence": ["maren@neuro.uni-bremen.de"], "figid": 185, "doi": "10.12751/nncn.bc2013.0185", "affiliations": [{"index": "1", "address": "University of Bremen, Germany"}], "title": "Learning inverse sensory-motor mappings with spike timing dependent plasticity", "abstract": "Song birds learn to imitate tutor songs from sensory memories. This implies the mental reproduction of a specific sensory experience and thus a precise sequence of motor activations to produce them. It has been proposed that this is realized by inverse models that map desired sensory representations onto motor activations to produce the respective motor gestures which in turn yield the desired sensory inputs [1].\n\nThe biological mechanisms that could form inverses of possibly non-linear forward mappings in closed loop situation containing substantial delays are unclear. We propose a conceptually simple, functionally complete, and biologically plausible approach to learning inverse models in closed loop motor-sonsor-motor networks consisting of spiking neurons.\n\nIt is based on reverse STDP (RSTDP), that is the long term potentiation (LTP) of a synapse due to a post-synaptic activation followed by a presynaptic activation and long term depression (LTD) as a consequence of the reverse temporal order, which has been observed in distal synapses of cortical excitatory neurons[2]. Furthermore, STDP was found in inhibitory synapses, where it takes the classical causal form [3]. This will, in combination with fixed excitatory synapses, be equivalent to\nRSTDP on excitatory synapses.\n\nAdditionally, we employ self-inhibition of motor neurons after a spike as a biological trace of earlier activations, which implies that it will take more input to drive the neuron to spike than at resting state. We show that with these assumptions random motor explorations robustly lead to causal inverse models from sensory to motor representations and suggest that this provides a plausible explanation for the remarkable imitation skills in song birds, as well as for experimentally observed mirror neurons. Our model naturally accounts for the gating off of self-induced sensory input and makes testable predictions about the spike statistics of the involved motor neuron population.", "acknowledgements": "Financial support by the BMBF (German Ministry of Education and Science): \"Bernstein Fokus Lernen - Variable Tunes: Neuronal Models of Sequence Learning\", grant number 01GQ0964.", "id": 196665, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Maren Westkott"}, {"epithet": "1", "name": "Christian Albers"}, {"epithet": "1", "name": "Klaus Pawelzik"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1]Hanuschkin, Ganguli, Hahnloser (2013) A Hebbian learning rule gives rise to mirror neurons and links them to control theoretic inverse models. Front. Neural Circuits 7:106.\n[2]Sjostrom, Hausser (2006) A cooperative switch determines the sign of synaptic plasticity in distal dendrites of neocortical pyramidal neurons. Neuron 51: 227\u2013238.\n[3]Haas, Nowotny, Abarbanel (2006) Spike-Timing-Dependent Plasticity of Inhibitory Synapses in the Entorhinal Cortex. J of Neurophysiol 96(6):3305-3313."}, {"correspondence": ["earcher@utexas.edu"], "doi": "10.12751/nncn.bc2013.0186", "affiliations": [{"index": "1", "address": "The University of Texas at Austin, United States"}], "title": "Generalized quadratic models and moment-based dimensionality reduction", "abstract": "A popular approach for investigating the neural code is via dimensionality reduction (DR): identifying a low-dimensional subspace of stimuli that modulate a neuron\u2019s response. The two most popular DR methods for spike train response involve first and second moments of the spike-triggered stimulus distribution: the spike-triggered average (STA) and the eigenvectors of the spike-triggered covariance (STC). In many cases, these methods provide a set of filters which span the space to which a neuron is sensitive. However, their efficacy depends upon the choice of the stimulus distribution. It is well known that for radially symmetric stimuli, STA is a consistent estimator of the filter in the LNP model. Recently, Park and Pillow [2] proposed an analogous model-based interpretation of both STA and STC analysis based on a quantity called the expected log-likelihood (ELL). Here, building upon the previous work [2], we present a novel model class\u2014the generalized quadratic model (GQM)\u2014which bridges a conceptual and methodological gap between moment-based dimensionality reduction on one hand and likelihood-based generative models on the other. The resulting theory generalizes spike- triggered covariance analysis to both analog and binary response data, and provides a framework enabling us to derive asymptotically-optimal moment-based estimators for a variety of non-Gaussian stimulus distributions. This extends prior work on the conditions of validity for moment-based estimators and associated dimensionality reduction techniques [1;3;4]. The GQM is also a probabilistic model of neural responses, and as such generalizes several widely-used models including the LNP, the GLM, and the 2nd-order Volterra series. We apply these methods to simulated and real neural data from retina (spiking) and V1 (membrane potential).\n", "acknowledgements": "", "id": 196666, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Evan Archer"}, {"epithet": "1", "name": "Memming Park"}, {"epithet": "1", "name": "Nicholas Priebe"}, {"epithet": "1", "name": "Jonathan Pillow"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "(left) GLM and GQM filters fit to spiking response of a retinal ganglion cell under binary full field flicker stimulus at 120 Hz. GLM is composed of only the linear stimulus and spike history filter (blue, top left) while GQM consists of all four filters. Each filter is exponentiated and plotted to represent gain. Both quadratic filters were suppressive. (right) Cross-validated rate prediction averaged over repeated trials.", "figpath": "186.png", "refs": "[1] Bussgang 1952.\n[2] Park and Pillow NIPS 2011.\n[3] Paninski Network 2003.\n[4] Pillow and Simoncelli J. Vision 2006."}, {"correspondence": ["jan.benda@uni-tuebingen.de"], "figid": 187, "doi": "10.12751/nncn.bc2013.0187", "affiliations": [{"index": "1", "address": "Universit\u00e4t T\u00fcbingen, Germany"}, {"index": "2", "address": "npi electronic GmbH, Germany"}, {"index": "3", "address": "Technische Universit\u00e4t M\u00fcnchen, Germany"}], "title": "A novel dynamic clamp system for sharp electrodes based on discontinuous current clamp synchronized with a software loop", "abstract": "The dynamic clamp is a powerful closed-loop technique for intracellular recordings that allows one to introduce artificial membrane conductances into real neurons. Crucial for a successful dynamic clamp are precise measurements of the cell's membrane potential and at the same time accurate current injections through a single electrode. While this is possible for linear patch and bridge-mode amplifiers when using low-resistance (patch-) electrodes, high resistance sharp electrodes require usage of a current-clamp amplifier in discontinuous mode where the amplifier switches periodically with a high frequency between voltage measurement and current injection. The dynamic clamp algorithm is also a periodic process that takes the measured voltage and calculates a current that is injected back into the cell. In particular when simulating fast voltage gated ionic currents this dynamic clamp loop needs to be fast (several tens of kilohertz). Because of the Nyquist theorem the frequency of the amplifier needs to be at least twice as fast as the one of the dynamic clamp loop. Depending on the electrode and properties of the neuron such a high switching frequency might be difficult to achieve.\n\nWe here present a solution to this problem where we synchronize the switching cycle of the amplifier with the dynamic clamp loop. This way we make the amplifier an integral part of the dynamic clamp loop, such that the amplifier has to run with the same and not with double the frequency of the dynamic clamp loop. We implemented this approach within the RELACS software (www.relacs.sf.net) running on an RTAI Linux computer and a slightly modified SEC-05LX amplifier (npi electronic GmbH, Tamm, Germany). This system also copes well with the unstable period length of the software loop running the dynamic clamp algorithm. Other dynamic clamp systems could be easily adapted to achieve similar results.\n", "acknowledgements": "Supported by BMBF Bernstein Center of Computational Neuroscience Munich, Project A2\n", "id": 196667, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Jan Benda"}, {"epithet": "2", "name": "Jens Looser"}, {"epithet": "3", "name": "Werner Hemmert"}, {"epithet": "2", "name": "Reiner Polder"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["andoni@mail.utexas.edu"], "figid": 188, "doi": "10.12751/nncn.bc2013.0188", "affiliations": [{"index": "1", "address": "University of Texas at Austin, United States"}], "title": "Subthreshold Binocular Receptive Fields of Cortical Neurons", "abstract": "The primary visual cortex (V1) is the first site in the visual pathway where binocularity emerges in the cat. Monocular signals converge within V1 to create binocular simple cells, which are thought to form the initial basis for our representation of the visual world in three dimensions. To examine the neural computations that underlie the integration of right and left eye signals we measured both monocular and binocular aspects of the receptive field of cortical neurons to determine whether responses to binocular stimuli can be derived from the responses to monocular stimulation alone. Using whole cell recording to measure subthreshold membrane potential and action potentials, we stimulated simple cells by randomly presenting light and dark bars to both eyes. We first extracted monocular receptive fields (RFs) from simple cells by computing the reverse-correlation between the noise stimulus and both membrane potential and spiking responses. We then used voltage- and spike-triggered covariance analysis to uncover the nonlinear interaction between right and left eye inputs. Anzai et al. (1999) have previously shown that the spiking binocular RF of simple cells could be described as the product of the monocular RFs. We found that this model applies to some simple cells where the subthreshold binocular RF did not have a significant nonlinear interaction but their spiking RF was equivalent to the product of the monocular RFs. In other simple cells, on the other hand, we uncovered a similar binocular interaction RF for membrane potential that is also equivalent to the product of the left and right RFs. The significant structure found in the binocular interaction field for membrane potential in these cells could indicate an input from neighboring binocular cells. Finally, complex cells had a similar spiking and subthreshold binocular interaction RFs, suggesting that their input is pooling binocular simple cells in accordance with the energy model.", "acknowledgements": "", "id": 196668, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Sari Andoni"}, {"epithet": "1", "name": "Ben Scholl"}, {"epithet": "1", "name": "Nicholas Priebe"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Anzai, Akiyuki, Izumi Ohzawa, and Ralph D. Freeman. \"Neural mechanisms for processing binocular information I. Simple cells.\" Journal of Neurophysiology 82.2 (1999): 891-908."}, {"correspondence": ["scholl.ben@gmail.com"], "doi": "10.12751/nncn.bc2013.0189", "affiliations": [{"index": "1", "address": "Institute of Neuroscience, University of Texas, Austin, United States"}], "title": "Functional selectivity of spikelets in cat primary visual cortex", "abstract": "Chemical synapses comprise the majority of neuronal connections in the mammalian central nervous system, however electrical connections between neurons are also present in the form of gap junctions. It is hypothesized that electrical coupling promotes circuitry early in development, before stronger synaptic connections arise. Using in vivo whole cell recordings in adult cat primary visual cortex, we measured responses of individual neurons to sinusoidal gratings and observed spikelet activity from putative gap junction connections. Spikelets occurred independently of sodium spikes neuron being recorded and were biphasic in shape (see figure), leading us to believe they were from electrically coupled neurons1. From our intracellular records we compared the functional selectivity of the neuron being recorded and the spikelets. Orientation preference between membrane potential and spikelets closely matched (\u0394\u03b8 = 34 \u00b1 35 degrees, n = 8). Similar orientation tuning is potentially due to the columnar organization of orientation selectivity, suggesting that neurons within single columns are connected via gap junctions. In contrast, ocular dominance and disparity phase preference between membrane potential and spikelet responses were surprisingly different (\u0394OD = 0.66 \u00b1 0.42, \u0394\u03a6 disparity = 105 \u00b1 75 degrees, respectively, n = 15). The columnar structure for disparity and ocular dominance in cat V1 would predict that spikelets have similar selectivity as their targets, yet the relationship appears random for ocular dominance and disparity tuning. If spikelets represent electrical connectivity via gap junctions, our measurements suggest that the functional connectivity of electrically coupled neurons does not necessarily follow columnar organization found in cat primary visual cortex.", "acknowledgements": "", "id": 196669, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Benjamin Scholl"}, {"epithet": "1", "name": "Nicholas J. Priebe"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Intracellular recording of a neuron and spikelets responding to a visual stimulus.", "figpath": "189.png", "refs": "1. Margrie TW, Meyer AH, Caputi A, Monyer H, Hasan MT, Schaefer AT, Denk W, Brecht M (2003) Targeted whole-cell recordings in the mammalian brain in vivo. Neuron 39: 911-918. DOI: 10.1016/j.neuron.2003.08.012"}, {"correspondence": ["markus.breit@gcsc.uni-frankfurt.de"], "doi": "10.12751/nncn.bc2013.0190", "affiliations": [{"index": "1", "address": "Goethe Center for Scientific Computing, University of Frankfurt, Germany"}, {"index": "2", "address": "Department of Neurobiology, Interdisciplinary Center for Neuroscience, University of Heidelberg, Germany"}], "title": "Detailed simulation of calcium signaling in 3d reconstructed neurons", "abstract": "We have developed a model for the tempo-spatial signaling of calcium in neurons, which we use for detailed numerical simulations on realistic (i.e. reconstructed) three-dimensional neuronal topologies.\n\nThe model currently comprises a diffusion process for calcium in the cytosol and the ER, diffusion and decay reaction for inositol-1,4,5-trisphosphate (IP3), a mobile cytosolic calcium buffer (calbindin-D28k) reaction as well as several channel and pump mechanisms both in the ER and plasma membrane:\nWe combine the IP3 receptor channel model from [1], a simplified ryanodine receptor channel model from [2] and a SERCA pump model from [3] for the definition of ER membrane fluxes with simple Hill-type models for PMCA and NCX pumps together with a VDCC model as in [4] for the definition of plasma membrane fluxes. Other mechanisms can easily (mostly) be added.\n\nProvided with the three-dimensional geometry data of a neuron reconstruction, the model can be applied to make reasonable predictions for the calcium signal within the boundaries of a wide variety of parameters (such as local channel and pump densities in the membranes, equilibrium calcium and buffer concentrations, synapse activity patterns, morphological properties of cell organelles etc.).", "acknowledgements": "", "id": 196670, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Markus Breit"}, {"epithet": "2", "name": "Peter Bengtson"}, {"epithet": "2", "name": "Anna Hagenston Hertle"}, {"epithet": "2", "name": "Hilmar Bading"}, {"epithet": "1", "name": "Gillian Queisser"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Visualisation of a simulation of a series of synapse activations along a dendrite. The colour code depicts the calcium concentration in the cytosol after 0.6s.\nInlay: Timeline of the cytosolic calcium concentrations at different zones along the dendrite during the first 0.1s of the simulation.", "figpath": "190.png", "refs": "[1] De Young, G. W. and Keizer, J. (1992). Proc. Natl. Acad. Sci. USA 89.20, 9895-9899\n[2] Keizer, J. and Levine, L. (1996). Biophys. J. 71.6, 3477-3487\n[3] Sneyd, J. et al. (2003). Biophys. J. 85.3, 1392-1405\n[4] Borg-Graham, L. J. (1998). In \"Cerebral Cortex, Vol. 13: Cortical Models\", Plenum Press, New York"}, {"correspondence": ["stephan.grein@gcsc.uni-frankfurt.de"], "figid": 191, "doi": "10.12751/nncn.bc2013.0191", "affiliations": [{"index": "1", "address": "Goethe Center for Scientific Computing, Frankfurt am Main, Germany"}, {"index": "2", "address": "Max Planck Institute for Brain Research, Frankfurt am Main, Germany"}], "title": "Long-Term Potentiation Through Calcium-Mediated N-Cadherin Interaction is Tightly Controlled by the Three- Dimensional Architecture of the Synapse", "abstract": "The synaptic cleft is an extracellular domain that is capable of relaying a presynaptically received electrical signal by diffusive neurotransmitters to the postsynaptic membrane. The cleft is trans-synaptically bridged by ring-like shaped clusters of pre- and postsynaptically localized calcium-dependent adhesion proteins of the N-Cadherin type and is possibly the smallest intercircuit in nervous systems [1]. The strength of association between the pre- and postsynaptic membranes can account for synaptic plasticity such as long-term potentiation [2]. Through neuronal activity the intra- and extracellular calcium levels are modulated through calcium exchangers embedded in the pre- and postsynaptic membrane. Variations of the concentration of cleft calcium induces changes in the N-Cadherin-zipper, that in synaptic resting states is rigid and tightly connects the pre- and postsynaptic domain. During synaptic activity calcium concentrations are hypothesized to drop below critical thresholds which leads to loosening of the N-Cadherin connections and subsequently \"unzips\" the Cadherin-mediated connection. These processes may result changing the synaptic strength [2]. In order to investigate the calcium-mediated N-Cadherin dynamics at the synaptic cleft, we developed a three-dimensional model including the cleft morphology and all prominent calcium exchangers and corresponding density distributions [3],[4],[5],[6]. The necessity for a fully three-dimensional model becomes apparent, when investigating the effects of the spatial architecture of the synapse [7],[8]. We show that the localization of calcium channels w.r.t the N-Cadherin ring has substantial effects on the time-scales on which the Cadherin-zipper switches between states, ranging from seconds to minutes. This will have significant effects on synaptic signaling as high-frequency action potential firing can only be relayed to the Calcium/N-Cadherin-system at a synapse under precise spatial synaptic reorganization.", "acknowledgements": "", "id": 196671, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Stephan Grein"}, {"epithet": "2", "name": "Stefanie Bunse"}, {"epithet": "2", "name": "Erin Schuman"}, {"epithet": "1", "name": "Gillian Queisser"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Sheng M, Hoogenraad CC: Annu. Rev. Biochem. 2007 76:823\u2013847\n2. Tai CY, Kim SA, Schuman EM: Curr. Opin. Cell Biol. 2008 20:567\u2013575\n3. Graham L: Interpretations of data for hippocampal pyramidal cells 1999\n4. Gabbiani F, Midtgaard J et al.: Neurophysiology 1994 72(2):999\u20131009\n5. Jahr CE, Stevens CF: PNAS Neurobiology 1993 90:11573\u2013115\n6. Vaithianathan et al.: Cell Biochem. & Biophysics 2005 42:75\u201386\n7. Burette et al.: Comp. Neurology 2012 520:2697-2711\n8. Chen X: PNAS 2012, 105(11):4453-4458"}, {"correspondence": ["markus.knodel@gcsc.uni-frankfurt.de"], "doi": "10.12751/nncn.bc2013.0192", "affiliations": [{"index": "1", "address": "GCSC Universit\u00e4t Frankfurt, Germany"}, {"index": "2", "address": "EMBL Heidelberg, Germany"}, {"index": "3", "address": "IZN Universit\u00e4t Heidelberg, Germany"}, {"index": "4", "address": "Polytecnic of Turin, Italy"}], "title": "Synaptic boutons sizes are tuned to best fit their physiological performances ", "abstract": "To truly appreciate the myriad of events which relate synaptic function and vesicle dynamics, simulations should be done in a spatially realistic environment. This holds true in particular in order to explain as well the rather astonishing motor patterns which we observed within in vivo recordings which underlie peristaltic contractionsas well as the shape of the EPSPs at different forms of long-term stimulation, presented both here, at a well characterized synapse, the neuromuscular junction (NMJ) of the Drosophila larva (c.f. Fig. 1). To this end, we have employed a reductionist approach and generated three dimensional models of single presynaptic boutons at the Drosophila larval NMJ. Vesicle dynamics are described by diffusion-like partial differential equations which are solved numerically on unstructured grids using the uG platform. In our model we varied parameters such as bouton-size, vesicle output probability Po, stimulation frequency and number of synapses, to observe how altering these parameters effected bouton function. We demonstrate that the morphologic and physiologic specialization maybe a convergent evolutionary adaptation to regulate the trade off between sustained, low output, and short term, high output, synaptic signals. There seems to be a biologically meaningful explanation for the co-existence of the two different bouton types as previously observed at the NMJ (characterized especially by the relation between size and Po),the assigning of two different tasks with respect to short- and long-time behaviour could allow for an optimized interplay of different synapse types. We can present astonishing similar results of experimental and simulation data which could be gained in particular without any data fitting, however based only on biophysical values which could be taken from different experimental results. As a side product, we demonstrate how advanced methods from numerical mathematics can support the solution of biological questions.", "acknowledgements": "", "id": 196672, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Markus M. Knodel"}, {"epithet": "2", "name": "Dan Bucher"}, {"epithet": "3", "name": "Romina Geiger"}, {"epithet": "3", "name": "Lihao Ge"}, {"epithet": "4", "name": "Alfio Grillo"}, {"epithet": "1", "name": "Gabriel Wittum"}, {"epithet": "3", "name": "Christoph Schuster"}, {"epithet": "1", "name": "Gillian Queisser"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Simulation of a bouton of the Drosophila NMJ", "figpath": "192.png", "refs": "1.Jan L, Jan Y.  J Physiol. 1976;262(1):189\u2013214. \n2.Schuster C, et.al. Neuron. 1996;17(4):655\u201367. doi: 10.1016/S0896-6273(00)80198-1. \n3.Delgado R, et.al.Neuron. 2000;28:941\u201353. doi: 10.101.6/S0896-6273(00)00165-3. \n4.Bastian P, et.al.. In: High performance computing in science and engineering. W. J\u00e4ger and E. Krause, editor. Springer; 1999.pp. 326\u2013339."}, {"correspondence": ["martin.stepniewski@gcsc.uni-frankfurt.de"], "doi": "10.12751/nncn.bc2013.0193", "affiliations": [{"index": "1", "address": "Goethe Center for Scientific Computing, Computational Neuroscience Group, University of Frankfurt, Germany"}, {"index": "2", "address": "Department of Neurobiology, Interdisciplinary Center for Neuroscience, University of Heidelberg, Germany"}], "title": "Interactions of psychiatrically relevant molecules in \u2028synaptic transmission", "abstract": "Applying an interdisciplinary approach we aim at investigating the interactions of psychiatrically relevant molecules in synaptic transmission. To overcome the experimental and computational limitations posed by the extraordinary complexity of mammalian brains we take advantage of the simple and defined network of glutamatergic synapses at the Drosophila neuromuscular junction (NMJ), which is built by two motor neurons forming two types of multi-release-site boutons (Is, Ib). Drosophila NMJs express orthologs of molecules thought to be involved in human psychiatric conditions e.g. mGluRs (schizophrenia), NMDARs (general neurological dysfunction), FMRP (FragileX Syndrome) or Myosin VIIa (Usher Syndrome) and hence constitute a highly accessible system for the analysis of the principal mechanisms underlying psychiatric disorders.\nBased on our detailed morphological (serial EM, confocal-, FM1-43-, Ca2+-imaging) and electrophysiological data (intracellular current/voltage clamp) we set up a realistic 3D-structure/functional model that initially uses a set of partial differential equations describing vesicle dynamics and interactions between vesicle pools, as well as calcium dynamics incorporating channel, pump and buffer mechanisms in single presynaptic boutons. Systematic numerical simulations amongst others shed light onto the question why both motor neurons maintain their obvious morphological and physiological differences revealing that Ib boutons with a low release probability are likely utilized to reliably transmit sustained high-frequency stimuli whereas Is boutons with a high release probability are better suited for few low-frequency events [1].\nImplementing experimentally defined physiological parameters of psychiatrically relevant molecules into the model and extending it to a multi bouton level will allow us to predict and assess the developmental and physiological impact of these molecules\u2019 malfunction on single synapses and simple synaptic networks.\n", "acknowledgements": "", "id": 196673, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Martin Stepniewski"}, {"epithet": "2", "name": "Yeung Leung"}, {"epithet": "2", "name": "Lihao Ge"}, {"epithet": "1", "name": "Markus Knodel"}, {"epithet": "2", "name": "Christoph Schuster"}, {"epithet": "1", "name": "Gillian Queisser"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "(A) Cut through a reconstructed triangulated and tetrahedralized presynaptic Is bouton inside the Drosophila NMJ. (B) Simulated calcium dynamics inside a presynaptic Is bouton evoked by a single action potential with graphs of (C) the course of the corresponding membrane potential and (D) the spatial average calcium concentration transient.   ", "figpath": "193.jpeg", "refs": "[1] Knodel, M.M., Geiger, R., Ge, L., Bucher, D., Grillo, A., Wittum, G., Schuster, C.M., Queisser, G. (in revision) Synaptic Bouton Properties Are Tuned to Best Fit the Prevailing Firing Pattern"}, {"correspondence": ["julia.veit@unifr.ch"], "figid": 194, "doi": "10.12751/nncn.bc2013.0194", "affiliations": [{"index": "1", "address": "Visual Cognition Lab, University of Fribourg, Switzerland"}, {"index": "2", "address": "Unit of Anatomy, University of Fribourg, Switzerland"}], "title": "Effects of basal forebrain activation on neural processing in primary visual cortex ", "abstract": "Acetylcholine is an important neuromodulator for regulating activity and plasticity in the cortex. Cholinergic projections to the cortex originate in the basal forebrain (BF). We use microstimulation of this region to investigate cholinergic effects on visual processing in the primary visual cortex (V1) of tree shrews. We recorded spiking activity and local field potentials (LFPs) from 109 locations through all cortical layers in 9 anesthetized animals with pairs or triplets of tetrodes during visual stimulation with binary sparse noise and drifting gratings. \nThe spectrum of spontaneous LFP activity typically showed a decrease in low frequency power (<10Hz) and a marked increase in power in the gamma range (30-90Hz) after BF stimulation. Both spontaneous as well as visual stimulus evoked firing rates were generally increased. Interestingly, the effects on firing rate were larger in the infragranular layers of cortex which mediate feedback to subcortical areas like the thalamus. The visual response properties showed certain characteristic changes, such that contrast sensitivity of the neurons was significantly enhanced after BF stimulation whereas orientation selectivity was decreased. Moreover BF stimulation led to robust decreases in the F1/F0 ratio (P<0.01), which is used to classify neurons into simple and complex cell categories. This resulted in 19 neurons that were classified as simple cells before to switch their cell category, meaning they responded like complex cells after BF stimulation.\nTaken together we found that BF microstimulation had a strong impact on neuronal processing in V1 leading to generally higher responsivity, contrast sensitivity and, surprisingly, a higher number of complex cell like responses. Our results contribute to understanding the actions of the neuromodulator acetylcholine on cortical circuitry and processing.\n", "acknowledgements": "This work was supported by a SNF Prodoc grant PDFMP3_127 179 and a ESF EURYI grant PE0033-117106 to G.R.", "id": 196674, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Julia Veit"}, {"epithet": "1", "name": "Anwesha Bhattacharyya"}, {"epithet": "2", "name": "Robert Kretz"}, {"epithet": "1", "name": "Gregor Rainer"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["friedrich@fias.uni-frankfurt.de"], "figid": 195, "doi": "10.12751/nncn.bc2013.0195", "affiliations": [{"index": "1", "address": "Frankfurt Institute for Advanced Studies, Germany"}], "title": "Software Platform and Integration Framework for Rapid Cognitive Systems Engineering", "abstract": "Rapid prototyping and testing of large scale cognitive vision systems with an interdisciplinary team involving scientists and engineers imposes a number of challenges:  Different theoretical viewpoints need to be incorporated, several programming languages need to be supported and integrated, and computational issues need to be handled by scaling up from single machine to a cluster of computers. We have developed an integration platform and rapid application development framework that is flexible and allows the management of heterogeneous subsystems. Large scale applications are constructed from basic building blocks, i.e. Components. Our platform is inspired by past cognitive architecture designs, e.g. CAST: The CoSy Architecture Schema Toolkit [1]. It provides a C++ API for basic functionality including communication, distribution, and includes a set of standard image processing and statistics algorithms and libraries. Our focus is more on integration of different paradigms, standard building blocks and components, and ease of development. A graphical editor to ease application design accompanies the platform. The interface is intuitive and designing applications reminds of drawing UML diagrams, and on top of the design step it allows to manage and debug distributed applications. The editor differs from existing implementations (see [2][3][4]) in terms of the features we need for large scale heterogeneous applications: running applications distributed on a cluster of machines, and ease of application development by adding code template generation and debugging features. We have established standards for software development, including automated builds, automated tests with coverage analysis, and static code analysis. The platform developed and software engineering processes have been evaluated in a concrete rapid prototyping case study involving video surveillance.", "acknowledgements": "This work was funded by the German Federal Ministry of Education (BMBF), project 01GQ0840 and 01GQ0841 (Bernstein Focus: Neurotechnology Frankfurt).", "id": 196675, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Holger Friedrich"}, {"epithet": "1", "name": "Tomas Fernandes"}, {"epithet": "1", "name": "Christoph von der Malsburg"}, {"epithet": "1", "name": "Visvanathan Ramesh"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] CAST: The CoSy Architecture Schema Toolkit, http://www.cs.bham.ac.uk/research/projects/cosy/cast/\n[2] Jens-Malte Gottfried, Daniel Kondermann: Charon Suite Software Framework - modular algorithms for image processing, 2012, http://www.ipol.im/event/2012_imlib/docs/charon.pdf\n[3] mAmigo Coral, http://mamigoinc.com/coral.html\n[4] eXtensible Imaging Platform (XIP), https://collab01a.scr.siemens.com/xipwiki/index.php/Main_Page\n"}, {"correspondence": ["hota@fias.uni-frankfurt.de"], "doi": "10.12751/nncn.bc2013.0196", "affiliations": [{"index": "1", "address": "Goethe university frankfurt am main, Germany"}], "title": "Video Surveillance \u2013 Case study for cognitive vision", "abstract": "The Bernstein Focus Neurotechnology Frankfurt is focused on the development of a cognitive vision platform that fuses the state of the art computer vision research with neuroscience insights [1,2].The architectural model employs a two stage process: a first stage involving massively parallel modules performing feed-forward decomposition of input visual signal into constituent modalities, that allow for indexing into a rich memory structure, and a second stage involving fusion and/or deliberation wherein generated hypotheses are then refined  via a dynamic, recurrent process to converge to a visual interpretation.\n\nAs a case study to demonstrate the cognitive vision framework, we have constructed a video surveillance system involving object detection, tracking, and high-level activity pattern learning.   Bayesian statistical modeling work done over several years were consolidated to identify modules for decomposition of input video stream into sub-modalities (color [3], motion, texture [4], etc).  Given that these modules have probability semantics, they are a natural fit for statistical fusion and thus form the basis for democratic cue-integration or Bayesian fusion [2]. The work conducted uses texture descriptors based on relative gray-level orderings (ordinal methods) in pixel values, simplified physics based models for shadow classification, shadow invariant measures, global statistical illumination models, and spatio-temporal models of data variation (see figure). Our key innovation is in the decomposition approach and systematic fusion. Advance over the state of the art is in the consistent unification of a large body of literature in Bayesian models and linkage to bio-inspired models and implementation.", "acknowledgements": "This work was funded by the German Federal Ministry of Education (BMBF), project 01GQ0840 and 01GQ0841 (Bernstein Focus: Neurotechnology Frankfurt).", "id": 196676, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Rudra Narayan Hota"}, {"epithet": "1", "name": "Visvanathan Ramesh"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Figure Illustrates a view of the cognitive architecture pipeline applied  to video surveillance problems. ", "figpath": "196.png", "refs": "1] Malsburg C. ,A Vision Architecture Based on Fiber Bundles. Front. Comput. Neurosci. Conference,  BCCN'12\n2] Greiffenhagen, M, et al, Design, analysis, and engineering of video monitoring systems: an approach and a case study. Proceedings of the IEEE (2001)\n3] Greiffenhagen, M, et.al.The systematic design and analysis cycle of a vision system: a case study in video surveillance, CVPR'01\n4] Singh, M, et.al.Order consistent change detection via fast statistical significance testing. CVPR'08.\n5] Parameswaran, V, Illumination compensation based change detection using order consistency. CVPR'10,\n6] Monnet, Antoine, et al. \"Background modeling and subtraction of dynamic scenes.\" Computer Vision'03."}, {"correspondence": ["rothkopf@fias.uni-frankfurt.de"], "figid": 198, "doi": "10.12751/nncn.bc2013.0198", "affiliations": [{"index": "1", "address": "Frankfurt Institute for Advanced Studies, Germany"}], "title": "Inferring intrinsic costs in human navigation with inverse reinforcement learning", "abstract": "In a large variety of situations one would like to have an expressive and accurate model of observed animal or human behavior. While general purpose mathematical models may capture successfully properties of observed behavior, it is desirable to root models in biological facts. Because of ample empirical evidence for reward-based learning in visuomotor tasks we use a computational model based on the assumption that the observed agent is balancing the costs and benefits of its behavior to meet its goals. This leads to using the framework of Reinforcement Learning, which additionally provides well-established algorithms for learning of visuomotor task solutions. To quantify the agent\u2019s goals as rewards implicit in the observed behavior we propose to use inverse reinforcement learning, which quantifies the agent\u2019s goals as rewards implicit in the observed behavior. Based on the assumption of a modular cognitive architecture, we introduce a modular inverse reinforcement learning algorithm that estimates the relative reward contributions of the component tasks in navigation, consisting of following a path while avoiding obstacles and approaching targets. It is shown how to recover the component reward weights for individual tasks and that variability in observed trajectories can be explained succinctly through behavioral goals. It is demonstrated through simulations that good estimates can be obtained already with modest amounts of observation data, which in turn allows the prediction of behavior in novel configurations. We infer implicit costs and benefits from measured navigation behavior from human subjects in a variety of tasks and show that subjects never fully followed the given tasks instructions but instead were also driven by additional intrinsic costs. Finally we show, that human eye movements during navigation are tightly linked to the inferred rewards.", "acknowledgements": "CR was supported by the BMBF Project Bernstein Fokus: Neurotechnologie Frankfurt, FKZ 01GQ0840 and EU- Project IM-CLeVeR, FP7-ICT-IP-231722.", "id": 196678, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Constantin Rothkopf"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["sadra.sadeh@bcf.uni-freiburg.de"], "figid": 199, "doi": "10.12751/nncn.bc2013.0199", "affiliations": [{"index": "1", "address": "Bernstein Center Freiburg & Faculty of Biology, University of Freiburg, Germany"}], "title": "Statistics and Geometry of Orientation Selectivity", "abstract": "Orientation maps are a prominent feature of the primary visual cortex of higher mammals. In monkeys and cats preferred orientations are organized in a specific pattern, where neurons with similar selectivity are clustered in iso-orientation domains. However, the map is not always continuous, and there are pinwheel-like singularities around which all orientations are arranged in an orderly fashion. Although subject of intense investigation for the past fifty years, it is still not fully clear how these maps emerge and what function they might serve. In a new model of orientation selectivity, we combine the geometry of cortical \u201ccolumns\u201d with statistical connectivity of thalamocortical afferents to explain the emergence of orientation maps. We show that the model can generate spatial patterns of orientation selectivity closely resembling real orientation maps. Without any additional assumptions, we further show how the pattern of ocular dominance columns is inherently connected to the pattern of orientation maps. We also suggest an explanation why orientation singularities should be in register with distortions of the visuotopic map. More generally, we argue for the concept of \u201corientation selectivity\u201d as a multi-columnar computation, possibly generalizable to other modalities as well.", "acknowledgements": "Funding by the German Ministry of Education and Research (BFNT Freiburg*T\u00fcbingen, grant 01GQ0830) is acknowledged.", "id": 196679, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Sadra Sadeh"}, {"epithet": "1", "name": "Stefan Rotter"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["Christopher.Doerr@KMUB.THM.de"], "doi": "10.12751/nncn.bc2013.0200", "affiliations": [{"index": "1", "address": "FB KMUB, Technische Hochschule Mittelhessen, Gie\u00dfen, Germany"}, {"index": "2", "address": "Thomas RECORDING GmbH, Gie\u00dfen, Germany"}], "title": "Enhancements of a spike sorting algorithm: GUI development and detection optimization", "abstract": "To understand the information processing of the brain knowledge about the activity of neurons is required. To achieve this, multi-neuron extracellular recordings with multicore micro-electrodes like tetrodes were introduced. Micro-electrode recordings contain action potentials (spikes) of several neurons and noise. In spike sorting, the spikes are detected and then classified into groups corresponding to neurons.\nWe adopted and refined a spike sorting algorithm, originally developed by Franke et al. [1] and tested its performance with simulated signals incorporating various signal properties. Its performance was evaluated via receiver operating characteristic [2].\nPerformance evaluation with simulated signals is very useful for testing, but it cannot reproduce all facets of real neuronal recordings. For this reason, we started to analyze extracellular recordings from animal and especially human brains.\nHowever, visual inspection of signals and of sorting results is important for assessing the algorithm\u2019s performance. To improve usage and control of the algorithm, we developed a graphical user interface (GUI) that provides an expedient interactive visual workplace (Fig. 1).\nThe spike detection process of the spike sorting algorithm consists of thresholding the instantaneous energy, computed by the multiresolution Teager energy operator (MTEO). The theoretically good temporal resolution of this operator is declined due to averaging to reduce wrongly computed negative energy values. We recently developed the multiresolution energy filter (MEF) to optimize the computation of the instantaneous energy. It is based on the analytic signal and adopts the multiresolution property of the MTEO [3]. Preliminary results indicate, that the detection performance is equal for non-overlapping spikes and that the distinguished temporal resolution of the MEF improves the discrimination of overlapping spikes (Fig. 1) and thus the quality of spike sorting.", "acknowledgements": "Thanks to Prof. K. Obermayer, TU Berlin, and his colleagues for providing us with their program.\nThanks to Prof. V. Sturm, Department of Stereotactic and Functional Neurosurgery, University of Cologne and his team for collaborating with data recording.\nThis work is funded by BMWi ZIM KF2268909AK2.", "id": 196680, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Christopher Doerr"}, {"epithet": "2", "name": "Dirk Hoehl"}, {"epithet": "2", "name": "Uwe Thomas"}, {"epithet": "1", "name": "Thomas Schanze"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Figure 1: Screenshot of the spike sorter GUI with sorting results of a clinical tetrode recording from the globus pallidus internus of a human brain. Three units were found. Left: Detected spike waveforms. Mid: Recorded clinical tetrode signal. Found spikes are marked in top plot with colours corresponding to neurons. Right top: Principal components projection of spikes. Right mid: Filter outputs correspond to neurons. Peaks indicate detected spikes, detection threshold can be varied via a slider. Right bottom: Interspike-interval histograms.", "figpath": "200.png", "refs": "[1] Franke, Felix et al. (2010): An online spike detection and spike classification algorithm capable of instantaneous resolution of overlapping spikes. In: J Comput Neurosci 29 (1-2), S. 127\u2013148.\n[2] Doerr, C.; Hoehl, D.; Thomas, U.; Schanze T. (2012): ROC-testing of a spike sorting algorithm. In: Biomed. Tech. 2012 57 (suppl. 1), 2012, S. 649.\n[3] Doerr, C.; Schanze T. (2013): Analytic Signal Based Detection of Extracellular Action Potentials. BMT 2013, Graz, Austria, submitted.\n"}, {"correspondence": ["justuskr@physik.hu-berlin.de"], "figid": 201, "doi": "10.12751/nncn.bc2013.0201", "affiliations": [{"index": "1", "address": "Humboldt-Universit\u00e4t zu Berlin, Germany"}, {"index": "2", "address": "University of S\u00e3o Paulo, Brazil"}, {"index": "3", "address": "University of S\u00e3o Paulo, S\u00e3o Carlos, Brazil"}], "title": "A dynamical approach on using signatures of canonical bursting model neurons to explain circuit connectivity in biological CPGs.", "abstract": "We investigate the effect of network connectivity on neural signatures in the central pattern generator (CPG) of the blue crab's stomatogastric ganglion. \nFollowing the concept of fast-slow bursting, one can classify bursting behavior by the bifurcations the fast sub-system undergoes when switched between \nresting and spiking state. Neural signatures contain information about the sequence of interspike intervals during a burst and are, therefore, strongly \nconnected to these bifurcations. Using the corresponding canonical models, we are able to show how circuit connectivity changes these bifurcations and, \nconsequently, influences fundamental properties like the neuron's type of bursting or it's excitability. Our results give new insight in the role of \nindividual synaptic connections in CPGs.", "acknowledgements": "", "id": 196681, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Justus Alfred Kromer"}, {"epithet": "2", "name": "Boris Marin"}, {"epithet": "3", "name": "Reynaldo Daniel Pinto"}, {"epithet": "1", "name": "Lutz Schimansky-Geier"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["sonne@physik.hu-berlin.de"], "figid": 202, "doi": "10.12751/nncn.bc2013.0202", "affiliations": [{"index": "1", "address": "Department of Physics, Humboldt-Universit\u00e4t zu Berlin; Bernstein Center for Computational Neuroscience Berlin, Germany"}, {"index": "2", "address": "Institute of Mathematics, Humboldt-Universit\u00e4t zu Berlin, Germany"}, {"index": "3", "address": "Department of Physics and Astronomy, Ohio University, Athens, Ohio 45701, United States"}], "title": "How noise and coupling patterns affect collective dynamics of excitable elements", "abstract": "Excitable elements are ubiquitous in physical, chemical and biological systems [1]. Such systems possess a stable equilibrium, but, once excited by sufficiently strong perturbations, they display large non-monotonic excursions before returning to the state of rest. \n\nComposed of a huge number of neurons, the brain can be seen as a gigantic network of excitable elements [2]. In networks of nonlinear oscillators, one typically encounters the collective phenomenon of synchronization: different oscillators adjust their rhythms due to coupling [3]. Recently much effort has been invested into understanding the mechanisms which stand behind synchronization in complex networks [4].\n\nWe use a phase oscillator model, the so-called active rotator model, which was introduced by Shinomoto and Kuramoto [5]. It is a well-known model for excitable dynamics of coupled elements. Most of the research considered the case of uniform global coupling. We study dynamics of networks of randomly connected stochastic active rotators and put emphasis on how temporal fluctuations and the coupling pattern influence the dynamics of the network as a whole. \n\nIn the limit of infinite number of elements, we apply a mean-field theory for the network [6] and then use a Gaussian approximation [7] to obtain a lower-dimensional system of deterministic differential equations. This allows a numerical bifurcation analysis.\n\nWhile a uniform decrease in the number of connections per element in a homogeneous network does not produce any qualitative changes in the network dynamics, we find that heterogeneity in the number of connections leads to bifurcations in the excitable regime. In particular, we find that the critical values of noise intensity for the onset of global oscillations (Hopf bifurcation) display minima at moderate coupling variances, if a small fraction of highly connected nodes is introduced. At these minima, switching between different spiking patterns is most easily achieved.", "acknowledgements": "This work was supported by the DFG Research Training Group GRK1589/1 and project A3 of the Bernstein Center for Computational Neuroscience Berlin. Research of M.Z. was supported by the project D21 of the DFG Research Center MATHEON.", "id": 196682, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Bernard Sonnenschein"}, {"epithet": "2", "name": "Michael A. Zaks"}, {"epithet": "3", "name": "Alexander B. Neiman"}, {"epithet": "1", "name": "Lutz Schimansky-Geier"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] B. Lindner et al. Phys. Rep. 392:321, 2004.\n[2] O. Sporns. Networks of the Brain. MIT Press, 2010.\n[3] A. Pikovsky et al. Synchronization: A universal concept in nonlinear sciences. Cambridge Univ. Press, U. K., 2003.\n[4] A. Arenas et al. Phys. Rep. 469:93, 2008.\n[5] S. Shinomoto and Y. Kuramoto. Prog. Theor. Phys., 75:1105, 1986.\n[6] B. Sonnenschein and L. Schimansky-Geier. Phys. Rev. E, 85:051116, 2012.\n[7] M. A. Zaks et al. Phys. Rev. E, 68:066206, 2003."}, {"correspondence": ["briceayissi03@yahoo.fr"], "figid": 203, "doi": "10.12751/nncn.bc2013.0203", "affiliations": [{"index": "1", "address": "Uni-Tuebingen, Germany"}], "title": "Khaya grandifoliola inhibits inducible nitric oxide synthase, P38 MAPK Kinase and pro-inflammatory cytokines gene expressions in LPS- treated N9 microglia.", "abstract": "Khaya grandifoliola is a species of plant in the Meliaceae family.  In this study, we prepared CH2CL2/MeOH 1:1 V/V crude extract and fractions from this plant, and find out their effects on N9 microglia cells activities. K. grandifoliola fraction 25% was shown to be a potent inhibitor of lipopolysaccharide (LPS)-induced expression of inducible nitric oxide synthase (iNOS) and pro-inflammatory cytokines mRNA expression (TNF\u03b1, IL6 and IL1\u03b2) in mouse microglia cells.  K. grandifoliola effects were compared to Baicalin, a flavonoid isolated from Scutellaria baicalensis Georgi, for their effects on LPS-induced nitric oxide (NO) production and iNOS and the expression of pro-inflammatory cytokines gene expressions in N9 microglia. K. grandifoliola crude extract and fractions, as well as Baicalin, inhibited LPS-induced NO production in a concentration-dependent manner without cytotoxicity. The decrease in NO production was in parallel with the inhibition of LPS-induced iNOS gene expression. In addition, the suppression of pro-inflammatory cytokine mRNA expression was very significant after treatment with K. grandifoliola fraction 25%. Furthermore, K. grandifoliola inhibited the activity of p38MAPK kinase (95% inhibition), suggesting that the inhibition of this kinase is one of the multiple signaling pathways supporting K. grandifoliola  effects on these cells. From these results, it was concluded that K. grandifoliola fraction 25%  contains prominent compounds with promising effects against neurodegenerative diseases and neuroinflammation.", "acknowledgements": "This research was supported by the DAAD and the chemistry part co-funded by the International Foundation for Sciences (IFS), Stockholm, Sweden, and the Organisation for the Prohibition of Chemical Weapons (OPCW), through the grant No F/ 4223-2 ", "id": 196683, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Brice Ayissi"}, {"epithet": "1", "name": "Hermann Schluesenner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Abdipranoto-Cowley, A., et al., Activin A is essential for neurogenesis following neurodegeneration. Stem Cells, 2009. 27(6): p. 1330-46.\n2.    Minghetti, L. and G. Levi, Microglia as effector cells in brain damage and repair: focus on prostanoids and nitric oxide. Prog Neurobiol, 1998. 54(1): p. 99-125.\n3.    Akiyama, H., et al., Cell mediators of inflammation in the Alzheimer disease brain. Alzheimer Dis Assoc Disord, 2000. 14 Suppl 1: p. S47-53.\n"}, {"correspondence": ["ufromme@physik3.gwdg.de"], "figid": 204, "doi": "10.12751/nncn.bc2013.0204", "affiliations": [{"index": "1", "address": "Drittes Physikalisches Institut, Fakult\u00e4t f\u00fcr Physik, Georg-August-Universit\u00e4t, 37077 G\u00f6ttingen, Germany"}, {"index": "2", "address": "Bernstein Center for Computational Neuroscience, 37073 G\u00f6ttingen, Germany"}], "title": "Fluorescence guided SICM images of the Axon-Initial-Segment", "abstract": "Scanning-Ion-Conductance-Microscopy (SICM) is a scanning-probe-microscopy which allows topographic imaging of living cells with resolutions superior to standard optical methods. Its probe consists of an electrolyte-filled glass pipette similar to those used in patch-clamp recordings, so that it can also be used for electrophysiological experiments [1]. By combining SICM with fluorescence microscopy, specific stained structures can be indentified and imaged with SICM. In this work we used fluorescently labeled antibodies against Neurofascin, a cell adhesion molecule that is predominantly expressed at the Axon-Initial-Segment (AIS). Applied to live, cultured hippocampal neurons, the antibody allows identification of the AIS [2]. This makes it possible to image the surface structure of the AIS of living neurons with lateral resolutions better than 50 nm, and axial resolutions better than 10 nm. Employing the same piezo-driven pipette it is then possible to perform electrophysiological measurements with the same high spacial precision. This way it is possible to combine structural information with electrophysiological information with high resolution. The shapes of extracellular action potential waveforms, recorded at various positions along the cell with this method, can give much more information about ion current surface densities and kinetics than standard whole cell recordings [3].", "acknowledgements": "This study was supported by a grant in the framework of the Bernstein Center for Computational Neuroscience G\u00f6ttingen. (Grant number 01GQ1005A)", "id": 196684, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Ulrich Fromme"}, {"epithet": "2", "name": "Christopher Dilip"}, {"epithet": "2", "name": "Andreas Neef"}, {"epithet": "1", "name": "Christoph Schmidt"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] J. Gorelik, Y. Gu,  H.A. Spohr, A.I. Shevchuk, M.J. Lab, S.E. Harding, C.R.W. Edwards, M. Whitaker,  G.W.J. Moss, D.C.H. Benton, D. Sanchez, A. Darszon, I. Vodyanoy, D. Klenerman, Y.E. Korchev,  Biophysical Journal 32, 3296-3303, 2002\n\n[2] K.L. Hedstrom, Y. Ogawa, M.N. Rasband, Journal of Cell Biology 138, 635-640, 2008 \n\n[3] C. Gold, D. Henze, C. Koch, Journal of Computational Neuroscience 23, 39\u201358, 2007"}, {"correspondence": ["gaertner@math.uni-frankfurt.de"], "figid": 205, "doi": "10.12751/nncn.bc2013.0205", "affiliations": [{"index": "1", "address": "Institute of Mathematics, Goethe University Frankfurt am Main, Germany"}, {"index": "2", "address": "Department of Neurology and Brain Imaging Center, Goethe University Frankfurt am Main, Germany"}, {"index": "3", "address": "Department of Neurology, University Medical Centre Schleswig-Holstein, Kiel, Germany"}], "title": "Discrete sampling of time continuous marked processes in EEG microstate analysis", "abstract": "The time series of spontaneously occurring scalp electric field topographies measured by electroencephalography (EEG) shows periods (\u2018EEG microstates\u2019) in which the topography is quasi-stable. These are commonly analyzed by first sampling the EEG signal at specific time points and then classifying the EEG at these time points into a small number of prototypical topographies (\u2018maps\u2019). This results in a discrete sequence of maps.\n\nWe present a stochastic model and apply it to spontaneous human EEG recordings in wakeful rest and non-REM sleep. Our sampled marked intervals (SMI) model describes the relation between the observed map sequence and the underlying time-continuous signal. In the SMI model, we assume an underlying process of intervals, each interval being marked by one map. By sampling this process at discrete times, one obtains an observed sequence of maps. Under specific assumptions, the observed map sequence can be described as a Markov chain. This can be used to investigate a reduction of the parameter space and to estimate parameters of the underlying process such as the rate of switching between EEG microstates. The SMI model thus builds a bridge between traditional Markov chain analyses of EEG microstates and their relation to the underlying process.", "acknowledgements": "This work was supported by the LOEWE-Schwerpunkt \u2018Neuronale Koordination Forschungsschwerpunkt Frankfurt\u2019.", "id": 196685, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Matthias G\u00e4rtner"}, {"epithet": "2", "name": "Verena Brodbeck"}, {"epithet": "2,3", "name": "Helmut Laufs"}, {"epithet": "1", "name": "Gaby Schneider"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["britta.grimme@ini.rub.de"], "figid": 206, "doi": "10.12751/nncn.bc2013.0206", "affiliations": [{"index": "1", "address": "Ruhr-Universit\u00e4t Bochum, Germany"}], "title": "Evidence for movement primitives in human arm movements: the lift and the transport primitive", "abstract": "During everyday life humans perform plenty of obstacle avoidance movements, e.g. when reaching for something on a crowded breakfast table. In our work, we investigate 3D human arm movement tasks that entail the avoidance of obstacles. In particular, we ask if such movements are performed with the aid of movement primitives. Specifically, we decomposed the spatial movement path of the end-effector in the transport primitive (movement from start to target position) and the lift/descend primitive (movement perpendicular to transport within the movement plane). Here, we report further evidence for the existence of elementary building blocks in human arm movements that can be combined for the generation of complex movements. Especially regarding the lift primitive we found invariances across a lot of experimental conditions, e.g. when changing the position of the obstacle along the path to the target (Grimme et al, 2012), when comparing the movement from the start to the target position with the movement back to the start position, or even when performing the same movement with different speeds. In all these conditions the lift primitive is alike whereas the transport primitive performs adjustments to fulfill the requirements of the tasks. Contrary, we were also able to find an exemplary condition in which the lift component changed with respect to obstacle height, while the transport component stayed invariant. \nThese results suggest simple mechanisms for movement generation through the use of movement primitives.\n", "acknowledgements": "The authors acknowledge support from the German Federal Ministry of Education and Research within the National Network Computational Neuroscience - Bernstein Fokus: \"Learning behavioral models: From human experiment to technical assistance\", grant FKZ 01GQ0951.", "id": 196686, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Britta Grimme"}, {"epithet": "1", "name": "Eva Nowak"}, {"epithet": "1", "name": "Hendrik Reimann"}, {"epithet": "1", "name": "Gregor Sch\u00f6ner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Grimme, B., Lipinski, J., Sch\u00f6ner, G. (2012) Naturalistic arm movements during obstacle avoidance in 3D and the identification of movement primitives. Exp Brain Res 222(3):185-200. "}, {"correspondence": ["eva.nowak@ini.rub.de"], "figid": 207, "doi": "10.12751/nncn.bc2013.0207", "affiliations": [{"index": "1", "address": "Ruhr-Universit\u00e4t Bochum, Germany"}], "title": "Comparison of anticipatory and carry-over coarticulation on the levels of end-effector trajectory and joint angles in human arm movements", "abstract": "Originally, coarticulation had been found in speech articulatory movements, but it was also found in limb movements. Coarticulation describes an interdependency of sequential movement segments.  In post-coarticulation a movement segment affects its successor, in anticipatory coarticulation a movement segment affects its predecessor. We examined direction dependent coarticulation both at the level of the end-effector trajectories and, given the redundancy of the system, at the level of the joint angle configurations. \nRight-handed participants moved a cylindrical object on a monitor-table. The movement started from one of six possible starting points that were arranged on a circle at 2, 4, 6, 8, 10, and 12 o\u2019clock positions. In each trial, the cylindrical object was moved from the starting position to a target at the center of the circle and from there to one of three possible final target positions at 2, 6, and 10 o\u2019clock. \nTo uncover coarticulation at the level of joint angle configurations, we apply an analysis of motor equivalence that is based on the concept of the uncontrolled manifold. Therefore, we decomposed the difference between joint configurations in different conditions into components that leave the position of the transported object invariant (UCM) and those that affect the position of the object. Motor equivalence is observed when this difference lies more in the UCM than in its orthogonal complement (same spatial trajectory, but moving through different joint configurations). \nAt the level of object trajectories we found direction dependent coarticulation in some, but not all conditions. Anticipatory coarticulation was almost never observed. In contrast, at the level of the joint angle configurations, comparison of the different conditions provided clear evidence for both anticipatory and post-coarticulation in the form of motor equivalence even under conditions in which no coarticulation is visible at the level of the end-effector trajectories.\n", "acknowledgements": "The authors acknowledge support from the German Federal Ministry of Education and Research within the National Network Computational Neuroscience - Bernstein Fokus: \"Learning behavioral models: From human experiment to technical assistance\", grant FKZ 01GQ0951.", "id": 196687, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Eva Nowak"}, {"epithet": "1", "name": "Britta Grimme"}, {"epithet": "1", "name": "Hendrik Reimann"}, {"epithet": "1", "name": "Gregor Schoener"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Nowak E, Grimme B, Reimann H, Sch\u00f6ner G (2012) Motor equivalence reveals coarticulation in arm movement sequences  involving obstacle avoidance. Frontiers in Computational Neuroscience Conference Abstract: Bernstein Conference on Computational Neuroscience, BC12.\n\nScholz JP, Sch\u00f6ner G. (1999) The uncontrolled manifold concept: identifying control variables for a functional task. Exp Brain Res 126: 289\u2013306"}, {"correspondence": ["rothkopf@fias.uni-frankfurt.de"], "figid": 208, "doi": "10.12751/nncn.bc2013.0208", "affiliations": [{"index": "1", "address": "Frankfurt Institute for Advanced Studies, Germany"}, {"index": "2", "address": "University of Minnesota, United States"}], "title": "Optimally adapting heuristics: humans quickly abandon the constant bearing angle strategy", "abstract": "Animals ranging from dragonflies through teleost fish to humans all intercept moving targets using the same strategy of adjusting their speed so as to hold the angle pointing towards their target constant over time. This constant-bearing-angle strategy has been suggested as a fundamental visuomotor heuristic and as Darwininan intelligence that overcomes the need for complex and expensive computations. \n\nWe consider the task of intercepting a moving ball for which many previous studies have shown that humans use this constant bearing angle strategy. Here we manipulated the observation function in a virtual reality setup so as to change the uncertainty of the ball\u2019s position parametrically. Specifically, the contrast of the ball changes as a function of the heading angle towards the ball along the subject\u2019s momentary trajectory. Subjects adjusted their interception strategy within an average of 26 trials and were consistently able to catch these balls.\n\nTo gain insight into the adopted new interception strategy, we setup an approximate optimal control models, which is provided observation function governing the uncertainty in state variables given visual observations. Parameters of this model are based on previous literature. The approach utilizes a Monte Carlo sampling of smooth trajectories of increasing complexity in a low dimensional parameter space. This analyses shows that the ideal actor modifies its trajectories by executing controls that increase information gain, and that these changes mirror human behavior.\n\nThus, we provide evidence that humans quickly abandon the constant bearing angle strategy in favor of more informative action sequences, if this allows catching moving targets more reliably. The constant-bearing-angle-strategy is not an invariant heuristic of Darwinian intelligence as humans employ near-optimal information seeking actions that violate the constant bearing angle strategy, but produce less uncertainty in the interception.", "acknowledgements": "CR was supported by the BMBF Project Bernstein Fokus: Neurotechnologie Frankfurt, FKZ 01GQ0840.", "id": 196688, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Constantin Rothkopf"}, {"epithet": "2", "name": "Paul Schrater"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["sven.blankenburg@physik.hu-berlin.de"], "figid": 209, "doi": "10.12751/nncn.bc2013.0209", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Berlin, 10115, Germany"}], "title": "The information transmission in resonate-and-fire neuron models", "abstract": "It is known that integrate-and-fire neurons act as low-pass filters on information [1], i.e. they preferentially encode information at low frequencies. However, many neurons cannot be described by such integrators, even qualitatively. Experiments show that in several areas of the mammalian brain single neurons display a resonance property in their subthreshold voltage dynamics, see for example [2,3]. Here, we study the information transmission of a current-based resonate-and-fire neuron model [4] by means of the spectral coherence function. We use a stochastic input current (the Ornstein-Uhlenbeck process from statistical physics) to model a complex dynamical stimulus. We show by numerical simulations that resonate-and-fire neurons encode time-dependent stimuli preferentially at moderate frequencies, including their resonance frequency, i.e. the coherence function of this model shows a clear maximum as a function of frequency. This is in marked contrast to the low-pass coherence that is found for the pure subthreshold dynamics (in the absence of spiking) in spite of resonant filter properties. We discuss dynamical mechanisms that lead to the band-pass filtering of information in the spiking resonate-and-fire model. ", "acknowledgements": "This work was supported by grants from the BMBF (01GQ0901,01GQ1001A) and Deutsche Forschungsgemeinschaft (SFB 618). \n", "id": 196689, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Sven Blankenburg"}, {"epithet": "1", "name": "Benjamin Lindner"}, {"epithet": "1", "name": "Susanne Schreiber"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] R.D.Vilela & B. Lindner, \nPhys. Rev. E 80 (2009)\n\n[2] B. Hutcheon and Y. Yarom, \nTINS 23 (2000): 216-222\n\n[3] I. Erchova, G. Kreck, U. Heinemann and A.V.M. Herz,\nJournal of Physiology 560 (2004): 89-110\n\n[4] T.A. Engel, L. Schimansky-Geier, A.V.M. Herz, S. Schreiber, I. Erchova,\nJ. Neurophysiology 100 (2007): 1576-1589"}, {"correspondence": ["schleimj@hu-berlin.de"], "figid": 210, "doi": "10.12751/nncn.bc2013.0210", "affiliations": [{"index": "1", "address": "Inst. for theoretical Biology, Humboldt University, Berlin, Germany"}], "title": "Heterogeneity in a population of sensory neurons benefits information transfer", "abstract": "Idealized descriptions of neuronal populations often assume that the nerve cells are identical copies of each other and differ only in their intrinsic noise. In part, the assumption can be attributed to the fact that the diversity of neural populations has not been well quantified in the past. Today, accumulating experimental data show how heterogeneous neurons in sensory populations vary in terms of their threshold, expressed ion channels, and morphology. We begin to understand that this heterogeneity is not just an additional source of network noise, but can in fact have a positive influence on information transmission in neuronal ensembles [1]. Examples of such effects include the biophysical diversity of hyperpolarization-activated HCN channels in olfactory bulb mitral cells [2], variability in response properties of orientation-tuned neurons in primary visual cortex [3], and the heterogeneity of baseline firing in the electro-sensory organ of fish [4].\nHere, we focus on the variability of biophysical variables in the context of temporal processing. We propose a general framework for the statistical analysis of temporal filters of heterogeneous neuronal populations based on the phase-oscillator description in the mean-driven firing regime. To this end, each phase oscillator's input susceptibility, characterized by the phase response curve (PRC), is decomposed into a mean function as well as a randomly drawn neuron-specific deviation. Furthermore, the distribution of the PRCs itself can be generated by heterogeneity in any biophysical parameter, such as threshold or ion channel composition. As an example, we characterize the distribution of PRCs induced by variable densities of HCN channels as observed in mitral cells. We confirm our analytically calculated population response filters by numerical simulations. Our analysis demonstrates that the diversity of neuronal dynamics shapes the population filter and can have beneficial effects for stimulus encoding.", "acknowledgements": "This work was supported by the BMBF and BCCN Berlin.", "id": 196690, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Jan-Hendrik Schleimer"}, {"epithet": "1", "name": "Susanne Schreiber"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] J. F. Mejias and A. Longtin, Phys. Rev. Lett. 108, 228102 (2012)\n[2] K. Angelo and T. W. Margrie, Sci. Rep. 1 (2011)\n[3] M. I. Chelaru and V. Dragoi, Proc Natl Acad Sci USA 105, 16344 (2008)\n[4] M. Savard, R. Krahe, and M. J. Chacron, Neurosci. 172, 270 (2011)"}, {"correspondence": ["s.jarvis@imperial.ac.uk"], "figid": 211, "doi": "10.12751/nncn.bc2013.0211", "affiliations": [{"index": "1", "address": "Dept of Bioengineering, Imperial College, United Kingdom"}, {"index": "2", "address": "Institute of Biomedical Engineering, Dept of Electrical and Electronic Engineering, Imperial College, United Kingdom"}], "title": "A fine balancing act: Optical modulation of excitation and inhibition in dendritic subdomains", "abstract": "Optogenetics provides a powerful tool with which to not only observe but also manipulate neuronal activity, due to the possibility to spatially and temporally target subpopulations of neurons. Much focus has been placed on characterizing excitatory opsins, such as channelrhodopsin-2 (ChR2) [1,2], which when illuminated locally depolarizes the neuron membrane (optimal activation wavelength \u03bb=470nm). More recently, possibilities for optical manipulation has been further complemented by the development of silencing opsins that hyperpolarize the membrane, including halorhodopsin (NpHR) [3] and Archaerhodopsin T (ArchT) [4]. As they can be illuminated independently of ChR2 (optimal activation wavelengths \u03bb=585, 575 for NpHR and ArchT respectively), together these two families of opsins provide a potential window through which to examine the interplay of competing excitatory and inhibitory inputs. Such characterization has implications for advancing our understanding of the non-linear nature of inhibition, and is also vital for identifying effective protocols for silencing activity \u2013 especially while the spatial range and depth of illumination has experimental limitations that prevent deep or large areas being easily accessible. More importantly, it may allow more subtle changes to be made to neuronal function, for instance by altering the transfer function of genetically targeted classes of neurons. Here, using a model of neurons expressing both ChR2, NpHR and ArchT in NEURON, we first examine common illumination strategies and subthreshold dynamics. We further demonstrate that it is possible to \u201creprogramme\u201d the current-to-firing-rate transfer function of a neuron [5], altering both gain and threshold in either direction, by optical neuromodulation when targeting activation of apical and basal dendrites. Using these results, we propose a more effective, targeted stimulation protocol for successfully modulating the activity of neuronal populations in cortical layers.", "acknowledgements": "This work was supported by Wellcome Trust grant 097816/Z/11/A. ", "id": 196691, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Sarah Jarvis"}, {"epithet": "2", "name": "Konstantin Nikolic"}, {"epithet": "1", "name": "Simon Schultz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Boyden et al. Nat Neurosci. 2005 Sep; 8(9):1263-1268. \n[2] Grossman et al. J Comp Neurosci 2013, 34(3): 477-488\n[3] Han and Boyden PLoS ONE 2007, 2(3):e299\n[4] Han et al Front. Systems Neurosci. 2011 Apr, 5:18\n[5] Chance et al Neuron 2002 35: 773-782"}, {"correspondence": ["cornelius.schwarz@uni-tuebingen.de"], "figid": 212, "doi": "10.12751/nncn.bc2013.0212", "affiliations": [{"index": "1", "address": "BCCN T\u00fcbingen, Germany"}, {"index": "2", "address": "4Wellcome Trust Centre for Neuroimaging, University College London, United Kingdom"}, {"index": "3", "address": "7Department of Biopsychology, University of Bochum, Germany"}], "title": "Functional analysis of ultra high information rates conveyed by rat vibrissal primary afferents", "abstract": "Sensory receptors determine the type and the quantity of information available for perception. Here, we characterize and quantify the information transferred by primary afferents in the rat whisker system. Classic information theoretic analysis, the \u2018direct method\u2019, reveals very high information transfer by the primary afferents (up to 529 bits/s). Information-theoretic analysis of spike-triggered kinematic stimulus features further reveals that primary afferent spikes best represent vibrissa velocity. To a lesser but significant degree position and acceleration are represented but only in combination with velocity. Coding based on the occurrence of single spikes is complex, showing a strong preference for multiple stimuli at a time. In addition, short bursts consisting of 2 or 3 spikes at intervals of 2-3 ms code for extreme vibrissa velocities. We use a generative neuronal model employing mixtures of Gaussians fitted to whisker stimulus distributions, designed to deal with this complexity and allowing quantitative and mechanistic insight into what features are actually coded. We find that instantaneous position, velocity, and acceleration explain about 50% of the information rate obtained with the direct method. Adding a 10 ms pre-spike interval of stimulus trajectory achieves 80-90%. The final 10-20% is due to non-linear coding by spike bursts.", "acknowledgements": "", "id": 196692, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Andre Maia Chagas"}, {"epithet": "1", "name": "Lucas Theis"}, {"epithet": "2", "name": "Biswa Sengupta"}, {"epithet": "3", "name": "Maik St\u00fcttgen"}, {"epithet": "1", "name": "Matthias Bethge"}, {"epithet": "1", "name": "Cornelius Schwarz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["c.freigang@tum.de"], "figid": 213, "doi": "10.12751/nncn.bc2013.0213", "affiliations": [{"index": "1", "address": "Technical University Munich, Germany"}], "title": "Sound source localization and auditory scene analysis with cochlear implants", "abstract": "The formation of auditory objects and the recovery of sound location and identity information from a complex mixture of sounds in an auditory scene is a complex task performed by the auditory system. It is why we can understand speech in challenging acoustic environments and orient in space. In deaf people, cochlear implants (CI) (neural prostheses) are used to provide a sense of hearing by stimulation of the auditory nerve. So far, speech understanding in quiet surroundings has been established for most CI users with coding strategies that transmit simple acoustic features. However, the presence of multiple sounds represents a problem for the CI, leaving equipped persons with a mixture of intermingled sounds that result in a diffuse perception of the acoustic environment. Recently, we developed a coding strategy by which the perceptual saliency of binaural cues and acoustic features can be increased which led to a benefit in normal hearing subjects. In future studies, we want to exploit the potential of this strategy by examining with CI users behavioral performance to localize sound sources in reverberant environments and thus look into how efficiently source segregation can be deployed by systematically varying the coding of parameters related to auditory scene analysis. ", "acknowledgements": "", "id": 196693, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Claudia Freigang"}, {"epithet": "1", "name": "Bernhard U. Seeber"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["hosam@ucsd.edu"], "figid": 214, "doi": "10.12751/nncn.bc2013.0214", "affiliations": [{"index": "1", "address": "CNL, Salk Inst. For Biol. Studies, La Jolla, CA, United States"}, {"index": "2", "address": "Kavli Inst. for Systems Neuroscience, Ctr. for Biol. of Memory, Norwegian Univ. of Sci. and Technol., Trondheim, Norway"}], "title": "Mean field modeling unveils common remapping mechanism in hippocampal area CA3", "abstract": "Activity patterns of hippocampal place cells correlate strongly with the physical location of an animal in its environment. A major class of models based on the dynamics of continuous attractor networks has been proposed to describe the spatial selectivity of these cells. However, place cell activity has also been shown to deviate dramatically from strictly spatial firing. To investigate whether the spatial mapping hypothesis of the hippocampus is consistent with the modulated responses of hippocampal cells to environmental morphing procedures, we developed an attractor network model of area CA3 in which network architecture facilitates both spatial selectivity and contextual modulation. The network was modeled as a combination of spatial and localized structures: Within cell assemblies, multiple representations of non-spatial environmental information are stored, while connections between different cell assemblies decay proportionally to their spatial separation.\nIndividual cells were found to exhibit both spatial selectivity and overly dispersive firing variability signalling encoding of non-spatial information. In the mean field approximation, we analytically computed the network phase diagram and found three distinct network regimes whose activation depended on the degree of encoded correlations, the distributions of assembly membership and the relative strengths of recurrent activity/entorhinal input. These modes generated statistical signatures matching i) purely feedforward networks, ii) Hopfield-like attractor networks, or iii) \u2018quasi-spatial\u2019 networks simultaneously expressing multiple 'attractors'. While single cell dynamics in a morph experiment show a range of transition behaviors in accordance with experimental data, the signatures of transitions between network states for both global and rate remapping statistics can be easily seen in the correlation structure of neural activity suggesting a common network level mechanism for both remapping paradigms. ", "acknowledgements": "Howard Hughes Medical Institute\nONR MURI Award #N00014-10-1-0072\nFulbright Foundation\nLeiv Eiriksson mobility grant", "id": 196694, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Hosam Yousif"}, {"epithet": "2", "name": "Trygve Solstad"}, {"epithet": "1", "name": "Terrence Sejnowski"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["fot104@yahoo.com"], "figid": 215, "doi": "10.12751/nncn.bc2013.0215", "affiliations": [{"index": "1", "address": "School of Applied Mathematics and Physical Sciences, National Technical University of Athens, Greece"}, {"index": "2", "address": "Dept. Psychiatry and Dept. of Neurology, Cognition and Action Group, National and Kapodistrian University, Aeginition Hospital, Athens, Greece"}], "title": "Constructing the Functional Connectivity Networks between brain areas resulting from Visual-Spatial Working Memory Tasks using Multivariate Granger Causality Analysis", "abstract": "We applied multivariate Granger Causality (MVAR GC)1,2 on multi-channel EEG recordings from 10 healthy subjects extracted from 56 electrodes, acquainted through the execution of visual-motor and visual-discrimination tasks with memory and non memory conditions. MVAR GC was performed at overlapping time-windows, at alpha (8-12Hz), beta (13-30Hz) and gamma (30-45Hz) frequency bands. \nOur analysis revealed that at alpha band (8-12Hz) there is a significant denser well structured functional network associated with the visual-motor task which required retention of the spatial location of the target. At beta band (12-30Hz) there was a clear fractionation between motor and discrimination tasks associated with working memory and those that don\u2019t. In particular, we identified a fronto-parietal directed information flow pertaining to the structure of the emerged working memory-related motor network and an exchange of information between central and frontal areas associated with the memory-related discrimination task. Finally, at gamma band (30-45Hz), there was a delayed activation of information flow concerning the tasks requiring the activation of working memory mechanism.\nHence, our analysis provides evidence for the fractionation of spatial Working Memory associated with motor and perceptual tasks. \n", "acknowledgements": "Ms Foteini Protopapa was supported by a Doctoral Fellowship from the School of Applied Mathematics and Physical Sciences, National Technical University of Athens, Greece.", "id": 196695, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Foteini Protopapa"}, {"epithet": "1", "name": "Constantinos Siettos"}, {"epithet": "2", "name": "Nikolaos Smyrnis"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1.    Seth AK (2010) A MATLAB toolbox for Granger causal connectivity analysis. J Neurosc Methods 183: 262-273.\n2.    Barrett AB, Barnett L, Seth AK (2010) Multivariate Granger Causality and Generalized Variance. Physical Rev E 81: 041907.\n"}, {"correspondence": ["elilife@gmail.com"], "figid": 216, "doi": "10.12751/nncn.bc2013.0216", "affiliations": [{"index": "1", "address": "Institute of Medical Psychology and Behavioral Neurobiology and MEG Center, University of T\u00fcbingen, Germany"}, {"index": "2", "address": "Applied Neurotechnology Lab, Department of Psychiatry and Psychotherapy, Germany"}, {"index": "3", "address": "MEG Core Facility, National Institute of Mental Health, NIH, Bethesda, United States"}, {"index": "4", "address": "Ospedale San Camillo, Istituto di Ricovero e Cura a Carattere Scientifico, Italy"}], "title": "Direct effects of transcranial direct current stimulation (tDCS) on motor related brain oscillations", "abstract": "Transcranial direct current stimulation (tDCS) has polarity dependent effects on brain excitability and behavior [1]. However, the effects of such currents on brain oscillations are unknown. Recently, we have introduced a novel strategy allowing in vivo assessment of MEG signals during tDCS [2]. Here we investigated the immediate effects of tDCS applied over the right M1 on motor related brain oscillations during a go/no-go task. We hypothesized that such stimulation would have a direct effect on the amplitude of motor-related brain oscillations. 14 healthy volunteers were invited to three MEG sessions. Each session consisted of three runs (pre-tDCS, during-tDCS and post-tDCS). During each run, participants engaged in a go/no-go task guided by a visual stimulus with three cues: left, right button-press and no-press. Right M1 was stimulated using a bi-cephalic montage [2]. Polarity of stimulation (anodal, cathodal, sham) was changed and randomized across sessions. Source activity of the right and left M1 was calculated using SAM beamforming. A time-frequency analysis was performed to quantify task-related changes of motor-related brain oscillations. A repeated-measures ANOVA was employed to compare the signal amplitude changes during the three stimulation conditions and runs, and preliminary results were thresholded at p<0.05 uncorrected. The rm-ANOVA showed significant interactions between run type and stimulation condition in the right M1. Post-hoc t-tests indicated a reduction of amplitude in theta band oscillations preceding the button-presses during anodal and cathodal stimulation, while amplitude of beta oscillations was decreased only after cathodal stimulation. Also, we found an increase in amplitude of alpha oscillations after anodal stimulation in the interval preceding button presses, while no direct or after-effects were found during sham stimulation or in the left M1. We conclude that tDCS over the right M1 can affect motorrelated brain oscillation.", "acknowledgements": "This work was supported by the Intramural Research Program (IRP) of NINDS and NIMH Bethesda, Maryland, USA, the German Federal Ministry of Education and Research (BMBF, F\u00f6rderzeichen 01GQ0831, 16SV5840), the Deutsche Forschungsgemeinschaft (DFG), the European Union (FP7-ICT-2011-288551) and DAAD.", "id": 196696, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Eliana Garc\u00eda-Cossio"}, {"epithet": "1,2", "name": "Matthias Witkowski"}, {"epithet": "3", "name": "Stephen Robinson"}, {"epithet": "1,4", "name": "Niels Birbaumer"}, {"epithet": "1,2", "name": "Surjo Soekadar"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Nitsche M.A. , Paulus W.. Transcranial direct current stimulation \u2013 update 2011. Restorative neurology and neuroscience. 29, 463-492, 2011.\n[2] Soekadar S., Witkowski M., Garc\u00eda-Cossio E., Birbaumer N., Robinson S., Cohen L. In vivo assessment of human brain oscillations during application of transcranial electric currents. Nature Communication. In press.\n"}, {"correspondence": ["lucon@math.tu-berlin.de"], "figid": 217, "doi": "10.12751/nncn.bc2013.0217", "affiliations": [{"index": "1", "address": "TU Berlin/BCCN Berlin, Germany"}], "title": "The Mathematical Analysis of Interacting Stochastic Oscillators", "abstract": "We analyze the behavior of large ensembles of interacting neurons with random conductances w.r.t. the spatial geometry of the underlying network structure (see [4]). In order to make the model more realistic, the parameters of the individual neurons and the coupling mechanism need not be known precisely but may be distributed according to some given distribution (see [4]).\n\nThe limiting continuous neural field equation [3], describing the asymptotic statistical properties of the whole network, is rigorously derived for a general class of singular geometries (polynomial decay, P-nearest neighbors) introduced and studied in [2]. We also obtain precise estimates on the speed of convergence of the empirical distribution of the finite network to the continuous neural field equation, which is the main tool for the analysis of qualitative and quantitative aspects of the collective behavior of the underlying neural system, e.g. partial synchronization [5,6].\n\nOne of the mathematical novelties of our work consists of the fact that our model allows for singular geometries requiring nonstandard rates which may become highly relevant once one has understood better the real network structure of the brain.\n", "acknowledgements": "This work is supported by the BMBF (grant no. 01GQ1001B), Project A11.", "id": 196697, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Eric Lu\u00e7on"}, {"epithet": "1", "name": "Wilhelm Stannat"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1]J.Baladron,D.Fasoli,O.Faugeras&J.Touboul(2012)J.Math.Neuro.,2(1):10,doi:10.1186/2190-8567-2-10\n[2]S.Gupta,M.Potters&S.Ruffo(2012)Phys.Rev.E, 85:066201,doi:10.1103/PhysRevE.85.066201\n[3]E.Lu\u00e7on(2011)Electr.J.Probab.,16:792-829,doi:10.1214/EJP.v16-874\n[4]E.Lu\u00e7on&W.Stannat(2013),arXiv:1301.6521\n[5]I.Omelchenko,Y.Maistrenko,P.H\u00f6vel&E.Sch\u00f6ll(2011)Phys.Rev.Lett.,106:234102,doi:10.1103/PhysRevLett.106.234102\n[6]J.L.Rogers&L.T.Wille(1996)Phys.Rev.E,54:R2193--R2196,doi:10.1103/PhysRevE.54.R2193."}, {"correspondence": ["sauer@math.tu-berlin.de"], "figid": 218, "doi": "10.12751/nncn.bc2013.0218", "affiliations": [{"index": "1", "address": "TU Berlin/BCCN Berlin, Germany"}], "title": "Modeling and Analysis of Spatially Extended Neural Systems Subject to Noise", "abstract": "We present recent results on the modeling, analysis and numerical analysis of neural systems subject to channel noise fluctuations, capable of describing realistic features in the nervous system. Recent findings have shown that one has to be cautious when dealing with the numerical approximation of nonlinear systems subject to noise. In fact, noise in interplay with possibly super-linearly growing nonlinearities may result in numerical artifacts or even divergence of the numerical scheme (see [1,2]).\n\nWe have shown in [4] that the widely used finite difference approximations are consistent for any neuronal model with quasi-monotone coefficients, a natural assumption in the biophysical context. We also derive explicit error estimates for the approximate solution that are consistent with the best rates known in the literature.\n\nAn application of our results is in particular the construction of explicit confidence intervals for statistical estimators of the underlying dynamics useful in the calibration of models to given data. Illustrations include spatially extended stochastic FitzHugh-Nagumo systems. In particular, we estimate the probability of faithful signal transmission of a pulse along the axon using a new, robust estimator (see [3] for a similar published study).", "acknowledgements": "This work is funded by the BMBF (grant  no. 01GQ1001B), Project A12.", "id": 196698, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Martin Sauer"}, {"epithet": "1", "name": "Wilhelm Stannat"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] M. Hairer & J. Voss (2011) J. Nonlinear Sci. 21(6):897\u2013920, doi:10.1007/s00332-011-9104-3.\n[2] M. Hutzenthaler, A. Jentzen, & P. E. Kloeden (2011) Proc. R. Soc. A 467(2130):1563\u20131576, doi:10.1098/rspa.2010.0348.\n[3] H. C. Tuckwell (2008) Neural Comput. 20(12):3003\u20133033, doi:10.1162/neco.2008.08-07-585.\n[4] M. Sauer & W. Stannat (2013) Preprint, arXiv:1301.6350."}, {"correspondence": ["dinu.patirniche@campus.lmu.de"], "doi": "10.12751/nncn.bc2013.0219", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience Munich and Department of Biology II, Ludwig-Maximilians-Universit\u00e4t, 82152 Planegg-Martinsried, Germany"}, {"index": "2", "address": "Goethe-Center for Scientific Computing (G-CSC), Goethe University Frankfurt am Main, 60325 Frankfurt am Main, Germany"}], "title": "Modeling the Dendritic Spine Response: Effect of Static Charges and Nanoscale Geometry", "abstract": "Dendritic spines, the postsynaptic structures involved in excitatory chemical transmission, display highly diverse morphologies. Variations in spine conformation presumably underlie the effective strength of the synapse. In the most extreme case, cable theory predicts that the spine head electrically decouples from the parent dendrite [1]. Yet spine neck resistance is only indirectly measurable, which has led to considerable debate as to the true value of the resistance in the literature. A crucial question is whether the macroscopic biophysics underlying cable theory even applies: the small spatial extent of spines, accompanied by numerous ultrastructural elements that crowd the interior of the spine, could potentially lead to nonlinear current-voltage relationships.\n\nTherefore, we numerically simulate two and three-dimensional idealized geometries of spines (Fig 1) using the Poisson-Nernst-Planck (PNP) equations to describe the spatio-temporal evolution of ionic currents. In our model, the plasmalemmal membrane is endowed with surface charges, while realistic single-channel kinetics govern the opening of pores in the postsynaptic density. Ultrastructural features, within the spine interior that mimic charged cytoskeletal elements \u2013 such as actin filaments or microtubuli, are also modeled. By tracking the currents and electrical potential in time, we compare the full-resolution modeling approach to cable-theory predictions for a range of biologically inspired geometries.\n", "acknowledgements": "", "id": 196699, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Dinu Patirniche"}, {"epithet": "2", "name": "Andreas Vogel"}, {"epithet": "1", "name": "Andreas V.M. Herz"}, {"epithet": "2", "name": "Gillian Queisser"}, {"epithet": "1", "name": "Martin Stemmler"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Example of an idealized 2D spine geometry. Red - the postsynaptic density; Yellow - ultrastructural features; Gray - plasmalemma; Black - edges endowed with surface charge; Blue - electrolyte.", "figpath": "219.png", "refs": "[1] Grunditz, \u00c5., et. al, Spine neck plasticity controls postsynaptic calcium signals through electrical compartmentalization. J. Neuroscience"}, {"correspondence": ["stemmler@bio.lmu.de"], "figid": 220, "doi": "10.12751/nncn.bc2013.0220", "affiliations": [{"index": "1", "address": "BCCN Munich, Germany"}], "title": "A comparison of  calcium versus sodium spike energetics", "abstract": "Evolutionary selection pressure to minimize metabolic energy has shaped the nervous system's structure and function. While many parts of the nervous system reduce energy consumption by using action potentials (AP\u2019s) only sparingly, selection pressure is also likely to have molded the molecular components underlying the generation of AP\u2019s. Two forms of AP's dominate: calcium and sodium spikes.  While the ion channels selectively permeable to calcium and sodium are highly related, the energetics are quite different, as most calcium is bound, whereas sodium is free. We study these energetics in the context of optimization, perturbation, and control theory, seeking to understand why calcium spikes have, in many cases, given way to sodium spikes during evolution.", "acknowledgements": "", "id": 196700, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Martin Stemmler"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["dominik.endres@klinikum.uni-tuebingen.de"], "figid": 221, "doi": "10.12751/nncn.bc2013.0221", "affiliations": [{"index": "1", "address": "Department of Cognitive Neurology, Section Computational Sensomotorics, BCCN, CIN, HIH and University Clinic T\u00fcbingen, Otfried-M\u00fcller-Str. 25, 72076 T\u00fcbingen, Germany"}, {"index": "2", "address": "Department of Cognitive Neurology, BCCN, CIN, HIH and University Clinic T\u00fcbingen, Otfried-M\u00fcller-Str. 25, 72076 T\u00fcbingen, Germany"}], "title": "Simple spikes of Purkinje cells: pre-dictive, post-dictive or both?", "abstract": "Saccades and smooth pursuit eye movements (SPEM) have profoundly different kinematics. Early electrophysiological studies indicate that at least some of the Purkinje Cells Simple Spikes recorded in the Oculomotor Vermis are sensitive to both saccades and SPEM, a puzzling finding given their different kinematics (Suzuki et al. 1988). A recently published hypothesis (Dash et al. 2012) posits that the time course of the spike rate of these cells may be fine-tuned to the kinematic characteristics of smooth pursuit eye movements. To investigate this hypothesis further, we ask in particular if Simple Spikes of eye movement related Purkinje Cells are predictive and/or post-dictive (indicative) of several eye movement parameters. We describe these cells by a spiking neuron model, comprised of a Poisson process spike generator whose rate is controlled by a generalized linear model with a rectifying nonlinearity and eye position, velocity and saccade timing as regressors. To determine if a cell is predictive or post-dictive, these regressors are time-shifted against the spikes. This model is fit to the data with a Laplace approximation, availing us of estimates of regressor relevance. We find that cells whose best model fit is obtained when a spike train modulation precedes an eye movement (\u201cpredictive cells\u201d) tend to have a saccade regressor with higher relevance than the other regressors , whereas in indicative cells (i.e. spike train modulation happens on average after the movement) , the relevance of the eye position regressor is usually highest. We are currently extending this approach to study the coding of parameters of SPEM initiation. Specifically, we would like to quantify the relevance of the initial acceleration phase for pre/post-dicting spike trains. As an additional validation of our approach, signals recorded from the motoneurons of Nucleus Abducens will be used as ground truth, since they are well described  in the literature (Prsa et al. 2010)", "acknowledgements": "German Federal Ministry of Education and Research: BMBF, FKZ: 01GQ1002A; DFG GI 305/4-1, DFG GZ: KA 1258/15-1, EU Commission, 7th Framework Programme: EC FP7-ICT-249858 TANGO, EC FP7-ICT-248311 AMARSi, FP7-PEOPLE-2011-ITN(Marie Curie): ABC PITN-GA-011-290011, The Human Brain Project", "id": 196701, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Dominik M Endres"}, {"epithet": "2", "name": "Aleksandra Smilgin"}, {"epithet": "2", "name": "Peter W Dicke"}, {"epithet": "1", "name": "Martin A Giese"}, {"epithet": "2", "name": "Peter Thier"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Dash S., Catz N., Dicke P.W., Thier P. (2012). Cerebral Cortex. 22(4):877-91. DOI: 10.1093/cercor/bhr153.\nPrsa M., Dicke P.W., Thier P. (2010).  J. Neurosci. 30(47):15834-42. DOI: 10.1523/JNEUROSCI.3901-10.2010.\nSuzuki D.A., Keller E.L (1988). J Neurophysiol. 59(1):19-40.\n"}, {"correspondence": ["pramod@fias.uni-frankfurt.de"], "figid": 223, "doi": "10.12751/nncn.bc2013.0223", "affiliations": [{"index": "1", "address": "Frankfurt Institute for Advanced Studies, Frankfurt am Main, Germany., Germany"}], "title": "An Active stereo vision-based object tracking on iCub Robot", "abstract": "Reproducing the ability of biological organisms to learn autonomously is a challenge for future robots assisting humans at home, work place, or other changing environments [1]. While developing such systems, selective attention becomes necessary in order to be able to learn efficiently. Visual object tracking is an important part of such a selective attention process that enhances the ability to learn and the quality of the internal model of the environment that is often dynamic in nature. \n\nIn this work, we introduce a novel active stereo vison-based object tracking scheme and demonstrate it on the iCub robot in an indoor environment. Tracking on a robotic platform is especially challenging as the system should perform in real time using active cameras while the object is moving in a dynamic environment. In contrast to previous work that integrates information from different visual cues [2], we here develop a simple local feature based tracking mechanism to track a moving object which is dynamically changing its appearance and pose. The inaccuracies in the tracking mechanism is rectified by learning short term models for the object and the background. This in-built model learning allows the system to continue tracking despite unusual events such as when the object changes its location or when it goes out of view and reappears in the scene or in the case of severe occlusions. The system is also equipped with different modalities such as an active search when the object is lost, an intentional waiting for reappearance when the object is hidden and the reinitialization of the tracking when the object is displaced by the user.", "acknowledgements": "This work was supported by the BMBF Project \u201cBernstein Fokus: Neurotechnologie Frankfurt, FKZ 01GQ0840.", "id": 196703, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Pramod Chandrashekhariah"}, {"epithet": "1", "name": "Jochen Triesch"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] P. Chandrashekhariah, G. Spina, J. Triesch, \"Let it Learn: A curious vision system for autonomous object learning\", VISAPP - International conference on computer vision theory and applications, 21-24 February, 2013, Barcelona, Spain.\n\n[2] J. Triesch and C. v.d. Malsburg, \u201cDemocratic integration: Self-organized integration of adaptive cues\u201d, Neural Computation, Vol. 13, pp. 2049-2074, \n2001."}, {"correspondence": ["m.butz@fz-juelich.de"], "doi": "10.12751/nncn.bc2013.0225", "affiliations": [{"index": "1", "address": "Simulation Lab Neuroscience - Bernstein Facility for Simulation and Database Technology Institute for Advanced Simulation J\u00fclich Aachen Research Alliance Forschungszentrum J\u00fclich, Germany"}, {"index": "2", "address": "Universit\u00e4t Freiburg, Germany"}, {"index": "3", "address": "Vrije Universiteit Amsterdam, Netherlands"}], "title": "Homeostasis in electrical activity increases efficiency in small-world topology of self-organizing neuronal networks", "abstract": "Small-world topologies are known for their efficiency in transmitting information at relatively low costs through the network. Even the brain is composed of small-world networks and it seems that evolution has optimized brain connectivity to a maximum in processing efficiency. In spite of a vast amount of studies on the impact of network topology on information processing, little is known about the rise of topology in self-organizing neuronal networks. We investigated whether a simple growth process [1, 3] that only favors short-range connections over long-range connections can already generate small-world topology. We further included a very general assumption that neurons during their maturation strive towards homeostasis in electrical activity [2] and investigated the impact of homeostasis on emerging topology. Surprisingly, small-world networks but neither random nor regular networks benefited from homeostasis by an increase in efficiency compared to non-homeostatic growth. Homeostatic small-world networks maintained a slow but steady increase in efficiency even in an equilibrium state. We found that an increase in efficiency is caused by the emergent property of the homeostatic growth process that neurons start forming more long-range connections, albeit at lower speed, when their electrical activities are close to the homeostatic set-point. Longer connections reduce characteristic path length which in turn increases efficiency. Although global network topology still undergoes changes while local neuronal activities are in a homeostatic equilibrium, the small-world property of self-organizing networks is maintained over the entire course of simulation. The model helps to understand how complex self-organizing systems such as the brain set up connectivity efficiently with little constraints. Novel approaches on creating connectivity by self-organization are thus highly relevant for large-scale neuronal networks and supercomputing for the human brain. ", "acknowledgements": "Funded by Grant 635.100.017 Computational Life Sciences program of the Netherlands Organization for Scientific Research. Partially funded by the Helmholtz Association through the Helmholtz Portfolio Theme \"Supercomputing and Modeling for the Human Brain\"", "id": 196704, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Markus Butz"}, {"epithet": "2", "name": "Ines Derya Steenbuck"}, {"epithet": "3", "name": "Arjen van Ooyen"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Figure 1. Homeostasis increases Efficiency in small world networks (middle column, orange curve) compared to a non-homeostatic growth process (middle column, grey curve) while Efficiency benefited from homeostatic growth neither in regular (left column, red curve: homeostatic growth, grey curve: non-homeostatic growth) nor in random networks (right column, blue curve: homeostatic growth, grey curve: non-homeostatic growth). gamma is a parameter that determines the shape of the Gaussian kernel for synapse formation. In dependence of gamma (as the only parameter to change!) we can generate either regular (e.g. gamma = 0.1), small world (e.g. gamma = 0) or random networks (e.g. gamma = 1). Time in updates in connectivity with an update in connectivity taking place every 100ms.    ", "figpath": "225.jpeg", "refs": "[1] Butz M et al. (2009) A model for cortical rewiring following deafferentation and focal stroke. Front Comput Neurosci. 2009;3:10.\n\n[2] Tetzlaff C et al. (2010) Self-organized criticality in developing neuronal networks. PLoS Comput Biol. 6(12):e1001013.\n\n[3] Butz M, Van Ooyen A (2013) A simple rule for dendritic spine and axonal bouton formation can account for cortical reorganization after focal retinal lesions. Subm."}, {"correspondence": ["sanderkeemink@gmail.com"], "figid": 226, "doi": "10.12751/nncn.bc2013.0226", "affiliations": [{"index": "1", "address": "School of Informatics, University of Edinburgh, United Kingdom"}, {"index": "2", "address": "Bernstein Center Freiburg, University of Freiburg, Germany"}], "title": "Contextual interactions and association fields in a V1 network encoding Bayesian posteriors", "abstract": "How visually salient contours are encoded in the visual system is still a matter of much debate. Psychophysical experiments (Field & Hess 1993, Kapadia et al., 2000) and computational models (e.g. Li, 1998) suggest the existence of an association field: collinear bar stimuli enhance each other's responses, while parallel bar stimuli inhibit each other. Similar interactions have been recorded in many studies of V1 neurons, perhaps most strikingly in Kapadia et al. (2000). \n\nIn this work we explore the possibility that a form of Bayesian estimation of local orientations would lead to the observed interactions. Indeed, Schwartz et al. (2006) showed how a Bayesian model explains many properties of the tilt illusion, whereby the tilt of a centre edge is misjudged in the presence of two flanking edges. Their model estimated the centre tilt by finding the optimal combination of the presented centre tilt, and the smoothest tilt connecting the two flankers. \n\nWe investigate if this mechanism also underlies the association field. We assume a layer of V1 neurons encodes a Bayesian posterior based on the work of Schwartz et al. (2006), and study how single neuron activation changes in the presence of different edge combinations. We show that a form of the association field automatically arises, and that the neurons behave qualitatively similar to those measured in Kapadia et al. (2000), except for edges located exactly parallel to each other. This suggests that that Bayesian processing underlies both association fields, neural activities, and the tilt illusion.", "acknowledgements": "Work funded by the EU (EuroSPIN Erasmus Mundus program).", "id": 196705, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Sander W Keemink"}, {"epithet": "2", "name": "Clemens Boucsein"}, {"epithet": "1", "name": "Mark CW van Rossum"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Field et al (1993) Contour integration by the human visual system: Evidence for a local association field. Vision Res. 33(2):173-193\nKapadia et al (2000) Spatial distribution of contextual interactions in primary visual cortex and in visual perception. J. Phys. 84(4):2048-2062\nLi (1998) A Neural Model of Contour Integration in the Primary Visual Cortex. Neur. Com., 10:903-940\nSchwartz et al (2006) A Bayesian Framework for Tilt Perception and Confidence. Adv. in Neur. Inf. Proc. Sys.,18:1201-1208"}, {"correspondence": ["rveltz@salk.edu"], "figid": 227, "doi": "10.12751/nncn.bc2013.0227", "affiliations": [{"index": "1", "address": "INRIA Sophia Antipolis, France"}], "title": "Network symmetries modulation of neural tuning properties", "abstract": "The goal of this work is to study the implications of a particular working regime of rate models of V1. The working regime broadly describes the set of parameters that produce similar responses of the network. It has been hypothesized in many works [1,2,3] that the local circuitry of the visual cortex operates at the edge of an instability where the network shows self-sustained stationary/oscillatory activity. Hence, in this regime, the recurrent connections are tightly balanced and dominate the thalamic input.\nThese local circuits are also orderly arranged in a pinwheel structure. Although, the connections are locally homogeneous [4], the local circuitry has to cope with the pinwheel structure and the thalamic input in order to produce a non-ambiguous cortical representation of the stimulus. We look at this representation in the case of drifting grating stimulus and orientation tuning curves. In particular, we investigate the possibility to find correlates of the pinwheel structure in single cells responses. In order to simplify to study, we suppose that the pinwheels are organized in a square lattice. Also, our results could be used for animals showing a highly orderly pinwheel structure like cats [5] or by using localized stimuli in monkeys.\nDepending on the spatial extend of the connectivity and the gain function of the populations, the network displays an intrinsic preference. Its response to weakly contrasted stimulus orientations is locked: for example it prefers horizontal drifting gratings. However, as the contrast is increased,  the cortical response starts to agree with the stimulus orientation as the contrast exceeds a perception threshold. Looking for this perception threshold in biological experiment is difficult but we argue that a well designed dynamical stimulus can produce a counter intuitive response in which the cortical network fails to follow the stimulus.\nThe effects of long-range connections and propagation delays are also investigated.", "acknowledgements": "", "id": 196706, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Romain Veltz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Tsodyks, M. V. et al. Paradoxical Effects of External Modulation of Inhibitory Interneurons. 1997\n[2] Ben-Yishai, R. et al. Theory of orientation tuning in visual cortex. 1995\n[3] Stimberg, M. et al. The Operating Regime of Local Computations in Primary Visual Cortex. 2009\n[4] Mari\u00f1o, J. et al. Invariant computations in local cortical networks with balanced excitation and inhibition. 2005\n[5] Kenet, T. et al. Spontaneously emerging cortical representations of visual attributes. 2003\n"}, {"correspondence": ["ramesh@fias.uni-frankfurt.de"], "doi": "10.12751/nncn.bc2013.0228", "affiliations": [{"index": "1", "address": "Goethe University, Frankfurt am Main, Germany"}, {"index": "2", "address": "Frankfurt Institute for Advanced Studies, Frankfurt am Main, Germany"}], "title": "Systems Engineering for Visual Cognition", "abstract": "The Frankfurt Vision initiative focuses on the development of an integrated architecture for vision whose design is inspired by bringing together insights from neuroscience, cognitive science/psychology and computer vision systems.  From a systems perspective, we can view the human brain as an evolved system, with a flexible learning architecture designed by nature to solve a range of specific tasks in a class of environments that enhances the survival of humans.   Model-driven systems engineering is a discipline that formalizes application domain specification, i.e. task performance requirements and contextual models, and translates these specifications into system designs.  Systems engineering in the context of computer vision has its origins from the early 90\u2019s and has been refined over the years through practice [1, 2].  At a coarse-level the architectures inspired from systems engineering have parallels to models of brain function detailed in the brain and cognitive sciences.  Our architectural design involves massively parallel modules performing feed-forward decomposition of input visual signal into constituent modalities (e.g. color, motion, texture, shadow, reflection, contours, etc.) that allow for indexing into a rich memory structure. Generated hypotheses are then refined via a dynamic, recurrent process to converge to an interpretation. While both engineering and brain science views ([3]) of the architecture are in agreement at this higher level, practical considerations present a multitude of options on module selection, learning and inference approaches, and memory representation schemes. Our systems engineering methodology allows for parallel execution and exploration of the tradeoffs and systematic analysis of alternative models. ", "acknowledgements": "This work was funded by the German Federal Ministry of Education (BMBF), project 01GQ0840 and 01GQ0841 (Bernstein Focus: Neurotechnology Frankfurt).", "id": 196707, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Visvanathan Ramesh"}, {"epithet": "2", "name": "Christoph von der Malsburg"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Cognitive Architecture illustrating key procedural steps (depicted as elliptical blobs) of: Sensing, Fast indexing for hypotheses generation (reflexive processing), Reasoning, deliberation and refinement of details (reflective processing), Knowledge update, and Sensor control and action selection. The rectangular boxes correspond to specific data that are the inputs and outputs of the procedures. The central memory structure consists of World knowledge (Statistics of patterns, Contextual knowledge, rules, tasks and requirements), current estimate of scene state and uncertainty, and procedural knowledge on what procedures apply to what scenarios. This process view has a correspondence to the system dynamics view proposed in [3].", "figpath": "228.png", "refs": "[1] V. Ramesh, \"Performance Characterization of Image Understanding Algorithms\", Ph.D. Dissertation, University of Washington, Seattle, March 1995. \n[2] Greiffenhagen M. et al, Design, analysis, and engineering of video monitoring systems: an approach and a case study; Proceedings of the IEEE; vol.89, no.10; Oct. 2001; 1498-517. \n[3] Von Der Malsburg C. A Vision Architecture Based on Fiber Bundles. Conference Abstract: Bernstein Conference 2012. doi: 10.3389/conf.fncom.2012.55.0008"}, {"correspondence": ["greene@bio.lmu.de"], "figid": 229, "doi": "10.12751/nncn.bc2013.0229", "affiliations": [{"index": "1", "address": "Department Biology II and Bernstein Center for Computational Neuroscience Munich, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Germany"}, {"index": "2", "address": "Department of Ophthalmology, Georg-August-Universit\u00e4t G\u00f6ttingen, Germany"}], "title": "Distinguishing local and global motion through non-linear retinal processing", "abstract": "Fixational eye movements shift the visual image across the retina during fixation. These movements can be well above thresholds for visual motion detection, yet produce little or no motion percept. This implies the existence of mechanisms for inhibition of motion signals due to eye movements. \nWe describe a model in which such perceptual suppression can arise as a result of non-linear processing in Parasol-type retinal ganglion cells. These cells implement a non-linear spatial integration, corresponding to individual rectification of bipolar cells within their dendritic field. Due to their highly transient, phase invariant spiking, these cells seem well adapted to signal motion onset and saccades. The model uses these cells as input to a motion detection mechanism which distinguishes between local and non-local motion at the retinal level.\nWhen tested with stimuli containing both local differential motion of an object against background, and global shifts of the stimulus which mimic micro-saccades, this model successfully suppresses detection of saccadic movements, while still enabling accurate tracking of object motion. Thus, the model can account for the inhibition of motion percepts arising from global shifts due to eye movements, even in the absence of any reliable information about eye position.", "acknowledgements": "This work is supported by BMBF grant 01GQ1004A", "id": 196708, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Garrett Greene"}, {"epithet": "1", "name": "Erica Ehrhardt"}, {"epithet": "2", "name": "Tim Gollisch"}, {"epithet": "1", "name": "Thomas Wachtler"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["kellner@bio.lmu.de"], "figid": 230, "doi": "10.12751/nncn.bc2013.0230", "affiliations": [{"index": "1", "address": "Department Biologie II, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Munich, Germany"}], "title": "A Model of Lateral Interactions in Color Vision", "abstract": "The perceived color of an object depends not only on the spectral composition of the light reflected from its surface, but also on the visual context such as illumination and background color. Psychophysical studies using asymmetric matching have shown systematic hue shifts in the perceived color of a given stimulus induced by background color. Such interactions are thought to underlie perceptual phenomena like color contrast and color constancy. A possible neuronal basis may be lateral interactions which manifest in contextual influence on the tuning of color-selective neurons in the visual cortex (Wachtler et al., 2003). We present a model of cortical color processing that predicts the color shifts observed in psychophysical studies. The model assumes that stimulus hue is encoded by a population of neurons with Gaussian tuning curves and preferences distributed in color space, corresponding to the finding of distributed color preferences in primary visual cortex (Lennie et al 1990). The model assumes lateral inhibitory interactions between neurons sharing the same color preferences, but no interactions between color channels. We tested the model with inputs corresponding to stimuli of different hues presented on neutral or colored backgrounds, and determined the encoded hue from the population responses. Around the borders between stimulus and background, the modulation of neural activities due to the lateral interactions led to systematic shifts in encoded hue that were directed away from the color of the background. The results indicate that important computations in color vision can be realized using simple neural mechanisms when color is represented by a distributed code.", "acknowledgements": "Supported by the Graduate School of Systemic Neurosciences and the Bernstein Center for Computational Neuroscience Munich.", "id": 196709, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Christian Kellner"}, {"epithet": "1", "name": "Olivia Haas"}, {"epithet": "1", "name": "Miguel Obando"}, {"epithet": "1", "name": "Thomas Wachtler"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "Wachtler, T., Sejnowski, T.J., and Albright, T.D. (2003). Representation of color stimuli in awake macaque primary visual cortex. Neuron, 37, 681-691.\nLennie, P., Krauskopf, J., and Sclar, G. (1990). Chromatic mechanisms in striate cortex of macaque. Journal of Neuroscience, 10, 649-669."}, {"correspondence": ["sobolev.andrey@gmail.com"], "figid": 231, "doi": "10.12751/nncn.bc2013.0231", "affiliations": [{"index": "1", "address": "Department Biology II, Ludwig-Maximilians-Universit\u00e4t M\u00fcnchen, Germany"}], "title": "Web Data Storage for Management and Sharing of Neuroscience Data", "abstract": "Recent advancements in technology and methodology enable scientists to produce growing amounts of increasingly complex data recorded from many species, modalities, and levels of study. Annotation and organization of these data has become a challenging task, which is not only important for the interpretability and reproducibility of results and analyses, but also essential for collaboration and data sharing. In order to address these issues, the German INCF Node (G-Node) is developing software solutions consisting of several services and tools for experimental neuroscientists, focusing on online data access and organization of electrophysiological data. The core of this project is a web service representing a centralized data storage system that provides functions for upload, search, and management of data and metadata [1]. The principal design goal of this service was to improve the experimental workflow and to unify data access from different locations and platforms. Libraries and client programs provide the full functionality while allowing the scientist to use this service either directly through a web page or from his or her preferred working environment. This includes a toolbox for the popular numeric computing environment Matlab and a library for the programming language Python. The software supports various techniques and standards used in the field for data analysis and management, including common data objects for neurophysiology data [2], access to various file formats [3], and data annotation [4]. The service provides powerful search capabilities, implements a versioning system for all stored data objects and allows fine-grained sharing of data from whole datasets down to single signals and files, thus facilitating data management and collaborative research.", "acknowledgements": "Supported by the Federal Ministry of Education and Research (Grant 01GQ0801).", "id": 196710, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Andrey Sobolev"}, {"epithet": "1", "name": "Adrian Stoewer"}, {"epithet": "1", "name": "Aljoscha Leonhardt"}, {"epithet": "1", "name": "Philipp Rautenberg"}, {"epithet": "1", "name": "Christian Kellner"}, {"epithet": "1", "name": "Christian Garbers"}, {"epithet": "1", "name": "Andreas Herz"}, {"epithet": "1", "name": "Thomas Wachtler"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] G-Node Repository (http://g-node.github.com)\n[2] NEO I/O (http://neuralensemble.org/neo)\n[3] Neuroshare (https://github.com/G-Node/python-neuroshare)\n[4] Grewe J, Wachtler T, Benda J (2011). A bottom-up approach to data annotation in neurophysiology. Front. Neuroinform. 5:16. doi: 10.3389/fninf.2011.00016"}, {"correspondence": ["anna.stockl@biol.lu.se"], "figid": 232, "doi": "10.12751/nncn.bc2013.0232", "affiliations": [{"index": "1", "address": "University of Lund, Department of Biology, Vision Group, Lund, Sweden"}, {"index": "2", "address": "Discipline of Physiology, School of Medical Sciences, The University of Adelaide, Australia"}], "title": "Higher-order visual processing in nocturnal hawk moths", "abstract": "Even though humans see poorly at night, the majority of the world\u2019s animals \u2013 both on land and under water \u2013 are active in dim light and many of them have excellent vision. How have the properties of the visual circuitry been optimised to maximize visual performance in dim light conditions?\nIn order to approach this question, we are studying the visual motion processing circuitry in hovering hawk moths \u2013 a group of fast-flying insects renowned for their impressive visual abilities, in which closely related species are active under completely different light conditions, ranging from bright sunlight to starlight. \nOne way of increasing visual performance in dim light is to spatially pool signals from neighbouring visual channels \u2013 a process called spatial summation. Alternatively, signals can be integrated over longer periods of time, a process called temporal summation [1].\nWide-field motion-sensitive (HS-like) neurons in the lobula plate of hawk moths are tuned to the optic flow experienced during flight [2]. We recorded from these to quantify the spatial and temporal response characteristics of the visual system of a nocturnal species. \nGoing from dusk light intensities down to starlight levels, the spatial and temporal optima of their lobula plate neurons both decreased. This finding was reinforced by theoretical modelling: using the response characteristics of the moth\u2019s photoreceptors, combined with computational models of Reichardt-detector-based motion processing, we could theoretically show that the temporal and spatial tuning decreased well below the limits set by the optics and photoreceptor dynamics. We therefore conclude that the visual system of D. elpenor sums visual signals both in space and time.", "acknowledgements": "", "id": 196711, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Anna St\u00f6ckl"}, {"epithet": "2", "name": "David O\u2019Carroll"}, {"epithet": "1", "name": "Eric Warrant"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Warrant. Seeing better at night: life style, eye design and the optimum strategy of spatial and temporal summation. Vision Research. 39(9): 1611\u20131630, 1999\n[2] O'Carroll, Bidwell, Laughlin, Warrant. Insect motion detectors matched to visual ecology. Nature. 382(6586):63-6, 1996"}, {"correspondence": ["annette.werner@uni-tuebingen.de"], "figid": 233, "doi": "10.12751/nncn.bc2013.0233", "affiliations": [{"index": "1", "address": "Institute for Ophthalmic Research, Tuebingen University, Germany"}], "title": "Top down inferences in colour processing of insects ", "abstract": " Light fields in threedimensional visual scenes are complex and contain multiple illuminations from interreflections. Experiments using a so called Mach-card stimulus have shown that human colour vision uses prior knowledge about the physics of three-dimensional scenes in order to identify and compensate mutual illuminations (Bloj et al., 1999, Nature, 402, 877-879). Here we ask whether such cognitive inferences are a unique property of human colour processing or whether they may have developed also and indepently in other visual systems. \nHoneybees have excellent colour constancy, as demonstrated for example by their performance in Mondrian-like arrangements (Werner et al., 1988, Journal of Neuroscience, 8, 156-159).\nI will present a Mach-card experiment with free-flying honeybees (apis mellifera). A series of experiments was conducted, whereby bees were trained to discriminate between green/white cards folded in different spatial configurations: (1) planar, (2) concave and (3) convex. Previous experiments had shown that bees recognize the depth profil of such stimuli. The paper cards (2.5 x 2.5 x 6 cm) were presented in front of a vertical, \u201cgrey\u201d background (a turntable disc, 80 cm diameter). After training to the green/white pattern in planar configuration, bees recognized the green/white stimulus irrespective of its spatial layout and irrespective of the presence of interreflexions (concave stimulus). At the same time, bees did discriminate the trained stimulus from a simulation of the interreflection on the planar card, as well as an interreflection presented on the convex configuration. This indicates that the interreflection was indeed visible to the bees; importantly, the mutual illumination was compensated only if interreflexions were likely to occur in the given spatial arrangement.\n\nThus bees successfully compensate the mutual illumination in a three-dimensional scene, suggesting that their colour system implements knowledge of the scenes light field.", "acknowledgements": "", "id": 196712, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Annette Werner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["viola.priesemann@brain.mpg.de"], "figid": 234, "doi": "10.12751/nncn.bc2013.0234", "affiliations": [{"index": "1", "address": "FIAS Frankfurt, Germany"}, {"index": "2", "address": "University of Los Andes, Colombia"}, {"index": "3", "address": "H\u00f4pital de la Piti\u00e9-Salp\u00eatri\u00e8re, France"}, {"index": "4", "address": "Goethe University, MEG Unit, Germany"}], "title": "Neuronal avalanches change from wakefulness to deep sleep \u2013 a study of intracranial depth recordings in humans ", "abstract": "Neuronal dynamics differs with cognitive states from wakefulness to deep sleep [1]. In contrast, neural dynamics was also proposed to be governed by a single attractor state, called self-organized critical (SOC) because of its optimal information processing [2]. It is unknown whether the human brain always operates in this computationally optimal state, even during deep sleep, or whether it undergoes phase transitions to sub- or supercritical states with cognitive states. To test this, we characterized neuronal avalanches [3] - spatiotemporal waves of enhanced activity - from intracranial depth recordings (5 humans, ~60 LFP channels each, 10 recording nights, ~100h of recordings). Note that ~60 channels provide sufficiently dense sampling to avoid distortions due to subsampling [4]. We compared these results to results from a subsampled SOC model of non-leaky integrate- and fire neurons, which can be tuned to the sub- and supercritical regime.\nWe show that avalanche distributions approximated a power law (the hall mark feature of SOC systems), but did not perfectly match it [5], indicating that neural dynamics is only close to criticality. This held independent of the applied threshold and temporal scale, and for each cognitive state. Differences between cognitive states are reflected in systematic deviations from power law scaling: Slow wave sleep (s3/s4) showed smaller deviations than REM sleep, while wakefulness showed intermediate ones (p<0.05). These deviations, together with modelling results, suggest transitions in neural dynamics within the subcritical regime, but not to the supercritical regime. This implies that the human brain does not operate in a SOC state proper (contrary to previous beliefs), but in a slightly subcritical regime. While a subcritical regime might be less optimal for information processing, it allows the network to keep a safety-margin to the supercriticality, which is linked to epilepsy [6].", "acknowledgements": "VP received support from the Max Planck Society. VP and MW received support from LOEWE Grant Neuronale Koordination Forschungsschwerpunkt Frankfurt (NeFF). MV and MLVQ received support from the European Union-FP7 Project EPILEPSIAE (Grant No 211713).", "id": 196713, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Viola Priesemann"}, {"epithet": "2", "name": "Mario Valderrama"}, {"epithet": "3", "name": "Michel Le Van Quyen"}, {"epithet": "4", "name": "Michael Wibral"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Tononi G, Cirelli C (2006) doi:10.1016/j.smrv.2005.05.002\n2. Bertschinger N, Natschl\u00e4ger T (2004) doi:10.1162/089976604323057443\n3. Beggs JM, Plenz D (2003) \n4. Priesemann V, Munk MHJ, Wibral M (2009) doi:10.1186/1471-2202-10-40.\n5. Clauset A, Shalizi CR, Newman MEJ (2009) doi:10.1137/070710111.\n6. Hsu D, Chen W, Hsu M, Beggs JM (2008) doi:10.1016/j.yebeh.2008.05.007"}, {"correspondence": ["ms@micaros.com"], "figid": 235, "doi": "10.12751/nncn.bc2013.0235", "affiliations": [{"index": "1", "address": "Brain Imaging Center Frankfurt / Goethe Universit\u00e4t Frankfurt, Germany"}, {"index": "2", "address": "Klinik f\u00fcr Psychiatrie und Psychotherapie Mainz, Germany"}, {"index": "3", "address": "Zentrum f\u00fcr Neurologie T\u00fcbingen, Germany"}], "title": "Network analysis of multiple sclerosis using Transfer Entropy", "abstract": "In complex networks such as neural circuits, the interaction delay, i.e. the time needed for information transfer from one part of the network to another, is a crucial factor in the proper information processing. In neuroscience, this interaction delay mainly depends on the time that action potentials need to propagate through neural axons. It is assumed today that symptoms associated with diseases such as multiple sclerosis (MS), schizophrenia, and autism are partially caused by modified interaction delays. In case of MS, insulating myelin sheaths around axons are impaired so that conduction velocity is decreased. Thus, interaction delays in the network are prolonged. Here, we try to detect these increased interaction delays in the brain of patients suffering from MS compared to healthy controls (HC) by means of transfer entropy (TE). To this end, we obtained data from a study by Jung et.al. [1] where 17 MS patients and 13 HC subjects were stimulated with electrical pulses to the left and right median nerve at the wrist. Neural response activity was measured by magnetoencephalography (MEG) and sources within the brain were reconstructed using a beamformer method, and interaction delays were reconstructed. In addition, subjects performed behavioral tasks. In preliminary data we find a weak but significant correlation between interaction delays obtained for a specific intrahemispheric network connection and subject's performance in behavioral tasks where intrahemispheric information transfer was involved. On this link, interaction delays were consistent over baseline and various stimulation conditions. Increases in interaction delays in MS patients did not survive correction for multiple comparisons, but displayed a trend.", "acknowledgements": "", "id": 196714, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Michael Schaum"}, {"epithet": "2", "name": "Jung Patrick"}, {"epithet": "3", "name": "Ulf Ziemann"}, {"epithet": "1", "name": "Michael Wibral"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] Jung, P., Klein, J. C., Wibral, M., Hoechstetter, K., Bliem, B., Lu, M., Wahl, M., and Ziemann, U. (2012). Spatiotemporal dynamics of bimanual integration in human somatosensory cortex and their relevance to bimanual object manipulation. J Neuroscience, 32(16):5667\u20135677."}, {"correspondence": ["p.wollstadt@stud.uni-frankfurt.de"], "figid": 236, "doi": "10.12751/nncn.bc2013.0236", "affiliations": [{"index": "1", "address": "MEG Unit, Brain Imaging Center, Goethe University, Frankfurt, Germany"}, {"index": "2", "address": "Department of Signal Theory and Communications and Telematics Engineering, University of Valladolid, Spain"}, {"index": "3", "address": "Frankfurt Institute for Advanced Studies (FIAS), Goethe University, Frankfurt, Germany"}], "title": "Efficient transfer entropy analysis of nonstationary neural time series", "abstract": "Information theory provides a framework for the understanding of complex dynamic systems such as the brain. Information theoretic measures such as transfer entropy (TE) [6] allow for the investigation of interactions between components of the system by quantifying information transfer within the system. In practice, a reliable estimation of TE requires many data samples from the same data-generating process. For stationary processes, the necessary amount of data may be gained by collecting observations over time. This is no longer possible if an interaction under investigation evolves over time, i.e. the process is non-stationary. However, if the whole non-stationary process is repeatable over time (as in the form of experimental trials), one may acquire sufficient samples of one time point over trials. Such a repeatable process is called cyclostationary. Efficient methods for the estimation of TE from cyclostationary processes were recently proposed by [2] by treating experimental trials as independent repetitions of a process. We combined this data-efficient approach with an TE estimator recently proposed by [7] allowing for the reconstruction of interactions delays between time series. We integrated this approach into the MATLAB open source toolbox TRENTOOL [5] by using a parallelized GPU implementation for the computationally most demanding parts of TE estimation, i.e. nearest neighbor searches in the reconstructed state spaces of the neural times series as proposed by [4]. In doing so, we provided a data-efficient way of computing time-resolved TE from trial-based neural data. We successfully applied this implementation to MEG data of participants performing a perceptual closure task [3]. Preliminary results show early (<100ms) information transfer from visual cortex to frontal areas, in line with a hypothesis by [1], followed by frontal to temporal feedback (30-200ms) and pronounced information transfer into temporal areas in the closure interval (130-400ms).", "acknowledgements": "", "id": 196715, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Patricia Wollstadt"}, {"epithet": "2", "name": "Mario Martinez Zarzuela"}, {"epithet": "3", "name": "Raul Vicente"}, {"epithet": "1", "name": "Michael Wibral"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] M.Bar et al, PNAS, 103(2), 2006.\n[2] G.Gomez-Herrero et al, arXiv preprint arXiv:1008.0539,2010.\n[3] C.Gruetzner et al, Front Hum Neurosci, 7:88, 2013. doi:10.3389/fnhum.2013.00088\n[4] A.Kraskov et al, Phys Rev E, 69(6), 2004. doi:10.1103/PhysRevE.69.066138\n[5] M.Lindner et al, BMC Neurosci, 12:119, 2011. doi:10.1186/1471-2202-12-119\n[6] T.Schreiber, Phys Rev Lett, 85(2), 2000. doi:10.1103/PhysRevLett.85.461\n[7] M.Wibral et al, PLoS ONE, 8(2), 2013. doi: 10.1371/journal.pone.0055809"}, {"correspondence": ["felix.wichmann@uni-tuebingen.de"], "figid": 237, "doi": "10.12751/nncn.bc2013.0237", "affiliations": [{"index": "1", "address": "BCCN & Universit\u00e4t T\u00fcbingen, Germany"}], "title": "Bayesian analysis of a psychophysical model of human pattern detection", "abstract": "In psychophysics and the behavioural neurosciences, computational models are used to bridge the gap between raw data and understanding. Researchers formulate mathematical models summarizing the experimental data into a more comprehensible set of model parameters, typically estimated using maximum likelihood (ML) methods.\n\nTraditional ML methods have a number of problems, however, which arise from the fact that they only find the single best solution, but do not explore the parameter space fully. First, the parameter space may contain very different model specifications that still produce almost similar results. Second, the parameters can be correlated. Third, maximum likelihood estimates by themselves provide no insight into the variability of the estimated parameters. Without estimates of variability of the fitted parameters it is difficult to interpret the modelling results, however. One traditional solution is to estimate the variability (standard errors) from the normal approximation at the mode found by ML estimation. As a natural alternative, we propose and demonstrate Bayesian methods of exploring the parameter space which not only provides model solutions, but also provides information on the distributions of, and correlations between, the model parameters.\n\nWe apply Bayesian methods to psychophysical models of human pattern detection. Such models assume that the retinal image is first analysed through (nearly) independent and linear pathways tuned to different spatial frequencies and orientations. Second, the activation within the pathways is non-linearly transformed, either via a non-linear transducer or via a divisive contrast gain control mechanism. Third, the outputs are subjected to a suitable noise source and are then combined into a single decision variable via a simple Minkowski-norm. We discuss how our Bayesian exploration of model parameters reflects on model quality and interpretability, and thus provides useful model diagnostics.", "acknowledgements": "We would like to thank Hannah Dold for her work on Bayesian analysis of early vision models, and Matthias Bethge and Jakob Macke for helpful advice. This work was funded, in part, by the BMBF through the Bernstein Computational Neuroscience Program T\u00fcbingen (FKZ: 01GQ1002).", "id": 196716, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "David Janssen"}, {"epithet": "1", "name": "Felix Wichmann"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["mfauth@physik3.gwdg.de"], "figid": 238, "doi": "10.12751/nncn.bc2013.0238", "affiliations": [{"index": "1", "address": "BCCN G\u00f6ttingen; III. Physikalisches Institut, Universit\u00e4t G\u00f6ttingen, Germany"}], "title": "The synaptic dynamics behind cortical connectivity ", "abstract": "Dendritic spines form the substrate for most of excitatory synapses in the cortex. Thus, it is not surprising, that their morphological properties correlate with electrophysiological parameters of the associated synapse. Especially the spine head volume the  synaptic weight (EPSP strength) are well correlated. To maintain this correlation during activity-dependent weight changes due to synaptic plasticity, the spine volume also changes with activity.\nFurthermore, dendritic spines are constantly created and removed, such that the connectivity of the network is altered.  This structural plasticity has been shown to play a role in memory formation.  The lifetime of single spines increases with their volume, and is, thus, also related to the weight. This results in an interaction of the fast process of synaptic plasticity (timescale minutes to hours) and the slower structural plasticity (timescale days). Despite many experimental clues, this interaction is still widely unknown.\nWe analyze this interaction in the following abstract model: Between two neurons, there are a certain number of potential synaptic locations, which can be transformed to a synapse by growing a dendritic spine with a certain probability. Each synapse is then adapted by synaptic plasticity which  changes the weights according to the experienced activity pattern. by contrast, the removal of the synapse happens at a weight-dependent probability in a way that bigger synapses live longer.\nThis model enables us to analyze the long-term behavior of this system and compare it with connectivity statistics from the cortex. From this we can derive, which kinds of neuron models and plasticity rules are capable of reproducing the biological data under our model-assumptions. Thereby, most importantly, the weights need to grow with the post-synaptic activity. Although this is consistent with the \u201cfire together-wire together\u201d-idea, common learning rules will only exhibit this behavior in a recurrent network.", "acknowledgements": "This work was supported by BCCN G\u00f6ttingen, Project D2.", "id": 196717, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Michael Fauth"}, {"epithet": "1", "name": "Christian Tetzlaff"}, {"epithet": "1", "name": "Florentin W\u00f6rg\u00f6tter"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["tetzlaff@physik3.gwdg.de"], "figid": 239, "doi": "10.12751/nncn.bc2013.0239", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, G\u00f6ttingen, Germany"}, {"index": "2", "address": "Weizmann Institute, Rehovot, Israel"}], "title": "Synaptic Scaling enables Dynamically Distinct Short- and Long-Term Memory Formation", "abstract": "Memory formation in the nervous system relies on mechanisms acting on time scales from minutes, for long-term synaptic plasticity [1], to days, for memory consolidation [2]. During such processes, the neural network distinguishes synapses relevant for forming a long-term storage (LTS), which are consolidated, from synapses of short-term storage (STS), which fade. How time scale integration and synaptic differentiation is simultaneously achieved within one neural circuit remains unclear. We show in simulations and mean-field analyses that synaptic scaling [3] \u2013 a slow process usually associated with the maintenance of activity homeostasis \u2013 combined with the faster processes of synaptic plasticity simultaneously achieve both, thereby providing a natural separation of short- from long-term storage. A network intrinsic bifurcation enables this separation as this bifurcation induces different response properties of previously learned cell assemblies due to external memory reactivations. These reactivations could be associated with \u201csleep-like\u201d activations as, for instance, sharp-wave ripples during slow-wave sleep [4,5]. Additionally, the interaction between plasticity and scaling provides an explanation for an established paradox where memory consolidation and destabilization critically depends on the exact order of learning and recall. This enables us to reproduce human-psychophysical results [6] on the apparently paradoxical effect of memory destabilization due to memory recall [7]. However, other experimentalists failed to reproduce this memory destabilization effect (e.g., [8]). This ambivalence can be explained by the here proposed bifurcation scenario as the initial conditions and exact timings of recall and learning determine the transition between consolidation and destabilization. Thus, the dynamics of our model yield the fact that recent memory \u2013 similar to the real systems \u2013 remains susceptible to perturbations and has to be repeatedly consolidated [2]. ", "acknowledgements": "", "id": 196718, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Christian Tetzlaff"}, {"epithet": "1", "name": "Christoph Kolodziejski"}, {"epithet": "1", "name": "Marc Timme"}, {"epithet": "2", "name": "Misha Tsodyks"}, {"epithet": "1", "name": "Florentin W\u00f6rg\u00f6tter"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Bliss TVP, Lomo T, J. Physiol. 1973, 232:331-356.\n2. Dudai Y. Annu. Rev. Psychol. 2004, 55:51-86.\n3. Turrigiano GG et al., Nature 1998, 391:892-896.\n4. Diekelmann S, Born J, Nat. Rev. Neurosci. 2010, 11:114-126.\n5. Chauvette S et al., Neuron 2012, 75:1105-1113.\n6. Walker MP et al., Nature 2003, 425:616-620.\n7. Nader K et al., Nature 2000, 406:722-726.\n8. Cammarota M et al., Learn. Mem. 2004, 11:572-578."}, {"correspondence": ["faghihi@physik3.gwdg.de"], "figid": 240, "doi": "10.12751/nncn.bc2013.0240", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience, Department of Computational Neuroscience, University of G\u00f6ttingen, G\u00f6ttingen, Germany"}, {"index": "2", "address": "Social Science and Psychology,University of Western Sydney, Australia"}, {"index": "3", "address": "Department of Cellular Neurobiology, Institute for Zoology and Anthropology, University of G\u00f6ttingen, G\u00f6ttingen, Germany"}], "title": "Retrograde Signaling Based Model of Associative Learning in Drosophila Olfactory System", "abstract": "Drosophila can learn the association of a given odor with an electric shock as punishment [1]. Thereby, timing plays an important role such that presenting the shock even seconds after the odor presentation (Inter Stimulus Interval [ISI]) can still lead to learning [2]. The mechanism of how the odor information is retained until presenting the shock is still unknown. Moreover, increase in the ISI leads to rise in the learning with maximum peak around ISI equal to 35 seconds. Any further increase in the ISI leads to the decrease in learning [2]. Another important question is the mechanism of detecting eligible synapses: electric shock cause non-specific release of dopamine into a large population of neurons in Mushroom Body but only a few neurons in Mushroom Body are activated by an odor (sparse coding) [3]. So, just the activated neurons should be affected by dopamine. Furthermore, Lateral Horn as a source of inhibition on Mushroom Body is believed to involve in sparse coding, however, its possible role in associative learning has been questioned [4]. Regarding that none of current learning algorithms is able to link the behavioral data to the neural mechanism underlying olfactory learning [5] we present a phenomenological learning rule to perform this link. In this work we assumed that in response to the odor presentation Nitric Oxide is produced in the Output Neurons and diffuses into Mushroom Body which in turn induces an increase in calcium concentration. This model proposes a mechanism for detecting eligible synapses by dopaminergic neurons as well as a molecular mechanism for learning. The results demonstrate the fundamental role of sparse coding and the parameters that support it (inhibition from Lateral Horn and low connectivity rate between Antennal Lobe and Mushroom Body) in system\u2019s efficiency for associative learning.  ", "acknowledgements": "This work was supported by Bernstein Center for Computational Neuroscience, G\u00f6ttingen. project B5", "id": 196719, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Faramarz Faghihi"}, {"epithet": "2", "name": "Ahmed Moustafa"}, {"epithet": "3", "name": "Ralf Heinrich"}, {"epithet": "1", "name": "Florentin W\u00f6rgotter"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] McGuire SE,et al. Thirty years of olfactory learning and memory research in Drosophila melanogaster. Progress in neurobiology (2005) \n[2] Yarali A, et al. Event timing in associative learning: from biochemical reaction dynamics to behavioural observations. PLoS One (2012)\n[3] Ito I,et al. Sparse odor representation and olfactory learning. Nature Neuroscience. (2008)\n[4]Nitin Gupta and Mark Stopfer. Functional analysis of a higher olfactory center, the lateral horn. Journal of Neuroscienc"}, {"correspondence": ["rainer@nld.ds.mpg.de"], "figid": 241, "doi": "10.12751/nncn.bc2013.0241", "affiliations": [{"index": "1", "address": "MPI for Dynamics and Self-0rganisation, Germany"}, {"index": "2", "address": "Tsinghua University, Beijing, Germany"}], "title": "Single cell dynamics shapes network chaos", "abstract": "Irregular and asynchronous dynamics of cortical activity can be explained by the balance of excitatory and inhibitory synatic inputs \u2013 the balanced state [1].\n\nAlthough the statistical properties of this state are well described by a field theory that is independent of the single neuron dynamics, recent studies show that its dynamics depends crucially on single cell properties. Inhibitory networks of pulse-coupled leaky-integrate-and-fire neurons show stable dynamics [2,3], while a balanced network of neurons with an active spike generation mechanism exhibit deterministic extensive chaos [4]. Increasing the action potential onset rapidness reduces the chaos in the balanced state [5].\n\nHere we extended this analysis to a new neuron type with both variable synaptic time constant and changeable action potential onset rapidness, called the correlated rapid theta neuron model. We derived an analytical expression for the single spike Jacobian, which enables us to calculate the Lyapunov spectrum for networks of neurons with any desired synaptic time constant and spike onset rapidness. We simulated the dynamics in numerically exact event-based simulations and calculated Lyapunov spectra, entropy production rate and attractor dimension.", "acknowledgements": "Van Vreeswijk, C., Sompolinsky, H., 1996. Chaos in Neuronal Networks with Balanced Excitatory and Inhibitory Activity. Science 274, 1724 \u20131726.\n1.Van Vreeswijk, C. & Sompolinsky, H. Chaos in Neuronal Networks with Balanced Excitatory and Inhibitory Activity. Science 274, 1724 \u20131726 (1996).\nVan Vreeswijk, C., and Sompolinsky, H. (1996). Chaos in Neuronal Networks with Balanced Excitatory and Inhibitory Activity. Science 274, 1724 \u20131726.\n[1] C. van Vreeswijk and H. Sompolinsky, \u201cChaos in Neuronal Networks with Balanced Excitatory and Inhibitory Activity,\u201d Science, vol. 274, no. 5293, pp. 1724 \u20131726, Dec. 1996.\n", "id": 196720, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Rainer Engelken"}, {"epithet": "2", "name": "Chenfei Zhang"}, {"epithet": "1", "name": "Michael Monteforte"}, {"epithet": "1", "name": "Fred Wolf"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] van Vreeswijk, C. & Sompolinsky, H. Chaos in neuronal networks with balanced excitatory and inhibitory activity. Science 274, 1724-1726 (1996). DOI:10.1126/science.274.5293.1724\n[2] Jahnke, S., Memmesheimer, R.-M. & Timme, M. How Chaotic is the Balanced State? Frontiers in Computational Neuroscience 3, 13 (2009).\n[3] Zillmer, R., Brunel, N. & Hansel, D. Very long transients, irregular firing, and chaotic dynamics in networks of randomly connected inhibitory integrate-and-fire neurons. Physical Review E 79, 031909 (2009).\n[4] Monteforte, M. & Wolf, F. Dynamical entropy production in spiking neuron networks in the balanced state. Physical Review Letters 105, 268104 (2010).\n[5] Monteforte, M., Wolf, F. (2011) Single cell dynamics determine strength of chaos in collective network dynamics. Twentieth Annual Computational Neuroscience Meeting: CNS2011"}, {"correspondence": ["mantas.gabrielaitis@gmail.com"], "figid": 242, "doi": "10.12751/nncn.bc2013.0242", "affiliations": [{"index": "1", "address": "Department of Nonlinear Dynamics, Max Planck Institute for Dynamics and Self-Organization, Goettingen, Germany"}, {"index": "2", "address": "Bernstein Center for Computational Neuroscience, Goettingen, Germany"}, {"index": "3", "address": "InnerEarLab, Department of Otolaryngology, University of Goettingen, Medical School, Goettingen, Germany"}], "title": "Response heterogeneity and efficiency of stimulus level encoding at inner hair cell ribbon synapses", "abstract": "Spiral ganglion neurons (SGN), which are postsynaptic to auditory inner hair cells (IHC), show high variability in spontaneous and sound-driven discharge rate, dynamic range, and sensitivity [1]. Recent experimental evidence suggests that molecular properties of the IHC presynaptic active zones also vary from synapse to synapse [2,3]. These findings support the hypothesis that the apparent variability of SGN responses could be due to the differences in the molecular organization of the presynaptic active zones [2,3].  However, it is not quantitatively understood how sound-driven SGN responses are affected by the organization of IHC presynaptic active zones.\n\nIn this work, we approached that question theoretically. To this end, we formulated and studied an analytically tractable biophysical model of the presynaptic active zone. As a quantitative response characteristic, we considered adapted rate-level (RL) functions of high characteristic frequency SGNs [1]. We found that the model is capable of reproducing experimental RL functions quantitatively. Furthermore, we showed that the same RL function could be reproduced by considerably different parameter sets of the model. For example, shift of the stimulus dependence of RL functions was achieved either by shifting the voltage dependence of presynaptic Ca2+ channel activation curves, changing release site recovery rates, or changing rates of Ca2+ binding to the vesicle release receptors. Changes in RL function slopes resulted either from changes in slopes of Ca2+ channel voltage activation curves or varying levels of response heterogeneity among different release sites of the same active zone. To assess efficiency of the stimulus level encoding, we estimated mutual information based on stationary inter-spike-intervals and spike count. Interestingly, in spite of the freedom of the parameter choice in reproducing the RL functions, some choices resulted in considerably more efficient stimulus encoding than the others.", "acknowledgements": "", "id": 196721, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1,2", "name": "Mantas Gabrielaitis"}, {"epithet": "1,2", "name": "Nikolai Chapochnikov"}, {"epithet": "2,3", "name": "Tobias Moser"}, {"epithet": "1,2", "name": "Fred Wolf"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. Sachs MB, Abbas PJ: Rate versus level functions for auditory-nerve fibers in cats: tone-burst stimuli. J Acoust Soc Am 1974, 56: 1835-47.\n2. Frank T, Khimich D, Neef A, Moser T: Mechanisms contributing to synaptic Ca2+ signals and their   heterogeneity in hair cells. Proc Natl Acad Sci U S A 2009, 106: 4483-88.\n3. Grant L, Yi E, Glowatzki E: Two modes of release shape the postsynaptic response at the inner hair cell ribbon synapse. J Neurosci 2010, 30: 4210-20."}, {"correspondence": ["joscha@nld.ds.mpg.de"], "figid": 243, "doi": "10.12751/nncn.bc2013.0243", "affiliations": [{"index": "1", "address": "MPI f\u00fcr Dynamik und Selbstorganisation, BCCN, Germany"}], "title": "Local stability properties of inhibitory chaotic balanced networks", "abstract": "The irregular and asynchronous spiking patterns observed in cortical neurons can be reproduced by neural network models in the balanced state, where the excitatory and inhibitory currents approximately cancel. This balanced state emerges from synaptic coupling strength of order 1/\u221aK, and external current of order K, with K the number of post-synaptic neurons on large Erd\u00f6s-R\u00e9nyi random graphs [1]. This configuration yields irregular and asynchronous spiking activity, which we simulate for sparsely connected inhibitory rapid theta networks with instantaneous pulse coupling. \nTo shed light on the dynamics governing these networks, one can examine their Lyapunov spectrum. This spectrum of exponents characterizes the asymptotic limit of the growth of infinitesimal perturbations in the network. Covariant Lyapunov vectors are vectors corresponding to these exponents and are locally defined [2]. They point in the direction of stable, neutral and unstable manifolds and thus define the local geometry of expanding or contracting perturbations. \nIn [3] sparsely connected inhibitory rapid theta networks with instantaneous pulse coupling were found to be chaotic, characterized by positive Lyapunov exponents, but become stable above a critical action potential onset rapidness. Here we extended this analysis by probing these dynamics with the covariant Lyapunov vectors. Our analysis gives the local properties of the stable, neutral and unstable manifold revealing the angle distribution between these manifolds and their local expansion rates.", "acknowledgements": "", "id": 196722, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Joscha Liedtke"}, {"epithet": "1", "name": "Fred Wolf"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1] van Vreeswijk, C. & Sompolinsky, H. (1996) Chaos in neuronal networks with balanced excitatory and inhibitory activity. Science 274, 1724-1726. \n\n[2] Ginelli, F. et al. (2007) Characterizing dynamics with covariant Lyapunov vectors. Physical Review Letters, 99(13), 130601. \n\n[3] Monteforte, M., Wolf, F. (2011) Single cell dynamics determine strength of chaos in collective network dynamics. Twentieth Annual Computational Neuroscience Meeting"}, {"correspondence": ["andreas@nld.ds.mpg.de"], "doi": "10.12751/nncn.bc2013.0244", "affiliations": [{"index": "1", "address": "MPI for Dynamics and Self-Organization, Germany"}, {"index": "2", "address": "Hebrew Univ., Rehovot, Israel"}, {"index": "3", "address": "MPI for Experimental Medicine, Germany"}], "title": " Neuronal encoding properties of individual neurons studied with continuous dynamic photostimulation", "abstract": "Understanding information encoding by individual central neurons requires characterization of their input-output functions under near-natural input conditions, e.g. in the fluctuation driven regime, characteristic of cortical circuits. Controlling the input and registering on the order of 104-105 spikes as output, one can compute transfer metrics which are critical for collective network dynamics, such as dynamic gain, correlation gain or spike frequency vs current (FI-) curves. Until now such data are exclusively obtained in sharp electrode or patch-clamp recordings, where the input to the cell body and therefore to the spike trigger zone in the axon initial segment is directly controlled. Due to the limited number of spikes obtained in invasive recordings, characterization of individual neurons is often not possible, dynamic gain curves, for instance, are averaged over tens of neurons.\nWe recently developed an alternative, non-invasive method for neuronal characterization. Spikes are recorded by an array of extracellular electrodes. Well-defined, fluctuating stimuli are delivered via light-activated channelrhodopsins to pharmacologically isolated neurons. Careful characterization of channelrhodopsin's transfer function warrants precise control over the waveform of the induced conductance. An 8x8 array of high-power LEDs provides local (50 \u00b5m) stimulation. Spot intensities of up to 30 mW/mm2 are independently modulated at several kHz. The non-invasive nature of the experiment enables characterization of many individual neurons for many hours, up to few days. The setup delivers orders of magnitude more data than previously possible in the field of input-output characterization. Neuronal responses were stable, measurement of pH_i showed only minor acidification under continuous stimulation. Comparison of our results with dynamic gain measurements and FI-curves obtain with traditional methods establishes the equivalence of the non-invasive, high-throughput method. ", "acknowledgements": "Supported by the BMBF through BCCN and BFNT G\u00f6ttingen (01GQ1005B, 01GQ0811, 01GQ0813, 01GQ1005E)", "id": 196723, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Andreas Neef"}, {"epithet": "1", "name": "Ahmed El Hady"}, {"epithet": "2", "name": "Elinor Lazarov"}, {"epithet": "1", "name": "Kai Br\u00f6king"}, {"epithet": "3", "name": "Walter St\u00fchmer"}, {"epithet": "1", "name": "Fred Wolf"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "Continuous Dynamic Photostimulation: (A) Diagram of the method. (B) Spike triggered average input conductance. (C) Conditional firing rate for partially correlated inputs.", "figpath": "244.png", "refs": ""}, {"correspondence": ["phine@nld.ds.mpg.de"], "figid": 245, "doi": "10.12751/nncn.bc2013.0245", "affiliations": [{"index": "1", "address": "MPI Dynamik und Selbstorganisation, BCCN, Germany"}], "title": "Chaos in 3-Neuron Networks", "abstract": "In balanced state networks of theta neurons(the phase representation of the QIF), chaos is a robust phenomenon ([1]). This state is characterized by asynchronous and irregular spiking patterns, similar to those in cortical neurons ([2]). To dissect the nature of the underlying mechanisms of chaos in spiking neuron networks we searched for the smallest network in which chaos occurs. Since chaos cannot occur in phase spaces of dimensionality lower than 3 we systematically screened all networks defined by three neuron motives, identifying chaotic three theta neuron networks. \nWe simulate such a network using the Phi representation of the Theta model, which has the advantage of a constant phase velocity. To shed light on the characteristics of the network chaos we examined Poincare sections defined by spike times of one of the neurons. Also we calculated the Lyapunov exponents of the network and its covariant Lyapunov vectors([3]). Many of the trajectories, are confined to quasiperiodic-tori enclosed in a sea of chaotic motion, similar to the phase space structure of generic Hamiltonian dynamical systems. Lyapunov exponents describe the growth of infinitesimal perturbations, whereas the covariant Lyapunov vectors assign local directions to the exponents. We give a complete characterization of the stability properties of the system and describe its route to chaos.\n\n", "acknowledgements": "", "id": 196724, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Josephine Thomas"}, {"epithet": "1", "name": "Joscha Liedtke"}, {"epithet": "1", "name": "Fred Wolf"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1]  Michael Monteforte, Fred Wolf:  \u201cDynamical Entropy Production in Spiking Neuron Networks in the Balanced State\u201d Phys. Rev. Lett. 105, 268104 (2010)\n\n[2] C. van Vreeswijk, H. Sompolinsky:\u201dChaos in neuronal networks with balanced excitatory and inhibitory activity.\u201d Science 274, 1724-1726 (1996)\n\n[3] Ginelli, F., Poggi, P., Turchi, A., Chat\u00e9, H., Livi, R., & Politi, A.\n(2007). Characterizing dynamics with covariant Lyapunov vectors. Phys. Rev. Lett., 99(13), 130601.\n"}, {"correspondence": ["mptouzel@nld.ds.mpg.de"], "figid": 246, "doi": "10.12751/nncn.bc2013.0246", "affiliations": [{"index": "1", "address": "Max Planck Institute for Dynamics and Self-organization, Bernstein Center for Computational Neuroscience, Goettingen, Germany"}], "title": "Microstate description of stable chaos in balanced spiking networks", "abstract": "Dynamic instabilities have been offered as an explanation for how the olfactory bulb can separate its inputs[1]. However, dynamical models that can flexibly adjust both to separate and categorize inputs based on relevance are lacking. Dynamic stability of networks with linear coupling is determined exclusively by the Lyapunov spectrum, while nonlinear \u2018spike\u2019 coupling can add an instability with respect to changes in spike sequence. When the Lyapunov spectrum is stable (e.g. for rapid action potential onset), the resulting stable chaos is determined by a critical scale separating coexisting stable and unstable dynamics [2]. Here, we explain this phenomenon at the level of network spike train activity and explore how this feature can be used by a network modeled after the bulb to facilitate learning of inputs.\n\nWe built a spiking network model based on the network of mutually inhibiting mitral cells. Using our analytic solution to a 2D mitral cell model, we implemented an efficient and precise root finding algorithm to obtain the next spike time within a network. Using this, we performed numerically exact, event-based network simulations, iterating from one spike in the network to the next. To assess the stability of such networks, we analytically calculated the single spike Jacobian of the event map, which describes how small perturbations evolve between spikes and which we use to compute the full Lyapunov spectrum, finding it stable. Our analysis of stability with respect to larger size perturbations shows that the sensitivity varies in time with the proximity of an event with a particular spiking and connectivity motif. From this mechanistic understanding, we were able to analytically derive the previously discovered [3] scaling of the sensitivity with the network parameters. This finding suggests a scheme for controlling the operating point of the system along the trade-off between categorizing and separating inputs to facilitate learning by olfactory cortex[3]", "acknowledgements": "M.P.T. acknowledges the support of the IMPRS for Physics of Biological and Complex Systems. This work was supported by BMBF (01GQ07113, 01GQ0811, 01GQ0922, 01GQ1005B), GIF (906-17.1/2006), DFG (SFB 889), VW-Stiftung (ZN2632), and the Max Planck Society.", "id": 196725, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Maximilian Puelma Touzel"}, {"epithet": "1", "name": "Michael Monteforte"}, {"epithet": "1", "name": "Fred Wolf"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1. M. Rabinovich, R. Huerta, and G. Laurent. Transient Dynamics for Neural Processing Science 321, 48 (2008). DOI: 10.1126/science.1155564\n2. Monteforte, M. & Wolf, F. Dynamic Flux Tubes Form Reservoirs of Stability in Neuronal Circuits. PRX 2, 1\u201312 (2012). DOI: 10.1103/PhysRevX.2.041007\n3. Chapuis, J. & Wilson, D. A. Bidirectional plasticity of cortical pattern recognition and behavioral sensory acuity. Nat. Neuro. 15, 155\u201361 (2012). DOI:10.1038/nn.2966\n"}, {"correspondence": ["nehrkorn@bio.lmu.de"], "figid": 248, "doi": "10.12751/nncn.bc2013.0248", "affiliations": [{"index": "1", "address": "Bernstein Center for Computational Neuroscience Munich, Martinsried, Germany"}, {"index": "2", "address": "Max Planck Institute of Neurobiology, Martinsried, Germany"}, {"index": "3", "address": "Ludwig-Maximilians-Universit\u00e4t Mu\u0308nchen, Faculty of Biology, Department II, Neurobiology, Martinsried, Germany"}, {"index": "4", "address": "Leibniz Institute for Neurobiology, Magdeburg, Germany"}], "title": "Learning about absolute odor intensities: A model for Drosophila melanogaster", "abstract": "Sensory stimuli can have multiple dimensions such as brightness and frequency for light, pitch and loudness for sound or odor quality and intensity for odors. The fruit fly Drosophila melanogaster can be trained to associate a particular odor with a reinforcement signal [1] when tested against a different odor. Also, and maybe more intriguingly, it is possible to train these flies to associate a particular absolute odor intensity when tested against higher and lower concentrations of the same odor [2, 3]. This implies a concentration-specific odor representation within the olfactory system. In contrast to this, the early processing stages in the olfactory system of Drosophila melanogaster harbor a nested representation of odor intensity: Their activation is monotonously increasing with increasing intensity [4, 5], which is unsuitable to form associations based on absolute concentrations. \nHere we propose a simple network scheme that is able to transform such a nested coding scheme into an intensity-specific representation, based on a layered structure that is compatible with the known anatomical and functional structure of the olfactory system of the fruit fly. The model predictions agree well with results from the behavioral experiments. \n", "acknowledgements": "This work was supported by a BMBF Grant to H. T. and AVM H.", "id": 196727, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Johannes Nehrkorn"}, {"epithet": "2", "name": "Hiromu Tanimoto"}, {"epithet": "3", "name": "Andreas Herz"}, {"epithet": "4", "name": "Ayse Yarali"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "1.    Tully T, Quinn WG (1985) J Comp Physiol A 157:263\u201377 doi:10.1007/BF01350033\n2.    Xia S, Tully T (2007) PLoS Biol: 5(10) e264 doi:10.1371/journal.pbio.0050264\n3.    Yarali A, Ehser S, Hapil FZ, Huang J, Gerber B (2009) Proc. Nat. Acad. Sci. B: Biological Sciences 276:3413 doi:10.1098/rspb.2009.0705\n4.    Hallem E, Carlson JR (2006) Cell 125:143\u201360 doi:10.1016/j.cell.2006.01.050\n5.    Olsen SR, Bhandawat V, Wilson RI (2010) Neuron 66:287\u201399 doi:10.1016/j.neuron.2010.04.009"}, {"correspondence": ["triesch@fias.uni-frankfurt.de"], "figid": 249, "doi": "10.12751/nncn.bc2013.0249", "affiliations": [{"index": "1", "address": "Frankfurt Institute for Advanced Studies, Germany"}, {"index": "2", "address": "Hong Kong University of Science and Technology, Hong Kong"}], "title": "Intrinsically Motivated Learning in Active Perception", "abstract": "The goal of perceptual systems is to provide useful knowledge about the environment and to encode this information efficiently. As such, perception is an active process that often involves the movement of sense organs such as the eyes. This active nature of perception has been neglected in popular theories describing how nervous systems learn sensory representations. Here we present an approach for intrinsically motivated learning during active perception that treats the learning of sensory representations and the learning of movements of the sense organs in an integrated manner. In this approach, a generative model learns to encode the sensory data while a reinforcement learner controls the sense organs so as to make the generative model work as effectively as possible. To this end, the reinforcement learner receives an intrinsic reward signal reflecting the encoding quality currently obtained by the generative model. The approach is quite general. In the context of binocular vision, it is shown to lead to a self-calibrating stereo vision system that learns a representation for binocular disparity while at the same time learning proper vergence eye movements to fixate objects. In the context of motion perception, it is shown to lead to the development of motion detectors and smooth pursuit behavior. The approach may also be used to better understand other types of eye movements or extended to different sensory modalities. Somewhat surprisingly, it also offers a new perspective on the development of imitation abilities.\n", "acknowledgements": "This work was supported by the Bernstein Focus for Neurotechnology Frankfurt, EU FP7 project IM-CLeVeR, and the German Academic Exchange Service (DAAD).", "id": 196728, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Pramod Chandrashekhariah"}, {"epithet": "1", "name": "S\u00e9bastien Forestier"}, {"epithet": "1", "name": "Luca Lonini"}, {"epithet": "1", "name": "Constantin Rothkopf"}, {"epithet": "2", "name": "Bert Shi"}, {"epithet": "1", "name": "C\u00e9line Teuli\u00e8re"}, {"epithet": "1", "name": "Jochen Triesch"}, {"epithet": "2", "name": "Chong Zhang"}, {"epithet": "2", "name": "Yu Zhao"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["archana.jalligampala09@gmail.com"], "doi": "10.12751/nncn.bc2013.0250", "affiliations": [{"index": "1", "address": "Institute for Ophthalmic Research; Centre for Integrative Neuroscience; Max Planck Graduate School of Neural and Behavioral Sciences, Eberhard-Karls University, T\u00fcbingen, Germany"}, {"index": "2", "address": "Institute for Ophthalmic Research; Centre for Integrative Neuroscience; Bernstein Center for Computational Neuroscience, Eberhard-Karls University, T\u00fcbingen, Germany"}], "title": "Electrically driven responses in Wild-Type and Rd10 Mouse Retinal Ganglion Cells", "abstract": "Purpose: Over the years,retinal implants have been developed to restore limited vision in patients blinded by outer retinal diseases like retinitis pigmentosa (RP) through electrical stimulation of the surviving neurons. The recently identified rd10 mouse, which has a relatively delayed onset and slower progression of degeneration is an appropriate model to study RP. Here we investigate retinal ganglion cell  (RGC) responses to different stimulation paradigms in adult wild-type (wt) & rd10 mice.\n\nMethods: RGC spiking responses were recorded in vitro from patches of wt and rd10 retina epiretinally, using a planar multi-electrode array (MEA, 60 electrodes, 200\u00b5m interelectrode distance, 30\u00b5m diameter, MCS, GmbH). The stimulus was delivered via one of the 60 electrodes on the MEA while the other electrodes recorded electrically-evoked responses. Stimuli consisted of square-wave, monophasic voltage pulses in incremental blocks with randomized pulse durations. The same protocol was applied during subretinal stimulation in which a flex-MEA (36 electrodes,300\u00b5m interelectrode distance, 30\u00b5m diameter, MCS, GmbH) was placed on the subretinal side to deliver electrical stimulation while the planar MEA recorded from RGCs in a 'sandwich' configuration.\n\nResults: Under epiretinal stimulation, the wt & rd10 retina demonstrated voltage and duration dependence. For both mouse strains, a dependence of the response on duration was typically seen only for a few transitional (threshold) voltages. There were no significant differences in stimulus thresholds between wt & rd10 retina,(Fig 1);(Chan 2011 , Jensen 2008). We also present preliminary epiretinally-recorded responses during simultaneous subretinal stimulation in wt retina using the \u2018sandwich\u2019 approach.\n\nConclusion: Based on our findings,we propose tentative stimulation parameters appropriate for activation of rd10 retina in our continued development of more efficient stimulation protocols for the T\u00fcbingen retinal prosthesis.\n", "acknowledgements": "BMBF, KFZ:01G1002 \nCIN(DFG EXC307,2011-07) \nT\u00fcbingen IZKF grant # F 1222724.1 \nTistou and Charlotte Kerstan Foundation \nProRETINA Foundation\nNeuroopthalmologie Gesellschaft(NOG)\n", "id": 196729, "topic": "Neural encoding and decoding", "authors": [{"epithet": "1", "name": "Archana Jalligampala"}, {"epithet": "2", "name": "Daniel Rathbun"}, {"epithet": "2", "name": "Eberhart Zrenner"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": " Fig 1:Population Summaries. (A & B) Threshold voltage for each duration. (C & D) Threshold duration for each voltage. Threshold was defined as the average baseline response + 2*variance. Black brackets and asterisks indicate groups between which each pairwise comparison yielded statistical significance (Wilcoxon ranksum test, p<.05). Red asterisks in B and D indicate statistical significance when comparing WT and rd10.", "figpath": "250.jpeg", "refs": "Chan LLH, Lee EJ, Humayun MS, Weiland JD.  2011.  \"Both electrical stimulation thresholds and SMI-32 immunoreactive retinal ganglion cell density correlate with age in s334ter line 3 rat retina.\"  J. Neurophysiol. 105: 2687\u20132697.\nDOI: 10.1152/jn.00619.2010.\nJensen RJ, Rizzo JF.  2008.  \"Activation of retinal ganglion cells in wild-type and rd1 mice through electrical stimulation of the retinal neural network.\"  Vision Res. 48: 1562\u20131568. \nDOI: 10.1016/j.visres.2008.04.016."}, {"correspondence": ["roland.w.fleming@psychol.uni-giessen.de"], "figid": 251, "doi": "10.12751/nncn.bc2013.0251", "affiliations": [{"index": "1", "address": "University of Giessen, Germany"}, {"index": "2", "address": "Yale University, United States"}], "title": "US-German Collaboration: Colour in Cortex: Orientations, flows, and surface inferences", "abstract": "What information is available for visually inferring the shape of an apple? Brightness variations provide a shape-from-shading cue, and surface markings provide a shape-from-texture cue. But at the same time, pigmentation in the skin of the apple also leads to brightness changes, which frequently confound those due to shading. We present evidence that crucial information is extracted from the way local image orientation signals vary continuously across projected surfaces ('orientation flows'), and that these flows provide the foundation for surface inferences. Striking regularities in the flows emerge when computer renderings of shaded and textured objects are represented in a (superficial-layer) V1 fashion. These orientation flows change when illumination and texture patterns change, leading to a number of psychophysical predictions. A model of shape inference from shading flows reveals how surface and light source properties emerge from the flows, and the geometry of the model could be learned by the visual system. Finally, returning to the apple example, we show how flows of color can separate material from reflectance changes. Physiologically, these flows  can be represented by oriented color double-opponent cells.  Together these findings suggest that the visual estimation of shape from shading, highlights and texture may have more in common than previously thought, that orientation fields could act as a 'common currency' for the visual estimation of shape, and that color is used for many computations other than segmenting red fruit from green foliage.\n", "acknowledgements": "This research is funded by the NSF-BMBF Joint Program in Computational Neuroscience (FKZ: 01GQ1111).", "id": 196730, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Roland Fleming"}, {"epithet": "2", "name": "Steven Zucker"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": ""}, {"correspondence": ["tspus@fuw.edu.pl"], "figid": 252, "doi": "10.12751/nncn.bc2013.0252", "affiliations": [{"index": "1", "address": "University of Warsaw Division of Physics, Poland"}], "title": "Decomposition of multitrial multichannel event related potentials", "abstract": "Event related potentials (ERP) are brain responses to a given stimuli observed in electroencephalogram (EEG). The classic approach to extract ERP is to average many stimulus-aligned epochs of the EEG signal containing the response [1].  But synchronous electrical activity of neurons can be approximated by the current dipole [2]. Each of the dipoles can be treated as a source, providing a contribution to the measured EEG. The potential measured at the scalp is a weighted sum of the components due to the various current sources.\n\nThe main objective of the project was to develop a method for the automatic decomposition of multichannel ERPs, that combines the best properties of Matching Pursuit (MP)[3] and Independent Component Analysis (ICA)[4] algorithms into a novel method. ICA enables the decomposition of the signal into a number of components equal to the number of channels that has been analyzed. Even though ICA components are statistically independent, we often observe residual crosstalk between them. To remove this significant drawback, the components were parametrized in time-frequency domain by MP procedure. Cluster analysis applied to such parametrized signals revealed repetitive structures in different components which enabled us to identify activity related to each of the underlying sources in multiple trials.\n\nThe presented method for the decomposition of evoked potentials into components was tested on both simulated and real experimental data.", "acknowledgements": "This study was supported by polish founds for science.", "id": 196731, "topic": "Neural encoding and decoding", "imagefile": "", "authors": [{"epithet": "1", "name": "Tomasz Spustek"}, {"epithet": "1", "name": "Jaros\u0142aw \u017bygierewicz"}], "coi": "The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.\n", "caption": "", "refs": "[1]S.J.Luck,\"An Introduction To The Event-Related Potential Technique\".MIT Press,2005\n[2]P.Nunez,\"Electric Fields of the Brain\".New York:Oxford University Press,1981\n[3]S.G.Mallat and Z.Zhang,\"Matching pursuits with time-frequency dictionaries\",IEEE Transactions on Signal Processing,pp.3397\u20133415,1993\n[4]S.Makeig,A.Bell,T.-P.Jung,T.Sejnowski,\"Independent component analysis of electroencephalographic data\",Advances in Neural Information Processing Systems vol.8,pp.145\u2013151,MIT Press,Cambridge,1996"}];